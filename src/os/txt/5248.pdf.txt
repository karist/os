22_CD Evolutionary_NNP Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NNP Francesco_NNP Mola1_NNP ,_, Raffaele_NNP Miele2_NNP and_CC Claudio_NNP Conversano1_NNP 1University_NNP of_IN Cagliari_NNP ,_, 2University_NNP of_IN Naples_NNP Federico_NNP II_NNP Italy_NNP 1_CD ._. Introduction_NNP One_CD of_IN the_DT biggest_JJS problem_NN that_IN many_JJ data_NNS analysis_NN techniques_NNS have_VBP to_TO deal_VB with_IN nowadays_RB is_VBZ Combinatorial_JJ Optimization_NN that_IN ,_, in_IN the_DT past_NN ,_, has_VBZ led_VBN many_JJ methods_NNS to_TO be_VB taken_VBN apart_RB ._. Actually_RB ,_, the_DT (_-LRB- still_RB not_RB enough_JJ !_. )_-RRB- higher_JJR computing_NN power_NN available_JJ makes_VBZ it_PRP possible_JJ to_TO apply_VB such_JJ techniques_NNS within_IN certain_JJ bounds_NNS ._. Since_IN other_JJ research_NN fields_NNS like_IN Artificial_JJ Intelligence_NNP have_VBP been_VBN (_-LRB- and_CC still_RB are_VBP )_-RRB- dealing_VBG with_IN such_JJ problems_NNS ,_, their_PRP$ contribute_VBP to_TO statistics_NNS has_VBZ been_VBN very_RB significant_JJ ._. This_DT chapter_NN tries_VBZ to_TO cast_VB the_DT Combinatorial_NNPS Optimization_NNP methods_NNS into_IN the_DT Artificial_JJ Intelligence_NNP framework_NN ,_, particularly_RB with_IN respect_NN Decision_NNP Tree_NNP Induction_NNP ,_, which_WDT is_VBZ considered_VBN a_DT powerful_JJ instrument_NN for_IN the_DT knowledge_NN extraction_NN and_CC the_DT decision_NN making_VBG support_NN ._. When_WRB the_DT exhaustive_NN enumeration_NN and_CC evaluation_NN of_IN all_DT the_DT possible_JJ candidate_NN solution_NN to_TO a_DT Tree-based_JJ Induction_NN problem_NN is_VBZ not_RB computationally_RB affordable_JJ ,_, the_DT use_NN of_IN Nature_NNP Inspired_NNP Optimization_NN Algorithms_NNP ,_, which_WDT have_VBP been_VBN proven_VBN to_TO be_VB powerful_JJ instruments_NNS for_IN attacking_VBG many_JJ combinatorial_JJ optimization_NN problems_NNS ,_, can_MD be_VB of_IN great_JJ help_NN ._. In_IN this_DT respect_NN ,_, the_DT attention_NN is_VBZ focused_VBN on_IN three_CD main_JJ problems_NNS involving_VBG Decision_NNP Tree_NNP Induction_NNP by_IN mainly_RB focusing_VBG the_DT attention_NN on_IN the_DT Classification_NN and_CC Regression_NN Tree-CART_NNP (_-LRB- Breiman_NNP et_NNP al_NN ._. ,_, 1984_CD )_-RRB- algorithm_NN ._. First_RB ,_, the_DT problem_NN of_IN splitting_NN complex_JJ predictors_NNS such_JJ a_DT multi-attribute_JJ ones_NNS is_VBZ faced_VBN through_IN the_DT use_NN of_IN Genetic_JJ Algorithms_NNP ._. In_IN addition_NN ,_, the_DT possibility_NN of_IN growing_VBG “optimal”_JJ exploratory_NN trees_NNS is_VBZ also_RB investigated_VBN by_IN making_VBG use_NN of_IN Ant_NNP Colony_NNP Optimization_NN (ACO_NN )_-RRB- algorithm_NN ._. Finally_RB ,_, the_DT derivation_NN of_IN a_DT subset_NN of_IN decision_NN trees_NNS for_IN modelling_VBG multi-attribute_JJ response_NN on_IN the_DT basis_NN of_IN a_DT data-driven_JJ heuristic_NN is_VBZ also_RB described_VBN ._. The_DT proposed_VBN approaches_NNS might_MD be_VB useful_JJ for_IN knowledge_NN extraction_NN from_IN large_JJ databases_NNS as_RB well_RB as_IN for_IN data_NNS mining_NN applications_NNS ._. The_DT solution_NN they_PRP offer_VBP for_IN complicated_VBN data_NNS modelling_JJ and_CC data_NNS analysis_NN problems_NNS might_MD be_VB considered_VBN for_IN a_DT possible_JJ implementation_NN in_IN a_DT Decision_NNP Support_NNP System_NNP (_-LRB- DSS)_NN ._. The_DT remainder_NN of_IN the_DT chapter_NN is_VBZ as_IN follows_VBZ ._. Section_NN 2_CD describes_VBZ the_DT main_JJ features_NNS and_CC the_DT recent_JJ developments_NNS of_IN Decision_NNP Tree_NNP Induction_NNP ._. An_DT overview_NN of_IN Combinatorial_NNP Optimization_NNP with_IN a_DT particular_JJ focus_NN on_IN Genetic_JJ Algorithms_NNP and_CC Ant_NNP Colony_NNP Optimization_NNP is_VBZ presented_VBN in_IN section_NN 3._VBD The_DT use_NN of_IN these_DT two_CD algorithms_NNS within_IN the_DT Decision_NNP Tree_NNP Induction_NNP Framework_NNP is_VBZ described_VBN in_IN section_NN 4_CD ,_, together_RB with_IN the_DT description_NN of_IN the_DT algorithm_NN for_IN modelling_VBG multi-attribute_JJ response_NN ._. Section_NN 5_CD summarizes_VBZ the_DT results_NNS of_IN the_DT proposed_VBN O_UH pe_VBD n_RB Ac_NNP ce_NN ss_NN D_NNP at_IN ab_JJ as_IN e_NN w_VBD w_WRB w_JJ .i-_. te_JJ ch_NN on_IN lin_NN e_NN ._. co_NN m_NN Source_NN :_: Advances_NNS in_IN Evolutionary_NNP Algorithms_NNP ,_, Book_NNP edited_VBD by_IN :_: Witold_NNP Kosiński_NNP ,_, ISBN_NNP 978-953-7619-11-4_CD ,_, pp_RP ._. 468_CD ,_, November_NNP 2008_CD ,_, I-Tech_NNP Education_NNP and_CC Publishing_NNP ,_, Vienna_NNP ,_, Austria_NNP www.intechopen.com_NN Advances_NNS in_IN Evolutionary_JJ Algorithms_NNP 444_CD method_NN on_IN real_JJ and_CC simulated_JJ datasets_NNS ._. Concluding_NNP remarks_NNS are_VBP presented_VBN in_IN section_NN 6_CD ._. The_DT chapter_NN also_RB includes_VBZ an_DT appendix_NN that_WDT presents_VBZ J-Fast_JJ ,_, a_DT Java-based_JJ software_NN for_IN Decision_NNP Tree_NNP that_WDT currently_RB implements_VBZ Genetic_JJ Algorithms_NNP and_CC Ant_NNP Colony_NNP Optimization_NNP ._. 2._'' Decision_IN tree_NN induction_NN Decision_NNP Tree_NNP Induction_NN (DTI_NNP )_-RRB- is_VBZ a_DT tool_NN to_TO induce_VB a_DT classification_NN or_CC regression_NN model_NN from_IN (usually_RB large_JJ )_-RRB- datasets_NNS characterized_VBN by_IN N_NNP observations_NNS (_-LRB- records_NNS )_-RRB- ,_, each_DT one_CD containing_VBG a_DT set_NN x_NN of_IN numerical_JJ or_CC nominal_JJ variables_NNS ,_, and_CC a_DT variable_JJ y_NN ._. Statisticians_NNPS use_VBP the_DT terms_NNS “splitting_VBG predictors_NNS ”_VBP to_TO identify_VB x_NN and_CC “response_NN variable_JJ ”_NN for_IN y_NN ._. DTI_NNP builds_VBZ a_DT model_NN that_IN summarizes_NNS the_DT underlying_VBG relationships_NNS between_IN x_NN and_CC y_NN ._. Actually_RB ,_, two_CD kinds_NNS of_IN model_NN can_MD be_VB estimated_VBN using_VBG decision_NN trees_NNS :_: classification_NN trees_NNS if_IN y_RB is_VBZ nominal_JJ ,_, and_CC regression_NN trees_NNS if_IN y_PRP is_VBZ numerical_JJ ._. Hereinafter_IN we_PRP refer_VBP to_TO classification_NN trees_NNS to_TO show_VB the_DT main_JJ features_NNS of_IN DTI_NNP and_CC briefly_NN recall_VBP the_DT main_JJ characteristics_NNS of_IN regression_NN trees_NNS at_IN the_DT end_NN of_IN the_DT section_NN ._. DTI_NNP proceeds_NNS by_IN inducing_VBG a_DT series_NN of_IN follow-up_JJ (usually_NN binary_NN )_-RRB- questions_NNS about_IN the_DT attributes_NNS of_IN an_DT unknown_JJ observation_NN until_IN a_DT conclusion_NN about_IN what_WP is_VBZ its_PRP$ most_RBS likely_JJ class_NN label_NN is_VBZ reached_VBN ._. Questions_NNS and_CC their_PRP$ alternative_JJ answers_NNS can_MD be_VB represented_VBN hierarchically_RB in_IN the_DT form_NN of_IN a_DT decision_NN tree_NN ._. It_PRP contains_VBZ a_DT root_NN node_NN and_CC some_DT internal_JJ and_CC terminal_JJ nodes_NNS ._. The_DT root_NN node_NN and_CC the_DT internal_JJ ones_NNS are_VBP used_VBN to_TO partition_NN observations_NNS of_IN the_DT dataset_NN into_IN smaller_JJR subsets_NNS of_IN relatively_RB homogeneous_JJ classes_NNS ._. To_TO classify_VB a_DT previously_RB unlabelled_JJ observation_NN ,_, say_VBP i*_FW (_-LRB- i*=1_NN ,…..,N)_NN ,_, we_PRP start_VBP from_IN the_DT test_NN condition_NN in_IN the_DT root_NN node_NN and_CC follow_VB the_DT appropriate_JJ pattern_NN based_VBN on_IN the_DT outcome_NN of_IN the_DT test_NN ._. When_WRB an_DT internal_JJ node_NN is_VBZ reached_VBN a_DT new_JJ test_NN condition_NN is_VBZ applied_VBN ,_, and_CC so_RB on_IN down_IN to_TO a_DT terminal_NN node_NN ._. Encountering_'' a_DT terminal_NN node_NN ,_, the_DT modal_JJ class_NN of_IN the_DT observations_NNS in_IN that_DT node_NN is_VBZ the_DT class_NN label_NN of_IN y_NN assigned_VBN to_TO the_DT (_-LRB- previously_RB )_-RRB- unlabeled_JJ observation_NN ._. For_IN regression_NN trees_NNS ,_, the_DT assigned_VBN class_NN is_VBZ the_DT mean_NN of_IN y_NN for_IN the_DT observations_NNS belonging_VBG to_TO that_DT terminal_NN node_NN ._. Because_IN of_IN their_PRP$ top-down_JJ binary_JJ splitting_JJ approach_NN ,_, decision_NN trees_NNS can_MD easily_RB be_VB converted_VBN into_IN IF-THEN_JJ rules_NNS and_CC used_VBD for_IN decision_NN making_NN purposes_NNS ._. DTI_NNP is_VBZ useful_JJ for_IN knowledge_NN extraction_NN from_IN large_JJ databases_NNS and_CC data_NNS mining_NN applications_NNS because_IN of_IN the_DT possibility_NN to_TO represent_VB functions_NNS of_IN numerical_JJ and_CC nominal_JJ variables_NNS as_RB well_RB as_IN of_IN its_PRP$ feasibility_NN ,_, predictive_JJ ability_NN and_CC interpretability_NN ._. It_PRP can_MD effectively_RB handle_VB missing_VBG values_NNS and_CC noisy_JJ data_NNS and_CC can_MD be_VB used_VBN either_RB as_IN an_DT explanatory_JJ tool_NN for_IN distinguishing_JJ observations_NNS of_IN different_JJ classes_NNS or_CC as_IN a_DT prediction_NN tool_NN to_TO class_NN labels_NNS of_IN previously_RB unseen_JJ observations_NNS ._. Some_DT of_IN the_DT well-known_JJ DTI_JJ algorithms_NNS include_VBP ID3_DT (_-LRB- Quinlan_NNP ,_, 1983_CD )_-RRB- ,_, CART_NNP (_-LRB- Breiman_NNP et_NNP al_NN ._. ,_, 1984_CD )_-RRB- ,_, C4.5_FW (_-LRB- Quinlan_NNP ,_, 1993_CD )_-RRB- ,_, SLIQ_NNP (_-LRB- Metha_NNP et_NNP al_NN ._. ,_, 1996_CD )_-RRB- ,_, FAST_NNP (_-LRB- Mola_NNP &_CC Siciliano_NNP ,_, 1997_CD )_-RRB- and_CC GUIDE_NNP (_-LRB- Loh_NNP ,_, 2002_CD )_-RRB- ._. All_PDT these_DT algorithms_NNS use_VBP a_DT greedy_JJ ,_, top-down_JJ recursive_JJ partitioning_NN approach_NN ._. They_PRP primarily_RB differ_VBP in_IN terms_NNS of_IN the_DT splitting_JJ criteria_NNS ,_, the_DT type_NN of_IN splits_NNS (2-way_JJ or_CC multi-way_JJ )_-RRB- and_CC the_DT handling_NN of_IN the_DT overfitting_JJ problem_NN ._. DTI_NNP uses_VBZ a_DT greedy_JJ ,_, top-down_JJ recursive_JJ partitioning_NN approach_NN to_TO induce_VB a_DT decision_NN tree_NN from_IN data_NNS ._. In_IN general_JJ ,_, DTI_NNP involves_VBZ the_DT following_VBG tasks_NNS :_: decision_NN tree_NN growing_VBG and_CC decision_NN tree_NN pruning_NN ._. 2.1_CD Tree_NNP growing_VBG As_IN for_IN the_DT growing_VBG of_IN a_DT decision_NN tree_NN ,_, DTI_NNP use_NN a_DT greedy_JJ heuristic_JJ to_TO make_VB a_DT series_NN of_IN locally_RB optimum_JJ decisions_NNS about_IN which_WDT value_NN of_IN a_DT splitting_JJ predictor_NN to_TO use_VB for_IN data_NNS partitioning_NN ._. A_DT www.intechopen.com_NN arsencihuy@gmail.com_NN Highlight_NNP arsencihuy@gmail.com_NN Highlight_NNP Evolutionary_NNP Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NNP 445_CD test_NN condition_NN depending_VBG on_IN a_DT splitting_JJ method_NN is_VBZ applied_VBN to_TO partition_VB the_DT data_NNS into_IN more_JJR homogeneous_JJ subgroups_NNS at_IN each_DT step_NN of_IN the_DT greedy_JJ algorithm_NN ._. Splitting_VBG methods_NNS differ_VBP with_IN respect_NN to_TO the_DT type_NN of_IN splitting_JJ predictor_NN :_: for_IN nominal_JJ splitting_NN predictors_NNS the_DT test_NN condition_NN is_VBZ expressed_VBN as_IN a_DT question_NN about_IN one_CD or_CC more_JJR of_IN its_PRP$ attributes_NNS ,_, whose_WP$ outcomes_NNS are_VBP “Yes_NNS ”/”_IN No”_NNP ._. Grouping_NNP of_IN splitting_JJ predictor_NN attributes_NNS is_VBZ required_VBN for_IN algorithms_NNS using_VBG 2-way_JJ splits_NNS ._. For_IN ordinal_JJ or_CC continuous_JJ splitting_NN predictors_VBZ the_DT test_NN condition_NN is_VBZ expressed_VBN on_IN the_DT basis_NN of_IN a_DT threshold_NN value_NN υ_, such_JJ as_IN (_-LRB- xi_NN ≤_NN υ_NN ?_. )_-RRB- or_CC (_-LRB- xi_NN >_NN υ_NN ?_. )_-RRB- ._. By_IN considering_VBG all_PDT the_DT possible_JJ split_NN points_NNS υ_RB ,_, the_DT best_JJS one_NN υ*_NN partitioning_VBG the_DT instances_NNS into_IN homogeneous_JJ subgroups_NNS is_VBZ selected_VBN ._. In_IN the_DT classification_NN problem_NN ,_, the_DT sample_NN population_NN consists_VBZ of_IN N_NNP observations_NNS deriving_VBG from_IN C_NNP response_NN classes_NNS ._. A_DT decision_NN tree_NN (_-LRB- or_CC classifier_NN )_-RRB- will_MD break_VB these_DT observations_NNS into_IN k_NN terminal_NN groups_NNS ,_, and_CC to_TO each_DT of_IN these_DT a_DT predicted_VBD class_NN (_-LRB- being_VBG one_CD of_IN the_DT possible_JJ attributes_NNS of_IN the_DT response_NN variable_JJ )_-RRB- is_VBZ assigned_VBN ._. In_IN actual_JJ application_NN ,_, most_JJS parameters_NNS are_VBP estimated_VBN from_IN the_DT data_NN ._. In_IN fact_NN ,_, denoting_VBG with_IN t_NN some_DT node_NN of_IN the_DT tree_NN (_-LRB- t_NN represents_VBZ both_DT a_DT set_NN of_IN individuals_NNS in_IN the_DT sample_NN data_NN and_CC ,_, via_IN the_DT tree_NN that_WDT produced_VBD it_PRP ,_, a_DT classification_NN rule_NN for_IN future_JJ data_NNS )_-RRB- from_IN the_DT binary_JJ tree_NN it_PRP is_VBZ possible_JJ to_TO estimate_VB P(t_NNP )_-RRB- and_CC P(_JJ i|t_NN )_-RRB- for_IN future_JJ observations_NNS as_IN follows_VBZ :_: (_-LRB- )_-RRB- (_-LRB- )_-RRB- {_NN }_JJ (_-LRB- )_-RRB- 1_CD 1_CD C_NNP C_NNP i_IN i_IN iA_DT ii_NNS i_IN P_NNP t_NN P_NNP x_NN t_NN x_NN i_VBD n_RB nπ_JJ τ_NN π_NN =_SYM =_SYM =_SYM ∈_VBN =_SYM ≈_VBN ∑_NN ∑_NN (_-LRB- 1_CD )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- {_NN }_JJ (_-LRB- )_-RRB- {_NN }_NN {_NN }_NN (_-LRB- )_-RRB- (_-LRB- )_-RRB- 1_CD C_NNP i_NN i_IN it_PRP i_VBZ i_IN it_PRP ii_VBZ P_NNP i_FW t_NN P_NNP x_NN i_IN x_NN t_NN P_NNP x_NN t_NN x_NN i_IN P_NNP x_NN t_VBD n_RB n_RB n_RB nτ_VB π_DT τ_JJ π_NN π=_NN =_SYM =_SYM ∈_VBN =_SYM ∈_VBN =_SYM ∈_VBN ≈_NN ∑_NN (_-LRB- 2_CD )_-RRB- where_WRB πi_NNP is_VBZ the_DT prior_JJ probability_NN of_IN each_DT class_NN i_FW (_-LRB- i_NN ∈_NN 1,2_CD ,….,C)_NNP ,_, τ(_JJ x_NN )_-RRB- is_VBZ the_DT true_JJ class_NN of_IN an_DT observation_NN xi_NN (_-LRB- x_NN is_VBZ the_DT vector_NN of_IN predictor_NN variables_NNS )_-RRB- ,_, ni_JJ and_CC nt_JJ are_VBP the_DT number_NN of_IN observations_NNS in_IN the_DT sample_NN that_IN respectively_RB are_VBP class_NN i_NN and_CC node_NN t_NN ,_, and_CC nit_NN is_VBZ the_DT number_NN of_IN observations_NNS in_IN the_DT sample_NN that_WDT are_VBP class_NN i_NN and_CC node_NN t_NN ._. In_IN addition_NN ,_, by_IN denoting_VBG with_IN R_NN the_DT risk_NN of_IN misclassification_NN ,_, the_DT risk_NN of_IN t_NN (_-LRB- denoted_VBN with_IN R(t_JJ )_-RRB- )_-RRB- and_CC the_DT risk_NN of_IN a_DT model_NN (_-LRB- or_CC tree_NN )_-RRB- T_NNP (_-LRB- denoted_VBN with_IN R(_JJ T)_NN )_-RRB- are_VBP measured_VBN as_IN follows_VBZ :_: (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- 1_CD ,_, C_NNP i_CC R_NN t_NN P_NNP i_IN t_NN L_NNP i_IN tτ==_NN ∑_NN (_-LRB- 3_CD )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- 1_CD k_NN j_NN jj_NN R_NN T_NNP P_NNP t_NN R_NN t==_NN ∑_NN (_-LRB- 4_CD )_-RRB- where_WRB L(i_JJ ,j_NN )_-RRB- is_VBZ the_DT loss_NN matrix_NN for_IN incorrectly_RB classifying_VBG an_DT i_NN as_IN a_DT j_NN (_-LRB- with_IN L(i_JJ ,i)=0_NN )_-RRB- ,_, and_CC τ(_JJ t_NN )_-RRB- is_VBZ the_DT class_NN assigned_VBN to_TO t_VB once_RB that_IN t_NN is_VBZ a_DT terminal_NN node_NN and_CC τ(_JJ t_NN )_-RRB- is_VBZ chosen_VBN to_TO minimize_VB R(t_NN )_-RRB- and_CC tj_NN are_VBP terminal_JJ nodes_NNS of_IN the_DT tree_NN T._NNP If_IN L(i_NNP ,i)=1_VBD for_IN all_DT i≠j_NN ,_, and_CC the_DT prior_JJ probabilities_NNS τ_, are_VBP set_VBN to_TO be_VB equal_JJ to_TO the_DT observed_JJ class_NN frequencies_NNS in_IN the_DT sample_NN ,_, then_RB P(_NNP i|t_NN )=nit/nt_NN and_CC R(_JJ T_NNP )_-RRB- is_VBZ the_DT proportion_NN of_IN misclassified_JJ observations_NNS ._. When_WRB splitting_VBG a_DT node_NN t_NN into_IN tr_NN and_CC tl_NN (_-LRB- left_VBD and_CC right_JJ sons_NNS )_-RRB- ,_, the_DT following_VBG relationship_NN holds_VBZ :_: P(tl_NN )_-RRB- R(tl_NN )_-RRB- +_NN P(tr_NN )_-RRB- R(tr_NN )_-RRB- ≤_NN P(t_NN )_-RRB- R(t_NN )_-RRB- ._. An_DT obvious_JJ way_NN to_TO build_VB a_DT tree_NN is_VBZ to_TO chose_VBD that_DT split_NN maximizing_VBG ΔR_NNP ,_, i_IN .e_NN ._. ,_, the_DT decrease_NN in_IN risk_NN ._. To_TO this_DT aim_NN ,_, several_JJ measures_NNS of_IN impurity_NN (_-LRB- or_CC diversity_NN )_-RRB- of_IN a_DT node_NN are_VBP used_VBN ._. Denoting_VBG with_IN f_NN some_DT impurity_NN function_NN ,_, the_DT local_JJ impurity_NN of_IN a_DT node_NN t_NN is_VBZ defined_VBN as_IN :_: www.intechopen.com_NN Advances_NNS in_IN Evolutionary_JJ Algorithms_NNP 446_CD (_-LRB- )_-RRB- (_-LRB- )_-RRB- 1_CD C_NNP iti_, t_IN f_NN pε_NN ==_NN ∑_NN (_-LRB- 5_CD )_-RRB- where_WRB pit_NN is_VBZ the_DT proportion_NN of_IN those_DT in_IN t_NN that_IN belong_VBP to_TO class_NN i_NN for_IN future_JJ samples_NNS ._. Since_IN ε(_VBG t_NN )=0_IN when_WRB t_NN is_VBZ pure_JJ ,_, f_NN must_MD be_VB concave_JJ with_IN f(_JJ 0_CD )=f(_NNS 1_CD )=0_CD ._. Two_CD candidates_NNS for_IN f_NN are_VBP the_DT information_NN index_NN f(_NN p_NN )_-RRB- =_SYM -p_JJ log(_JJ p_NN )_-RRB- and_CC the_DT Gini_NNP index_NN f(_NN p_NN )_-RRB- =_SYM -p(1-p)_JJ ,_, that_IN slightly_RB differ_VB for_IN the_DT two_CD class_NN problem_NN where_WRB nearly_RB always_RB choose_VBP the_DT same_JJ split_NN point_NN ._. Once_RB that_IN f_NN has_VBZ been_VBN chosen_VBN ,_, the_DT split_NN maximizing_VBG the_DT impurity_NN reduction_NN is_VBZ :_: (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )l_NN l_JJ r_NN rp_JJ t_NN t_NN p_NN t_NN t_NN p_NN t_NN tε_IN ε_JJ ε_NN εΔ_NN =_SYM −_FW −_FW (_-LRB- 6_CD )_-RRB- Data_NNP partitioning_NN proceeds_NNS recursively_RB until_IN a_DT stopping_NN rule_NN is_VBZ satisfied_VBN :_: this_DT usually_RB happens_VBZ when_WRB the_DT number_NN of_IN observations_NNS in_IN a_DT node_NN is_VBZ lower_JJR than_IN a_DT previously-specified_JJ minimum_NN number_NN necessary_JJ for_IN splitting_JJ ,_, as_RB well_RB as_IN when_WRB the_DT same_JJ observations_NNS belong_VBP to_TO the_DT same_JJ class_NN or_CC have_VBP the_DT same_JJ response_NN class_NN ._. 2.2_CD FAST_NNP splitting_NN algorithm_IN The_DT goodness_NN of_IN split_NN criterion_NN based_VBN on_IN (_-LRB- 6_CD )_-RRB- expresses_VBZ in_IN different_JJ way_NN some_DT equivalent_JJ criteria_NNS which_WDT are_VBP present_JJ in_IN most_JJS of_IN the_DT tree-growing_NN procedures_NNS implemented_VBN in_IN specialized_JJ software_NN ;_: such_JJ as_IN ,_, for_IN instance_NN ,_, CART_NNP (_-LRB- Breiman_NNP et_NNP al_NN ._. ,_, 1984_CD )_-RRB- ,_, ID3_NNP and_CC C4.5_NNP (_-LRB- Quinlan_NNP ,_, 1993_CD )_-RRB- ._. In_IN many_JJ situations_NNS the_DT computational_JJ time_NN required_VBN by_IN a_DT recursive_JJ partitioning_NN algorithm_NN is_VBZ an_DT important_JJ issue_NN that_WDT can_MD not_RB be_VB neglected_VBN ._. In_IN this_DT respect_NN ,_, a_DT fast_JJ algorithm_NN is_VBZ required_VBN to_TO speed_VB up_RP the_DT procedure_NN ._. In_IN view_NN of_IN that_DT ,_, it_PRP is_VBZ worth_JJ considering_VBG a_DT two-stage_JJ splitting_NN criterion_NN which_WDT takes_VBZ into_IN account_NN of_IN the_DT global_JJ role_NN played_VBD by_IN a_DT splitting_JJ predictor_NN in_IN the_DT partitioning_NN step_NN ._. A_DT global_JJ impurity_NN reduction_NN factor_NN of_IN any_DT predictor_NN xi_NN is_VBZ defined_VBN as_IN :_: (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- |_NN |_NN |_NN s_VBZ s_PRP y_NN x_NN y_RB g_VBG g_VBG G_NNP t_NN t_NN p_NN g_VBG tε∈Ε_NN =_SYM ∑_FW (_-LRB- 7_CD )_-RRB- where_WRB εy|g(_JJ t_NN )_-RRB- is_VBZ the_DT impurity_NN of_IN the_DT conditional_JJ distribution_NN of_IN y_NN given_VBN the_DT s-th_JJ attribute_NN of_IN xs_JJ and_CC G_NNP is_VBZ the_DT number_NN of_IN attributes_NNS of_IN xs_NNS (_-LRB- g_VBG ε_JJ G_NNP )_-RRB- ._. The_DT two-stage_JJ criterion_NN finds_VBZ the_DT best_JJS splitting_NN predictor(_NN s_VBZ )_-RRB- as_IN the_DT one_CD (_-LRB- or_CC those_DT )_-RRB- minimizing_VBG (_-LRB- 7_CD )_-RRB- and_CC ,_, consequently_RB ,_, the_DT best_JJS split_NN point_NN among_IN the_DT candidate_NN splits_VBZ induced_VBN by_IN the_DT best_JJS predictor(_NN s_VBZ )_-RRB- minimizing_VBG the_DT (_-LRB- 6_CD )_-RRB- by_IN taking_VBG account_NN only_RB the_DT partitions_NNS or_CC splits_NNS generated_VBN by_IN the_DT best_JJS predictor_NN ._. This_DT criterion_NN can_MD be_VB applied_VBN either_CC sic_JJ et_FW simpliciter_FW or_CC by_IN considering_VBG alternative_JJ modelling_JJ strategies_NNS in_IN the_DT predictor_NN selection_NN (_-LRB- an_DT overview_NN of_IN the_DT two-stage_JJ methodology_NN can_MD be_VB found_VBN in_IN Siciliano_NNP &_CC Mola_NNP ,_, 2000_CD )_-RRB- ._. The_DT FAST_NNP splitting_NN algorithm_NN (_-LRB- Mola_NNP &_CC Siciliano_NNP ,_, 1997_CD )_-RRB- can_MD be_VB applied_VBN when_WRB the_DT following_JJ property_NN holds_VBZ for_IN the_DT impurity_NN measure_NN :_: (_-LRB- )_-RRB- (_-LRB- )_-RRB- |_NN |_NN ;_: s_PRP y_RB x_NN y_RB ht_VBD t_NN h_NN g_VBG h_NN GΕ_NNP ≤_NNP Ε_NNP ∀_NNP ≠_NN ∈_NN (_-LRB- 8_CD )_-RRB- and_CC it_PRP consists_VBZ of_IN two_CD basic_JJ rules_NNS :_: •_NNS iterate_VBP the_DT two-stage_JJ partitioning_NN criterion_NN by_IN using_VBG (_-LRB- 7_CD )_-RRB- and_CC (_-LRB- 6_CD )_-RRB- :_: select_VB one_CD splitting_JJ predictor_NN at_IN a_DT time_NN and_CC consider_VB ,_, at_IN each_DT time_NN ,_, the_DT previously_RB unselected_JJ splitting_NN predictors_NNS ;_: www.intechopen.com_IN Evolutionary_NNP Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NNP 447_CD •_TO stop_VB the_DT iterations_NNS when_WRB the_DT current_JJ best_JJS predictor_NN in_IN the_DT order_NN x(_JJ k_NN )_-RRB- at_IN iteration_NN k_NN does_VBZ not_RB satisfy_VB the_DT condition_NN (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )*_NN 1|_JJ |k_NN ky_JJ x_NN y_RB ht_VBD t−Ε_DT ≤_JJ Ε_NN ,_, where_WRB s*(k−1_NN )_-RRB- is_VBZ the_DT best_JJS partition_NN at_IN the_DT iteration_NN (k_NN −_NN 1_CD )_-RRB- ._. The_DT algorithm_NN finds_VBZ the_DT optimal_JJ split_NN with_IN substantial_JJ time_NN savings_NNS in_IN terms_NNS of_IN the_DT reduced_JJ number_NN of_IN partitions_NNS or_CC splits_VBZ to_TO be_VB tried_VBN out_RP at_IN each_DT node_NN of_IN the_DT tree_NN ._. Simulation_NNP studies_NNS show_VBP that_IN the_DT relative_JJ reduction_NN in_IN the_DT average_JJ number_NN of_IN splits_NNS analyzed_VBN by_IN the_DT FAST_NNP algorithm_NN with_IN respect_NN to_TO the_DT standard_JJ approaches_NNS in_IN binary_JJ trees_NNS increases_NNS as_IN a_DT function_NN of_IN both_DT the_DT number_NN of_IN attributes_NNS of_IN the_DT splitting_JJ predictor_NN and_CC of_IN the_DT number_NN of_IN observations_NNS at_IN a_DT given_VBN node_NN ._. Further_RBR theoretical_JJ results_NNS about_IN the_DT computational_JJ efficiency_NN of_IN FAST-like_JJ algorithms_NNS can_MD be_VB found_VBN in_IN Klaschka_NNP et_NNP al_NN ._. (_-LRB- 1998_CD )_-RRB- ._. 2.3_CD Tree_NNP pruning_NN As_IN for_IN the_DT pruning_JJ step_NN ,_, it_PRP is_VBZ usually_RB required_VBN in_IN DTI_NNP in_IN order_NN to_TO control_VB for_IN the_DT size_NN of_IN the_DT induced_JJ model_NN and_CC to_TO avoid_VB in_IN this_DT way_NN data_NNS overfitting_VBG ._. Typically_RB ,_, data_NNS is_VBZ partitioned_VBN into_IN a_DT training_NN set_NN (_-LRB- containing_VBG two-third_JJ of_IN the_DT data_NNS )_-RRB- and_CC a_DT test_NN set_NN (_-LRB- with_IN the_DT remaining_VBG one-third_NN )_-RRB- ._. Training_NNP set_VBD contains_VBZ labelled_JJ observations_NNS and_CC it_PRP is_VBZ used_VBN for_IN the_DT tree_NN growing_VBG ._. It_PRP is_VBZ assumed_VBN that_IN the_DT test_NN set_NN contains_VBZ unlabelled_JJ observations_NNS and_CC it_PRP is_VBZ used_VBN for_IN selecting_VBG the_DT final_JJ decision_NN tree_NN :_: to_TO check_VB whether_IN a_DT decision_NN tree_NN ,_, say_VBP T_NNP ,_, is_VBZ generalizable_JJ ,_, it_PRP is_VBZ necessary_JJ to_TO evaluate_VB its_PRP$ performance_NN on_IN the_DT test_NN set_NN in_IN terms_NNS of_IN misclassification_NN error_NN by_IN comparing_VBG the_DT true_JJ class_NN labels_NNS of_IN the_DT test_NN data_NNS against_IN those_DT predicted_VBN by_IN T._NNP Reduced-size_NNP trees_NNS perform_VBP poorly_RB on_IN both_DT training_NN and_CC test_NN sets_NNS causing_VBG underfitting_JJ ._. Instead_RB ,_, increasing_VBG the_DT size_NN of_IN T_NNP improves_VBZ both_DT the_DT training_NN and_CC test_NN errors_NNS up_IN to_TO a_DT “critical_JJ size_NN ”_NN from_IN which_WDT the_DT test_NN errors_NNS increase_NN even_RB though_IN the_DT corresponding_JJ training_NN errors_NNS decrease_NN ._. This_DT means_VBZ that_IN T_NNP overfits_IN the_DT data_NNS and_CC cannot_MD be_VB generalized_VBN to_TO class_NN prediction_NN of_IN unseen_JJ observations_NNS ._. In_IN the_DT machine_NN learning_VBG framework_NN ,_, the_DT training_NN error_NN is_VBZ named_VBN resubstitution_NN error_NN and_CC the_DT test_NN error_NN is_VBZ known_VBN as_IN the_DT generalization_NN error_NN ._. It_PRP is_VBZ possible_JJ to_TO prevent_VB overfitting_JJ by_IN haltering_VBG the_DT tree_NN growing_VBG before_IN it_PRP becomes_VBZ too_RB complex_JJ (_-LRB- pre-pruning_JJ )_-RRB- ._. In_IN this_DT framework_NN ,_, one_NN can_MD assume_VB the_DT training_NN data_NNS is_VBZ a_DT good_JJ representation_NN of_IN the_DT overall_JJ data_NNS and_CC use_VB the_DT resubstitution_NN error_NN as_IN an_DT optimistic_JJ estimate_NN of_IN the_DT error_NN of_IN the_DT final_JJ DTI_NN model_NN (_-LRB- optimistic_JJ approach_NN )_-RRB- ._. Alternatively_RB ,_, Quinlan_NNP (_-LRB- 1987_CD )_-RRB- proposed_VBD a_DT pessimistic_JJ approach_NN that_WDT penalizes_VBZ complicated_VBN models_NNS by_IN assigning_VBG a_DT cost_NN penalty_NN to_TO each_DT terminal_NN node_NN of_IN the_DT decision_NN tree_NN :_: for_IN C4.5_NNP ,_, the_DT generalization_NN error_NN is_VBZ R(t_JJ )/nt+ε_NN ,_, where_WRB ,_, for_IN a_DT node_NN t_NN ,_, nt_NN is_VBZ the_DT number_NN of_IN observations_NNS and_CC R(t_NN )_-RRB- is_VBZ the_DT misclassification_NN error_NN ._. It_PRP is_VBZ assumed_VBN that_IN R(t_NNP )_-RRB- follows_VBZ a_DT Binomial_JJ distribution_NN and_CC that_DT ε_NN is_VBZ the_DT upper_JJ bound_JJ for_IN R(t_JJ )_-RRB- computed_VBN from_IN such_JJ a_DT distribution_NN (_-LRB- Quinlan_NNP ,_, 1993_CD )_-RRB- ._. An_DT alternative_NN pruning_NN strategy_NN is_VBZ based_VBN on_IN the_DT growing_VBG of_IN the_DT entire_JJ tree_NN and_CC the_DT subsequent_JJ retrospective_JJ trimming_VBG of_IN some_DT of_IN its_PRP$ internal_JJ nodes_NNS (_-LRB- post-pruning_NN )_-RRB- :_: the_DT subtree_JJ departing_VBG from_IN each_DT internal_JJ node_NN is_VBZ replaced_VBN with_IN a_DT new_JJ terminal_NN node_NN whose_WP$ class_NN label_NN derives_NNS from_IN the_DT majority_NN class_NN of_IN observations_NNS belonging_VBG to_TO that_DT subtree_NN ._. The_DT latter_NN is_VBZ definitively_RB replaced_VBN by_IN the_DT terminal_NN node_NN if_IN such_JJ a_DT replacement_NN induces_VBZ an_DT improvement_NN of_IN the_DT generalization_NN error_NN ._. Pruning_NN stops_VBZ when_WRB no_DT further_JJ improvements_NNS can_MD be_VB achieved_VBN ._. The_DT generalization_NN error_NN can_MD be_VB estimated_VBN through_IN either_CC the_DT optimistic_JJ or_CC pessimistic_JJ approaches_NNS ._. Other_JJ post-pruning_JJ algorithms_NNS ,_, such_JJ as_IN CART_NNP ,_, use_VBP a_DT complexity_NN measure_NN that_WDT accounts_VBZ for_IN both_DT the_DT tree_NN size_NN and_CC the_DT generalization_NN error_NN ._. Once_RB the_DT entire_JJ tree_NN is_VBZ grown_VBN using_VBG training_NN www.intechopen.com_NN Advances_NNS in_IN Evolutionary_NNP Algorithms_NNP 448_CD observations_NNS ,_, a_DT penalty_NN parameter_NN expressing_VBG the_DT gain/cost_NN trade_NN off_IN for_IN trimming_VBG each_DT subtree_NN is_VBZ used_VBN to_TO generate_VB a_DT sequence_NN of_IN pruned_JJ trees_NNS ,_, and_CC the_DT tree_NN in_IN the_DT sequence_NN presenting_VBG the_DT lowest_JJS generalization_NN error_NN (0-SE_JJ rule_NN )_-RRB- or_CC the_DT one_CD with_IN a_DT generalization_NN error_NN within_IN one_CD standard_JJ error_NN of_IN its_PRP$ minimum_NN (1-SE_JJ rule_NN )_-RRB- is_VBZ selected_VBN ._. Let_VB α_CC be_VB a_DT number_NN in_IN [0_CD ,+∞]_NN ,_, called_VBN complexity_NN parameter_NN ,_, measuring_VBG the_DT “cost_NN ”_NN of_IN adding_VBG another_DT variable_JJ to_TO the_DT model_NN ._. Let_VB R(_JJ T0_IN )_-RRB- be_VB the_DT risk_NN for_IN the_DT zero_CD split_NN tree_NN ._. Define_NN :_: (_-LRB- )_-RRB- (_-LRB- )R_NN T_NNP R_NN T_NNP Tα_NNP α_NNP =_SYM +_FW (_-LRB- 9_CD )_-RRB- to_TO be_VB the_DT cost_NN for_IN the_DT tree_NN ,_, and_CC define_VB Tα_NNS to_TO be_VB that_DT subtree_NN of_IN the_DT entire_NN tree_NN having_VBG the_DT minimal_JJ cost_NN ._. Obviously_RB ,_, T0_PRP is_VBZ the_DT entire_JJ tree_NN and_CC T∞_NNP is_VBZ the_DT zero_CD splits_VBZ model_NN ._. The_DT idea_NN is_VBZ to_TO find_VB ,_, for_IN each_DT α_NN ,_, the_DT subtree_JJ Tα_NNP ⊆_NNP T0_. minimizing_VBG Rα(_JJ T_NNP )_-RRB- ._. The_DT tuning_NN parameter_NN α_IN ≥_JJ 0_CD governs_NNS the_DT trade_NN off_RP between_IN the_DT tree_NN size_NN and_CC its_PRP$ goodness_NN of_IN fit_NN to_TO the_DT data_NNS ._. Large_JJ values_NNS of_IN α_NNS result_VBP in_IN small_JJ trees_NNS ,_, and_CC conversely_RB for_IN smaller_JJR values_NNS of_IN α_NNP ._. Of_IN course_NN ,_, with_IN α=0_VBG the_DT solution_NN is_VBZ the_DT full_JJ tree_NN T0_NN ._. It_PRP is_VBZ worth_JJ noticing_VBG that_IN ,_, by_IN adaptively_RB choosing_VBG αI_RB ,_, it_PRP exists_VBZ a_DT unique_JJ smallest_JJS subtree_JJ Tα_NN minimizing_VBG Rα(_JJ T_NNP )_-RRB- ._. A_DT weakest_JJS link_NN pruning_VBG approach_NN is_VBZ used_VBN to_TO find_VB Tα_NNP :_: it_PRP consists_VBZ in_IN successively_RB collapsing_VBG the_DT internal_JJ node_NN producing_VBG the_DT smallest_JJS per-node_JJ increase_NN in_IN R(_NNP T)_NNP ,_, continuing_VBG this_DT way_NN until_IN the_DT single-node_NN (_-LRB- root_NN )_-RRB- tree_NN is_VBZ produced_VBN ._. This_DT gives_VBZ a_DT (_-LRB- finite_NN )_-RRB- sequence_NN of_IN subtrees_NNS ,_, and_CC it_PRP is_VBZ easy_JJ to_TO show_VB that_IN this_DT sequence_NN must_MD contains_VBZ Tα_JJ (_-LRB- see_VBP Breiman_NNP et_FW al_NN (_-LRB- 1984_CD )_-RRB- for_IN details_NNS )_-RRB- ._. Usually_RB ,_, pruning_NN algorithms_NNS can_MD be_VB combined_VBN with_IN V-fold_JJ cross-validation_NN when_WRB few_JJ observations_NNS are_VBP available_JJ ._. Training_NNP data_NNS is_VBZ divided_VBN into_IN V_NNP disjoint_NN blocks_NNS and_CC a_DT tree_NN is_VBZ grown_VBN V_NNP times_NNS on_IN V-1_JJ blocks_NNS estimating_VBG the_DT error_NN by_IN testing_VBG the_DT model_NN on_IN the_DT remaining_VBG block_NN ._. In_IN this_DT case_NN ,_, the_DT generalization_NN error_NN is_VBZ the_DT average_JJ error_NN made_VBN for_IN the_DT V_NNP runs_VBZ ._. The_DT estimation_NN of_IN α_NN I_PRP is_VBZ achieved_VBN by_IN V-fold_NNP cross-validation_NN :_: the_DT final_JJ choice_NN is_VBZ the_DT αˆ_NN minimizing_VBG the_DT cross-validated_JJ R(_JJ T_NNP )_-RRB- and_CC the_DT final_JJ tree_NN is_VBZ ˆTα_RB ._. Cappelli_NNP et_NNP al_NN ._. (_-LRB- 2002_CD )_-RRB- improved_VBD this_DT approach_NN introducing_VBG a_DT statistical_JJ testing_NN pruning_NN to_TO achieve_VB the_DT most_RBS reliable_JJ decision_NN rule_NN from_IN a_DT sequence_NN of_IN pruned_JJ trees_NNS ._. 2.4_CD Regression_NN tree_NN In_IN the_DT case_NN the_DT response_NN variable_NN is_VBZ numeric_JJ ,_, the_DT outcome_NN of_IN a_DT recursive_JJ partitioning_NN algorithm_NN is_VBZ regression_NN tree_NN ._. Here_RB ,_, the_DT splitting_JJ criterion_NN is_VBZ SSt-_NNP (_-LRB- SSl_NNP -_: SSr_NN )_-RRB- ,_, where_WRB SSt_NNP is_VBZ the_DT residual_JJ sum_NN of_IN squares_NNS for_IN the_DT parent_NN node_NN ,_, and_CC SSl_NNP and_CC SSr_NNP are_VBP the_DT residual_JJ sum_NN of_IN squares_NNS for_IN the_DT left_NN and_CC right_JJ son_NN ,_, respectively_RB ._. This_DT is_VBZ equivalent_JJ to_TO choosing_VBG the_DT splits_NNS maximizing_VBG the_DT between-groups_NNS sum-of-squares_NNS in_IN a_DT simple_JJ analysis_NN of_IN variance_NN ._. In_IN each_DT terminal_NN node_NN ,_, the_DT mean_JJ value_NN of_IN the_DT response_NN variable_JJ μy_NN of_IN cases_NNS belonging_VBG to_TO that_DT node_NN is_VBZ considered_VBN as_IN the_DT fitted_VBN value_NN whereas_IN the_DT variance_NN is_VBZ considered_VBN as_IN an_DT indicator_NN of_IN the_DT error_NN of_IN a_DT node_NN ._. For_IN a_DT new_JJ observation_NN ynew_IN the_DT prediction_NN error_NN is_VBZ (ynew_JJ -_: μy_NN )_-RRB- ._. In_IN the_DT regression_NN tree_NN case_NN ,_, cost-_NNS complexity_NN pruning_NN is_VBZ applied_VBN with_IN the_DT sum_NN of_IN squares_NNS replacing_VBG the_DT misclassification_NN error_NN ._. 2.5_CD DTI_NNP enhancements_NNS A_DT consolidated_JJ literature_NN about_IN the_DT incorporation_NN of_IN parametric_JJ and_CC nonparametric_JJ models_NNS into_IN trees_NNS appeared_VBN in_IN recent_JJ years_NNS ._. Several_JJ algorithms_NNS have_VBP been_VBN introduced_VBN as_IN hybrid_JJ or_CC functional_JJ trees_NNS (_-LRB- Gama_NNP ,_, 2004_CD )_-RRB- ,_, among_IN the_DT machine_NN learning_VBG community_NN ._. As_IN an_DT example_NN ,_, DTI_NNP is_VBZ used_VBN for_IN regression_NN smoothing_NN purposes_NNS in_IN Conversano_NNP (_-LRB- 2002_CD )_-RRB- :_: a_DT novel_JJ class_NN of_IN www.intechopen.com_NN Evolutionary_NNP Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NNP 449_CD semiparametric_JJ models_NNS named_VBN Generalized_NNP Additive_NNP Multi-Mixture_NNP Models_NNP (_-LRB- GAM-MM)_NNP ._. Other_JJ hybrid_JJ approaches_NNS are_VBP presented_VBN in_IN Chan_NNP and_CC Loh_NNP (_-LRB- 2004_CD )_-RRB- ,_, Su_NNP et_NNP al_NN ._. (_-LRB- 2004_CD )_-RRB- ,_, Choi_NNP et_NNP al_NN ._. (_-LRB- 2005_CD )_-RRB- and_CC Hothorn_NNP et_NNP al_NN ._. (_-LRB- 2006_CD )_-RRB- ._. Nevertheless_RB ,_, relatively_RB simple_JJ procedures_NNS combining_VBG DTI_NNP models_NNS in_IN different_JJ ways_NNS have_VBP been_VBN proposed_VBN in_IN the_DT last_JJ decade_NN in_IN the_DT statistics_NNS and_CC machine_NN learning_NN literature_NN and_CC their_PRP$ effectiveness_NN in_IN improving_VBG the_DT predictive_JJ ability_NN of_IN the_DT traditional_JJ DTI_NNP method_NN has_VBZ been_VBN proven_VBN in_IN different_JJ fields_NNS of_IN application_NN ._. The_DT first_JJ ,_, rather_RB intuitive_JJ ,_, approach_NN is_VBZ Tree_NNP Averaging_NNP ._. It_PRP is_VBZ based_VBN on_IN the_DT generation_NN of_IN a_DT set_NN of_IN candidate_NN trees_NNS and_CC on_IN their_PRP$ subsequent_JJ aggregation_NN in_IN order_NN to_TO improve_VB their_PRP$ generalization_NN ability_NN ._. It_PRP requires_VBZ the_DT definition_NN of_IN a_DT suitable_JJ set_NN of_IN trees_NNS and_CC their_PRP$ associated_JJ weights_NNS and_CC classifies_VBZ a_DT new_JJ observation_NN by_IN averaging_VBG over_IN the_DT set_NN of_IN weighted_JJ trees_NNS (_-LRB- Oliver_NNP and_CC Hand_NNP ,_, 1995_CD )_-RRB- ._. Either_CC a_DT compromise_NN rule_NN or_CC a_DT consensus_NN rule_NN can_MD be_VB used_VBN for_IN averaging_NN ._. An_DT alternative_NN method_NN consists_VBZ in_IN summarizing_VBG the_DT information_NN of_IN each_DT tree_NN in_IN a_DT table_NN cross_NN -_: classifying_NN terminal_NN nodes_VBZ outcomes_NNS with_IN the_DT response_NN classes_NNS in_IN order_NN to_TO assess_VB the_DT generalization_NN ability_NN through_IN a_DT statistical_JJ index_NN and_CC select_VB the_DT tree_NN providing_VBG the_DT maximum_JJ value_NN of_IN such_JJ index_NN (_-LRB- Siciliano_NNP ,_, 1998_CD )_-RRB- ._. Tree_NNP Averaging_NNP is_VBZ very_RB similar_JJ to_TO Ensemble_NNP methods_NNS ._. These_DT are_VBP based_VBN on_IN a_DT weighted_JJ or_CC non_JJ weighted_JJ aggregation_NN of_IN single_JJ trees_NNS (_-LRB- the_DT so_RB called_VBN weak_JJ learners_NNS )_-RRB- in_IN order_NN to_TO improve_VB the_DT overall_JJ generalization_NN error_NN induced_VBN by_IN each_DT single_JJ tree_NN ._. They_PRP are_VBP more_RBR accurate_JJ than_IN a_DT single_JJ tree_NN if_IN they_PRP have_VBP a_DT generalization_NN error_NN that_WDT is_VBZ lower_JJR than_IN random_JJ guessing_NN and_CC if_IN the_DT generalization_NN errors_NNS of_IN the_DT different_JJ trees_NNS are_VBP uncorrelated_JJ (_-LRB- Dietterich_NNP ,_, 2000_CD )_-RRB- ._. A_DT first_JJ example_NN of_IN Ensemble_NNP method_NN is_VBZ Bootstrap_NNP Aggregating_NNP ,_, which_WDT is_VBZ also_RB called_VBN Bagging_NNP (_-LRB- Breiman_NNP ,_, 1996_CD )_-RRB- ._. It_PRP works_VBZ by_IN randomly_RB replicating_VBG the_DT training_NN observations_NNS in_IN order_NN to_TO induce_VB single_JJ trees_NNS whose_WP$ aggregation_NN by_IN majority_NN voting_NN provides_VBZ the_DT final_JJ classification_NN ._. Bagging_'' is_VBZ able_JJ to_TO improve_VB the_DT performance_NN of_IN unstable_JJ classifiers_NNS (_-LRB- i_NN .e_NN ._. trees_NNS with_IN high_JJ variance_NN )_-RRB- ._. Thus_RB ,_, bagging_NN is_VBZ said_VBN to_TO be_VB a_DT reduction_NN variance_NN method_NN ._. Adaptive_NNP Boosting_NNP ,_, also_RB called_VBN AdaBoost_NNP (_-LRB- Freud_NNP &_CC Schapire_NNP ,_, 1996_CD )_-RRB- is_VBZ an_DT Ensemble_NNP method_NN that_WDT uses_VBZ iteratively_RB bootstrap_JJ replication_NN of_IN the_DT training_NN instances_NNS ._. At_IN each_DT iteration_NN ,_, previously-misclassified_JJ observations_NNS receive_VBP higher_JJR probability_NN of_IN being_VBG sampled_VBN ._. The_DT final_JJ classification_NN is_VBZ obtained_VBN by_IN majority_NN voting_NN ._. Boosting_NN forces_NNS the_DT decision_NN tree_NN to_TO learn_VB by_IN its_PRP$ error_NN ,_, and_CC is_VBZ able_JJ to_TO improve_VB the_DT performance_NN of_IN trees_NNS with_IN both_DT high_JJ bias_NN (_-LRB- such_JJ as_IN single_JJ -_: split_JJ trees_NNS )_-RRB- and_CC variance_NN ._. Finally_RB ,_, Random_NNP Forest_NNP (_-LRB- Breiman_NNP ,_, 2001_CD )_-RRB- is_VBZ an_DT ensemble_NN of_IN unpruned_JJ trees_NNS obtained_VBN by_IN randomly_RB resampling_VBG training_NN observations_NNS and_CC variables_NNS ._. The_DT overall_JJ performance_NN of_IN the_DT method_NN derives_VBZ from_IN averaging_VBG the_DT generalization_NN errors_NNS obtained_VBN in_IN each_DT run_NN ._. Simultaneously_RB ,_, suitable_JJ measures_NNS of_IN variables_NNS importance_NN are_VBP obtained_VBN to_TO enrich_VB the_DT interpretation_NN of_IN the_DT model_NN ._. 3._'' Combinatorial_NNP optimization_NN Combinatorial_NNP Optimization_NNP can_MD be_VB defined_VBN as_IN the_DT analysis_NN and_CC solution_NN of_IN problems_NNS that_WDT can_MD be_VB mathematically_RB modelled_JJ as_IN the_DT minimization_NN (_-LRB- or_CC maximization_NN )_-RRB- of_IN an_DT objective_JJ function_NN over_IN a_DT feasible_JJ space_NN involving_VBG mutually_RB exclusive_JJ ,_, logical_JJ constraints_NNS ._. Such_DT logical_JJ constraints_NNS can_MD be_VB seen_VBN as_IN the_DT arrangement_NN of_IN a_DT bunch_NN of_IN given_VBN elements_NNS into_IN sets_NNS ._. In_IN a_DT mathematical_JJ form_NN :_: (_-LRB- )_-RRB- {_NN }min_NN T_NNP F_NNP Tα∈_NNP or_CC (_-LRB- )_-RRB- {_, }maxT_NNP F_NNP Tα∈_NNP (_-LRB- 10_CD )_-RRB- www.intechopen.com_NN Advances_NNS in_IN Evolutionary_NNP Algorithms_NNP 450_CD where_WRB T_NNP can_MD be_VB seen_VBN as_IN an_DT arrangement_NN ,_, F_NNP is_VBZ the_DT collection_NN of_IN feasible_JJ arrangements_NNS and_CC α(_JJ T_NNP )_-RRB- measures_VBZ the_DT value_NN of_IN the_DT members_NNS of_IN F._NNP Combinatorial_NNP Optimization_NN problems_NNS are_VBP of_IN great_JJ interest_NN because_IN many_JJ real_JJ life_NN decision_NN -_: making_NN situations_NNS force_NN people_NNS to_TO choose_VB over_IN a_DT set_NN of_IN possible_JJ alternatives_NNS with_IN the_DT aim_NN of_IN maximizing_VBG some_DT utility_NN function_NN ._. On_IN the_DT one_CD hand_NN ,_, the_DT discreteness_NN of_IN the_DT solutions_NNS space_NN offers_VBZ the_DT great_JJ advantage_NN of_IN concreteness_NN and_CC ,_, indeed_RB ,_, elementary_JJ graphs_NNS or_CC similar_JJ illustrations_NNS can_MD often_RB naturally_RB be_VB used_VBN to_TO represent_VB the_DT meaning_NN of_IN a_DT particular_JJ solution_NN to_TO a_DT problem_NN ._. On_IN the_DT other_JJ end_NN ,_, those_DT problems_NNS carry_VBP a_DT heavy_JJ burden_NN in_IN terms_NNS of_IN dimensionality_NN ._. If_IN more_JJR than_IN few_JJ choices_NNS are_VBP to_TO be_VB made_VBN ,_, the_DT decision-making_JJ process_NN has_VBZ to_TO face_VB with_IN the_DT evaluation_NN of_IN a_DT terribly_RB big_JJ expanse_NN of_IN cases_NNS ._. This_DT dualism_NN (_-LRB- intuitive_JJ simplicity_NN of_IN presentation_NN of_IN a_DT solution_NN versus_IN complexity_NN of_IN solutions_NNS search_NN )_-RRB- has_VBZ made_VBN this_DT area_NN of_IN combinatorics_NNS attractive_JJ for_IN researchers_NNS from_IN many_JJ fields_NNS ,_, ranging_VBG from_IN engineering_NN to_TO management_NN sciences_NNS ._. Elegant_NNP procedures_NNS to_TO find_VB optimal_JJ solutions_NNS have_VBP been_VBN found_VBN for_IN some_DT problems_NNS ,_, but_CC for_IN most_JJS of_IN them_PRP only_RB a_DT bunch_NN of_IN properties_NNS and_CC algorithms_NNS have_VBP been_VBN developed_VBN that_IN still_RB do_VBP not_RB allow_VB to_TO reach_VB a_DT complete_JJ resolution_NN ._. This_DT is_VBZ the_DT case_NN of_IN Computational_NNP Statistics_NNPS ,_, in_IN which_WDT computationally-intensive_JJ methods_NNS are_VBP used_VBN to_TO “mine_VB “_RB large_JJ ,_, heterogeneous_JJ ,_, multi-_NNS dimensional_JJ datasets_NNS in_IN order_NN to_TO discover_VB knowledge_NN in_IN the_DT data_NNS ._. To_TO give_VB an_DT example_NN ,_, the_DT objective_NN of_IN Cluster_NNP Analysis_NNP is_VBZ to_TO find_VB the_DT “best_JJS ”_NN partition_NN of_IN the_DT dataset_NN according_VBG to_TO some_DT criterion_NN ,_, which_WDT is_VBZ always_RB expressed_VBN as_IN an_DT objective_JJ function_NN ._. This_DT means_VBZ that_IN all_DT possible_JJ and_CC coherent_JJ partitions_NNS of_IN the_DT dataset_NN should_MD be_VB generated_VBN and_CC the_DT objective_JJ function_NN has_VBZ to_TO be_VB calculated_VBN for_IN each_DT of_IN them_PRP ._. In_IN many_JJ cases_NNS ,_, the_DT number_NN of_IN possible_JJ partitions_NNS grows_VBZ too_RB rapidly_RB with_IN respect_NN to_TO the_DT number_NN of_IN units_NNS ,_, making_VBG such_JJ strategy_NN practically_RB unfeasible_JJ ._. Another_DT example_NN is_VBZ the_DT apparently_RB simple_JJ problem_NN of_IN calculating_VBG the_DT variance_NN for_IN interval_NN data_NNS ,_, for_IN which_WDT the_DT maximum_NN and_CC the_DT minimum_NN of_IN the_DT variance_NN function_NN have_VBP to_TO be_VB searched_VBN over_IN the_DT multidimensional_JJ cube_NN defined_VBN by_IN all_DT the_DT intervals_NNS in_IN which_WDT the_DT statistical_JJ units_NNS are_VBP defined_VBN ._. These_DT are_VBP examples_NNS of_IN statistical_JJ problems_NNS that_WDT cannot_MD be_VB faced_VBN with_IN the_DT total_JJ enumeration_NN and_CC evaluation_NN of_IN the_DT solutions_NNS ._. In_IN order_NN to_TO try_VB to_TO tackle_VB with_IN this_DT kind_NN of_IN problems_NNS ,_, a_DT lot_NN of_IN theory_NN has_VBZ been_VBN developed_VBN ._. One_CD case_NN is_VBZ when_WRB some_DT properties_NNS about_IN the_DT objective_JJ function_NN are_VBP available_JJ ._. These_DT allow_VBP to_TO calculate_VB some_DT kind_NN of_IN upper_JJ (_-LRB- or_CC lower_JJR )_-RRB- bound_VBN that_IN a_DT set_NN of_IN possible_JJ solutions_NNS could_MD admit_VB ._. In_IN this_DT case_NN ,_, the_DT search_NN could_MD be_VB performed_VBN just_RB on_IN the_DT set_NN of_IN possible_JJ solutions_NNS whose_WP$ upper_JJ bound_VBN is_VBZ higher_JJR ._. If_IN one_CD solution_NN whose_WP$ effective_JJ value_NN is_VBZ higher_JJR than_IN the_DT bounds_NNS of_IN all_PDT the_DT other_JJ sets_NNS is_VBZ found_VBN ,_, it_PRP would_MD not_RB be_VB necessary_JJ to_TO continue_VB the_DT search_NN ,_, being_VBG all_PDT the_DT other_JJ subsets_NNS not_RB able_JJ to_TO provide_VB better_JJR solutions_NNS ._. This_DT is_VBZ the_DT case_NN of_IN the_DT aforementioned_JJ problem_NN of_IN finding_VBG the_DT upper_JJ bound_JJ of_IN variance_NN for_IN interval_NN data_NNS ,_, because_IN it_PRP can_MD be_VB verified_VBN that_IN the_DT maximum_NN is_VBZ necessarily_RB reached_VBN in_IN one_CD of_IN the_DT vertices_NNS of_IN the_DT multidimensional_JJ cube_NN ,_, so_RB that_IN exploring_VBG the_DT whole_JJ cube_NN is_VBZ not_RB necessary_JJ ._. Such_PDT a_DT situation_NN allows_VBZ to_TO restrict_VB the_DT solutions_NNS space_NN to_TO a_DT set_NN of_IN 2n_JJ possible_JJ solutions_NNS ,_, where_WRB n_NN is_VBZ the_DT number_NN of_IN statistical_JJ units_NNS ._. Unfortunately_RB ,_, this_DT does_VBZ not_RB solve_VB the_DT problem_NN because_IN the_DT solutions_NNS space_NN becomes_VBZ enormous_JJ even_RB in_IN presence_NN of_IN small_JJ datasets_NNS (_-LRB- with_IN just_RB 30_CD units_NNS the_DT number_NN of_IN solutions_NNS to_TO evaluate_VB is_VBZ greater_JJR than_IN one_CD thousand_CD millions_NNS )_-RRB- ._. The_DT FAST_NNP algorithm_NN is_VBZ another_DT example_NN of_IN a_DT partial_JJ enumeration_NN approach_NN ,_, in_IN which_WDT a_DT measure_NN of_IN the_DT upper_JJ bound_JJ of_IN the_DT predictive_JJ power_NN of_IN a_DT solutions_NNS set_NN is_VBZ defined_VBN and_CC exploited_VBN in_IN order_NN to_TO get_VB the_DT same_JJ results_NNS of_IN the_DT CART_NNP greedy_JJ approach_NN by_IN using_VBG a_DT reduced_JJ amount_NN of_IN computations_NNS ._. www.intechopen.com_NN Evolutionary_NNP Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NNP 451_CD Another_DT way_NN to_TO proceed_VB is_VBZ to_TO make_VB use_NN of_IN non_JJ exact_JJ procedures_NNS ,_, often_RB called_VBN heuristics_NNS ._. Those_DT algorithms_NNS do_VBP not_RB claim_VB to_TO find_VB the_DT global_JJ optimum_NN ,_, but_CC are_VBP able_JJ to_TO converge_VB rapidly_RB towards_IN a_DT local_JJ one_CD ._. Non_FW exact_JJ algorithms_NNS (_-LRB- that_WDT will_MD be_VB called_VBN heuristics_NNS in_IN the_DT rest_NN of_IN this_DT chapter_NN )_-RRB- are_VBP certainly_RB not_RB recent_JJ ._. What_WP has_VBZ changed_VBN ,_, in_IN time_NN ,_, is_VBZ the_DT respectability_NN associated_VBN to_TO them_PRP ,_, due_JJ to_TO the_DT fact_NN that_IN many_JJ heuristics_NNS have_VBP been_VBN proved_VBN to_TO rival_VB their_PRP$ counterparts_NNS in_IN elegance_NN ,_, sophistication_NN and_CC ,_, particularly_RB ,_, usefulness_NN ._. Many_JJ heuristics_NNS have_VBP been_VBN proposed_VBN in_IN the_DT literature_NN ,_, but_CC only_RB two_CD kinds_NNS of_IN them_PRP will_MD be_VB briefly_RB described_VBN in_IN this_DT context_NN due_JJ to_TO their_PRP$ role_NN in_IN the_DT problems_NNS that_WDT will_MD be_VB faced_VBN in_IN the_DT next_JJ sections_NNS ._. These_DT are_VBP :_: Greedy_JJ procedures_NNS and_CC Nature_NNP Inspired_NNP optimization_NN algorithms_NNS ._. In_IN Greedy_NNP procedures_NNS the_DT optimization_NN process_NN selects_VBZ ,_, at_IN each_DT stage_NN ,_, an_DT alternative_NN that_WDT is_VBZ the_DT best_JJS among_IN all_PDT the_DT feasible_JJ alternatives_NNS without_IN taking_VBG into_IN account_NN the_DT impact_NN that_IN such_JJ choice_NN will_MD have_VB on_IN the_DT subsequent_JJ decisions_NNS ._. The_DT CART_NNP algorithm_NN makes_VBZ use_NN of_IN a_DT greedy_JJ procedure_NN to_TO grow_VB a_DT tree_NN in_IN which_WDT the_DT optimality_NN criterion_NN is_VBZ maximised_VBN just_RB locally_RB ,_, that_DT is_VBZ ,_, for_IN each_DT node_NN of_IN the_DT tree_NN but_CC not_RB considering_VBG the_DT tree_NN as_IN a_DT whole_JJ ._. This_DT approach_NN clearly_RB results_VBZ in_IN a_DT suboptimal_NN tree_NN but_CC allows_VBZ ,_, at_IN least_JJS ,_, to_TO obtain_VB a_DT tree_NN in_IN a_DT reasonable_JJ amount_NN of_IN time_NN ._. Whereas_'' ,_, the_DT so-called_JJ Nature_NN Inspired_VBN heuristics_NNS ,_, which_WDT are_VBP also_RB called_VBN “_JJ Heuristics_NNP from_IN Nature_NN ”_NN (_-LRB- Colorni_NNP et_NNP al_NN ._. ,_, 1993_CD )_-RRB- ,_, are_VBP Inspired_VBN by_IN natural_JJ phenomena_NNS or_CC behaviour_NN such_JJ as_IN Evolution_NNP ,_, Ants_NNP ,_, Honey-_NNP Bees_NNP ,_, Immune_NNP systems_NNS ,_, Forests_NNS ,_, etc_FW ._. Some_DT important_JJ Nature_NN Inspired_VBN heuristics_NNS are_VBP :_: Simulated_JJ Annealing_NNP (_-LRB- SA_NNP )_-RRB- ,_, TABU_JJ Search_NNP (_-LRB- TS_NNS )_-RRB- algorithms_NNS ,_, Ant_NNP Colony_NNP Optimization_NN (ACO_NN )_-RRB- and_CC Evolutionary_NNP Computation_NNP (EC_NNP )_-RRB- ._. ACO_NNP and_CC EC_NNP are_VBP described_VBN in_IN the_DT following_VBG since_IN they_PRP are_VBP used_VBN throughout_IN the_DT chapter_NN ._. Ant_'' Colony_NNP Optimization_NNP represents_VBZ a_DT class_NN of_IN algorithms_NNS that_WDT were_VBD inspired_VBN by_IN the_DT observation_NN of_IN real_JJ ant_JJ colonies_NNS ._. Observation_NN shows_VBZ that_IN a_DT single_JJ ant_NN only_RB applies_VBZ simple_JJ rules_NNS ,_, has_VBZ no_DT knowledge_NN and_CC it_PRP is_VBZ unable_JJ to_TO succeed_VB in_IN anything_NN when_WRB it_PRP is_VBZ alone_RB ._. However_RB ,_, an_DT ant_JJ colony_NN benefits_NNS from_IN the_DT coordinated_JJ interaction_NN of_IN each_DT ant_JJ ._. Its_PRP$ structured_JJ behaviour_NN ,_, described_VBN as_IN a_DT “social_JJ life”_NN ,_, leads_VBZ to_TO a_DT cooperation_NN of_IN independent_JJ searches_NNS with_IN high_JJ probability_NN of_IN success_NN ._. ACO_NNP were_VBD initially_RB proposed_VBN by_IN Dorigo_NNP (_-LRB- 1992_CD )_-RRB- to_TO attack_VB the_DT Traveling_NNP Salesman_NNP Problem_NNP ._. A_DT real_JJ ant_JJ colony_NN is_VBZ capable_JJ of_IN finding_VBG the_DT shortest_NN path_NN from_IN a_DT food_NN source_NN to_TO its_PRP$ nest_NN by_IN using_VBG pheromone_NN information_NN :_: when_WRB walking_VBG ,_, each_DT ant_JJ deposits_NNS a_DT chemical_NN substance_NN called_VBD pheromone_NN and_CC follows_VBZ ,_, in_IN probability_NN ,_, a_DT pheromone_NN trail_NN already_RB deposited_VBN by_IN previous_JJ ants_NNS ._. Assuming_NN that_IN each_DT ant_NN has_VBZ the_DT same_JJ speed_NN ,_, the_DT path_NN which_WDT ends_VBZ up_RP with_IN the_DT maximum_JJ quantity_NN of_IN pheromone_NN is_VBZ the_DT shortest_NN one_CD ._. Evolutionary_NNP computation_NN (_-LRB- Fogel_NNP and_CC Fogel_NNP ,_, 1993_CD )_-RRB- incorporates_VBZ algorithms_NNS that_WDT are_VBP inspired_VBN from_IN evolution_NN principles_NNS in_IN nature_NN ._. The_DT methods_NNS of_IN evolutionary_JJ computation_NN algorithms_NNS are_VBP stochastic_JJ and_CC their_PRP$ search_NN methods_NNS imitate_VBP and_CC model_NN some_DT natural_JJ phenomena_NNS ,_, namely_RB :_: 1_CD ._. the_DT survival_NN of_IN the_DT fittest_JJS 2._CD genetic_JJ inheritance_NN Evolutionary_JJ computing_NN can_MD be_VB applied_VBN to_TO problems_NNS when_WRB it_PRP is_VBZ difficult_JJ to_TO apply_VB traditional_JJ methods_NNS (_-LRB- e_NN .g._NNP ,_, when_WRB gradients_NNS are_VBP not_RB available_JJ )_-RRB- or_CC when_WRB traditional_JJ methods_NNS lead_JJ to_TO unsatisfactory_JJ solutions_NNS like_IN local_JJ optima_NN (_-LRB- Fogel_NNP ,_, 1997_CD )_-RRB- ._. Evolutionary_NNP algorithms_NNS work_VBP with_IN a_DT population_NN of_IN potential_JJ solutions_NNS (_-LRB- i_NN .e_NN ._. individuals_NNS )_-RRB- ._. Each_DT individual_NN is_VBZ a_DT potential_JJ solution_NN to_TO the_DT problem_NN under_IN consideration_NN and_CC it_PRP is_VBZ encoded_VBN into_IN a_DT data_NNS structure_NN suitable_JJ to_TO the_DT problem_NN ._. Each_DT encoded_VBN solution_NN is_VBZ evaluated_VBN by_IN an_DT objective_JJ function_NN (_-LRB- environment_NN )_-RRB- in_IN order_NN to_TO measure_VB its_PRP$ fitness_NN ._. The_DT bias_NN on_IN selecting_VBG high-fitness_NN individuals_NNS exploits_VBZ the_DT acquired_VBN fitness_NN information_NN ._. The_DT individuals_NNS will_MD change_VB and_CC evolve_VB to_TO form_VB a_DT new_JJ www.intechopen.com_NN Advances_NNS in_IN Evolutionary_NNP Algorithms_NNP 452_CD population_NN by_IN applying_VBG genetic_JJ operators_NNS ._. Genetic_NNP operators_NNS perturb_VBP those_DT individuals_NNS in_IN order_NN to_TO explore_VB the_DT search_NN space_NN ._. There_EX are_VBP two_CD main_JJ types_NNS of_IN genetic_JJ operators_NNS :_: Mutation_NN and_CC Crossover_NNP ._. Mutation_NNP type_NN operators_NNS are_VBP asexual_JJ (unary_JJ )_-RRB- operators_NNS ,_, which_WDT create_VBP new_JJ individuals_NNS by_IN a_DT small_JJ change_NN in_IN a_DT single_JJ individual_NN ._. On_IN the_DT other_JJ hand_NN ,_, Crossover_NNP type_NN operators_NNS are_VBP multi-sexual_JJ (_-LRB- multary_JJ )_-RRB- operators_NNS ,_, which_WDT create_VBP new_JJ individuals_NNS by_IN combining_VBG parts_NNS from_IN two_CD or_CC more_JJR individuals_NNS ._. As_RB soon_RB as_IN a_DT number_NN of_IN generations_NNS have_VBP evolved_VBN ,_, the_DT process_NN is_VBZ terminated_VBN according_VBG to_TO a_DT termination_NN criterion_NN ._. The_DT best_JJS individual_NN in_IN the_DT final_JJ step_NN of_IN the_DT process_NN is_VBZ then_RB proposed_VBN as_IN a_DT (_-LRB- hopefully_RB suboptimal_JJ or_CC optimal_JJ )_-RRB- solution_NN for_IN the_DT problem_NN ._. Evolutionary_PDT computing_NN are_VBP further_RB classified_VBN into_IN four_CD groups_NNS :_: Genetic_JJ Algorithms_NNP (_-LRB- GA_NNP )_-RRB- ,_, Evolutionary_NNP Programming_NNP ,_, Evolution_NNP Strategies_NNP and_CC Genetic_JJ Programming_NN ._. Although_IN there_EX are_VBP many_JJ relevant_JJ similarities_NNS between_IN these_DT evolutionary_JJ computing_NN paradigms_NNS ,_, profound_JJ differences_NNS among_IN them_PRP also_RB emerge_VBP (_-LRB- Michalewicz_NNP ,_, 1996_CD )_-RRB- ._. These_DT differences_NNS generally_RB involve_VBP the_DT level_NN in_IN the_DT hierarchy_NN of_IN the_DT evolution_NN being_VBG modelled_JJ ,_, that_DT is_VBZ :_: the_DT chromosome_NN ,_, the_DT individual_NN or_CC the_DT species_NNS ._. There_EX are_VBP also_RB many_JJ hybrid_JJ methods_NNS that_WDT combine_VBP various_JJ features_NNS from_IN two_CD or_CC more_JJR of_IN the_DT methods_NNS described_VBN in_IN this_DT section_NN ._. Genetic_JJ Algorithms_NNP (_-LRB- GAs_NNP )_-RRB- ,_, that_WDT will_MD be_VB used_VBN in_IN the_DT follwing_NN ,_, are_VBP part_NN of_IN a_DT collection_NN of_IN stochastic_JJ optimization_NN algorithms_NNS inspired_VBN by_IN the_DT natural_JJ genetics_NNS and_CC the_DT theory_NN of_IN the_DT biological_JJ evolution_NN ._. The_DT idea_NN behind_IN genetic_JJ algorithms_NNS is_VBZ to_TO simulate_VB the_DT natural_JJ evolution_NN when_WRB optimizing_VBG a_DT particular_JJ objective_JJ function_NN ._. GAs_NNP have_VBP emerged_VBN as_IN practical_JJ ,_, robust_JJ optimization_NN and_CC search_NN methods_NNS in_IN the_DT last_JJ three_CD decades_NNS ._. In_IN the_DT literature_NN ,_, Hollands_NNP ’_NNP genetic_JJ algorithm_NN is_VBZ called_VBN Simple_NNP Genetic_NNP Algorithm_NNP (_-LRB- Vose_NN ,_, 1999_CD )_-RRB- ._. It_PRP works_VBZ with_IN a_DT population_NN of_IN individuals_NNS (_-LRB- chromosomes_NNS )_-RRB- ,_, which_WDT are_VBP encoded_VBN as_IN binary_JJ strings_NNS (_-LRB- genes_NNS )_-RRB- ._. 4_CD ._. Genetic_NNP algorithms_NNS and_CC heuristics_NNS in_IN DTI_NNP 4.1_CD Genetic_JJ algorithm_NN for_IN complex_JJ predictors_NNS The_DT CART_NNP methodology_NN looks_VBZ for_IN the_DT best_JJS split_NN by_IN making_VBG use_NN of_IN a_DT brute-force_NN (_-LRB- enumerative_JJ )_-RRB- procedure_NN ._. All_PDT the_DT possible_JJ splits_NNS from_IN all_PDT the_DT possible_JJ variables_NNS are_VBP generated_VBN and_CC evaluated_VBN ._. Such_PDT a_DT procedure_NN must_MD be_VB performed_VBN anytime_RB a_DT node_NN has_VBZ to_TO be_VB split_VBN and_CC can_MD lead_VB to_TO computational_JJ problems_NNS when_WRB the_DT number_NN of_IN modalities_NNS grows_VBZ ._. Let_VB us_PRP first_RB consider_VBP how_WRB a_DT segmentation_NN procedure_NN generates_VBZ and_CC evaluates_VBZ all_DT possible_JJ splits_NNS ._. Nominal_NN unordered_JJ predictors_NNS (_-LRB- Nup_NN )_-RRB- are_VBP more_RBR complicated_JJ to_TO handle_VB than_IN ordered_VBN ones_NNS because_IN the_DT number_NN of_IN possible_JJ splits_NNS that_WDT can_MD be_VB generated_VBN grows_VBZ exponentially_RB with_IN the_DT number_NN of_IN attributes_NNS m_NN ._. The_DT number_NN of_IN possible_JJ splits_NNS is_VBZ (_-LRB- 2m-1-1_JJ )_-RRB- ._. The_DT computational_JJ complexity_NN of_IN a_DT procedure_NN that_IN generates_VBZ and_CC evaluates_VBZ all_PDT the_DT splits_NNS from_IN a_DT nominal_JJ unordered_JJ predictor_NN is_VBZ O(_JJ 2n_JJ )_-RRB- ._. In_IN this_DT respect_NN ,_, it_PRP is_VBZ evident_JJ that_IN such_JJ enumerative_JJ algorithm_NN becomes_VBZ prohibitive_JJ when_WRB the_DT number_NN of_IN attributes_NNS is_VBZ high_JJ ._. This_DT is_VBZ one_CD of_IN the_DT reasons_NNS why_WRB some_DT software_NN do_VBP not_RB accept_VB Nups_NNS with_IN a_DT number_NN of_IN attributes_NNS higher_JJR than_IN a_DT certain_JJ threshold_NN (usually_RB between_IN 12_CD and_CC 15_CD )_-RRB- ._. One_CD of_IN the_DT possible_JJ way_NN to_TO proceed_VB is_VBZ to_TO make_VB use_NN of_IN a_DT heuristic_JJ procedure_NN ,_, like_IN the_DT one_CD proposed_VBN in_IN this_DT section_NN ._. In_IN order_NN to_TO design_VB a_DT Genetic_JJ Algorithm_NNP to_TO solve_VB such_JJ a_DT combinatorial_JJ problem_NN ,_, it_PRP is_VBZ necessary_JJ to_TO identify_VB :_: •_VB a_DT meaningful_JJ representation_NN (_-LRB- coding_NN )_-RRB- for_IN the_DT candidate_NN solutions_NNS (_-LRB- the_DT possible_JJ splits_NNS )_-RRB- •_VBP a_DT way_NN to_TO generate_VB the_DT initial_JJ population_NN •_VBD a_DT fitness_NN function_NN to_TO evaluate_VB any_DT candidate_NN solution_NN www.intechopen.com_IN Evolutionary_NNP Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NNP 453_CD •_, a_DT set_NN of_IN useful_JJ genetic_JJ operators_NNS that_WDT can_MD efficiently_RB recombine_VB and_CC mutate_VB the_DT candidate_NN solutions_NNS •_VBD the_DT values_NNS of_IN the_DT parameters_NNS used_VBN by_IN the_DT GA_NNP (_-LRB- population_NN size_NN ,_, genetic_JJ operators_NNS parameters_NNS values_NNS ,_, selective_JJ pressure_NN ,_, etc._FW )_-RRB- ;_: •_RP a_DT stopping_NN rule_NN for_IN the_DT algorithm_NN ._. The_DT aforementioned_JJ points_NNS have_VBP been_VBN tackled_VBN as_IN follows_VBZ ._. As_IN for_IN the_DT coding_NN ,_, it_PRP has_VBZ been_VBN chosen_VBN the_DT following_VBG representation_NN :_: a_DT solution_NN is_VBZ coded_VBN in_IN a_DT string_NN of_IN bits_NNS (_-LRB- chromosomes_NNS )_-RRB- called_VBN x_NN ,_, where_WRB each_DT bit_NN (_-LRB- gene_NN )_-RRB- is_VBZ associated_VBN to_TO an_DT attribute_NN of_IN the_DT predictor_NN according_VBG to_TO the_DT following_JJ rule_NN :_: 0_CD 1_CD i_IN if_IN i_PRP goes_VBZ to_TO left_JJ x_NN if_IN i_PRP goes_VBZ to_TO right_JJ ⎧_NN =_SYM ⎨_FW ⎩_FW (_-LRB- 11_CD )_-RRB- The_DT choice_NN of_IN the_DT fitness_NN function_NN is_VBZ straightforward_RB :_: the_DT split_NN evaluation_NN function_NN of_IN the_DT standard_JJ recursive_JJ partitioning_NN algorithm_NN is_VBZ used_VBN (_-LRB- i_IN .e_NN ._. the_DT maximum_NN decrease_NN in_IN node_NN impurity_NN )_-RRB- ._. Since_IN the_DT canonical_NN (_-LRB- binary_JJ )_-RRB- coding_NN is_VBZ chosen_VBN ,_, the_DT corresponding_JJ two_CD parents_NNS single-point_JJ crossover_NN and_CC mutation_NN operators_NNS and_CC ,_, as_IN a_DT stopping_NN rule_NN can_MD be_VB used_VBN ._. In_IN addition_NN ,_, a_DT maximum_JJ number_NN of_IN iterations_NNS is_VBZ chosen_VBN on_IN the_DT basis_NN of_IN empirical_JJ investigations_NNS ._. The_DT rest_NN of_IN the_DT GA_NNP features_NNS are_VBP similar_JJ to_TO the_DT classic_JJ ones_NNS :_: elitism_NN is_VBZ used_VBN (_-LRB- at_IN each_DT iteration_NN the_DT best_JJS solution_NN is_VBZ kept_VBN in_IN memory_NN )_-RRB- and_CC the_DT initial_JJ population_NN is_VBZ chosen_VBN randomly_RB ._. 4.2_CD An_DT ACO_NNP algorithm_NN for_IN exploratory_JJ DTI_NNP When_WRB growing_VBG a_DT Classification_NN or_CC a_DT Regression_NNP Tree_NNP ,_, CART_NNP first_RB grows_VBZ the_DT so-called_JJ exploratory_NN tree_NN ._. Such_DT tree_NN is_VBZ grown_VBN using_VBG data_NNS of_IN the_DT training_NN set_NN ._. Then_RB ,_, it_PRP is_VBZ validated_VBN by_IN using_VBG the_DT test_NN set_NN or_CC by_IN cross-validation_NN ._. In_IN this_DT section_NN ,_, the_DT attention_NN is_VBZ focused_VBN on_IN the_DT exploratory_NN tree-growing_NN procedure_NN ._. In_IN this_DT phase_NN ,_, in_IN theory_NN ,_, the_DT best_JJS possible_JJ tree_NN should_MD be_VB built_VBN ,_, which_WDT is_VBZ the_DT tree_NN having_VBG the_DT lowest_JJS global_JJ impurity_NN measure_NN among_IN all_PDT the_DT generable_JJ trees_NNS ._. It_PRP has_VBZ been_VBN shown_VBN (_-LRB- Hyafil_NNP and_CC Rivest_NNP ,_, 1976_CD )_-RRB- that_IN constructing_VBG the_DT optimal_JJ tree_NN is_VBZ a_DT NP-Complete_JJ problem_NN ._. In_IN other_JJ words_NNS ,_, in_IN order_NN to_TO use_VB a_DT polynomial_NN algorithm_NN ,_, it_PRP is_VBZ only_RB possible_JJ to_TO get_VB suboptimal_JJ trees_NNS ._. For_IN such_JJ a_DT reason_NN ,_, the_DT recursive_JJ partitioning_NN algorithms_NNS make_VBP use_NN of_IN greedy_JJ heuristics_NNS to_TO reach_VB a_DT compromise_NN between_IN the_DT tree_NN quality_NN and_CC the_DT computational_JJ effort_NN ._. In_IN particular_JJ ,_, most_JJS of_IN the_DT existing_VBG methods_NNS for_IN DTI_NNP use_NN a_DT greedy_JJ heuristic_JJ ,_, which_WDT is_VBZ based_VBN on_IN a_DT top-down_JJ recursive_JJ partitioning_NN approach_NN in_IN which_WDT ,_, any_DT time_NN ,_, the_DT split_NN that_IN maximizes_VBZ the_DT one_CD step_NN impurity_NN decrease_NN is_VBZ chosen_VBN ._. This_DT kind_NN of_IN greedy_JJ approach_NN ,_, that_WDT splits_VBZ the_DT data_NN locally_RB (_-LRB- i_FW .e_FW ._. ,_, in_IN a_DT given_VBN node_NN )_-RRB- and_CC only_RB once_RB for_IN each_DT node_NN ,_, allows_VBZ to_TO grow_VB a_DT tree_NN in_IN a_DT reasonable_JJ amount_NN of_IN time_NN ._. On_IN the_DT other_JJ hand_NN ,_, this_DT rule_NN is_VBZ able_JJ to_TO generate_VB only_RB a_DT suboptimal_JJ tree_NN because_IN anytime_RB a_DT split_NN is_VBZ chosen_VBN a_DT certain_JJ subspace_NN of_IN possible_JJ trees_NNS is_VBZ not_RB investigated_VBN anymore_RB by_IN the_DT algorithm_NN ._. If_IN the_DT optimal_NN tree_NN is_VBZ included_VBN in_IN one_CD of_IN those_DT subspaces_NNS there_EX is_VBZ no_DT chance_NN for_IN the_DT algorithm_NN of_IN finding_VBG it_PRP ._. Taking_VBG these_DT considerations_NNS into_IN account_NN ,_, we_PRP propose_VBP an_DT Ant_NNP Colony_NNP Optimization_NNP algorithm_NN to_TO try_VB to_TO find_VB best_JJS exploratory_NN tree_NN ._. In_IN order_NN to_TO attack_VB a_DT problem_NN with_IN ACO_NNP the_DT following_VBG design_NN task_NN must_MD be_VB performed_VBN :_: 1_CD ._. Represent_IN the_DT problem_NN in_IN the_DT form_NN of_IN sets_NNS of_IN components_NNS and_CC transitions_NNS or_CC by_IN means_NNS of_IN a_DT weighted_JJ graph_NN ,_, on_IN which_WDT ants_NNS build_VBP solutions_NNS www.intechopen.com_IN Advances_NNS in_IN Evolutionary_NNP Algorithms_NNP 454_CD 2._. Appropriately_RB define_VB the_DT meaning_NN of_IN the_DT pheromone_NN trails_NNS :_: that_DT is_VBZ ,_, the_DT type_NN of_IN decision_NN they_PRP bias_NN ._. 3._'' Appropriately_RB define_VB the_DT heuristic_JJ reference_NN for_IN each_DT decision_NN an_DT ant_NN has_VBZ to_TO take_VB while_IN constructing_VBG a_DT solution_NN ._. 4_LS ._. If_IN possible_JJ ,_, implement_VB an_DT efficient_JJ local_JJ search_NN algorithm_NN for_IN the_DT problem_NN to_TO be_VB solved_VBN ._. The_DT best_JJS results_NNS from_IN the_DT application_NN of_IN the_DT ACO_NNP algorithms_NNS to_TO NP-hard_JJ combinatorial_JJ optimization_NN problems_NNS are_VBP achieved_VBN by_IN coupling_VBG ACO_NNP with_IN local_JJ optimizers_NNS (_-LRB- Dorigo_NNP and_CC Stutzle_NNP ,_, 2004_CD )_-RRB- 5_CD ._. Choose_VB a_DT specific_JJ ACO_NNP algorithm_NN and_CC apply_VB it_PRP to_TO the_DT problem_NN to_TO be_VB solved_VBN ,_, taking_VBG the_DT previous_JJ issues_NNS into_IN account_NN 6_CD ._. Tune_NNP the_DT parameters_NNS of_IN the_DT ACO_NNP algorithm_NN ._. A_DT good_JJ starting_NN point_NN is_VBZ to_TO use_VB parameter_NN settings_NNS that_WDT were_VBD found_VBN to_TO be_VB good_JJ when_WRB applying_VBG the_DT same_JJ ACO_NNP algorithm_NN to_TO similar_JJ problems_NNS or_CC to_TO a_DT variety_NN of_IN other_JJ problems_NNS The_DT most_RBS complex_JJ task_NN is_VBZ probably_RB the_DT first_JJ one_CD ,_, in_IN which_WDT a_DT way_NN to_TO represent_VB the_DT problem_NN in_IN the_DT form_NN of_IN a_DT weighted_JJ graph_NN must_MD be_VB found_VBN ._. We_PRP use_VBP a_DT representation_NN based_VBN on_IN the_DT following_VBG idea_NN :_: let_VB us_PRP imagine_VB having_VBG two_CD nominal_JJ predictors_NNS P1_. =_SYM {a1_CD ,_, b1_CD ,_, c1_CD }_NN and_CC P2_NNP =_SYM {a2_CD ,_, b2_CD }_NN with_IN ,_, respectively_RB ,_, two_CD and_CC three_CD attributes_NNS ._. Such_JJ simple_JJ predictors_NNS are_VBP considered_VBN only_RB to_TO explain_VB the_DT idea_NN ,_, because_IN of_IN the_DT combinatorial_JJ explosion_NN of_IN the_DT phenomenon_NN ._. In_IN this_DT case_NN ,_, the_DT set_NN of_IN all_DT possible_JJ splits_NNS ,_, at_IN a_DT root_NN node_NN ,_, is_VBZ the_DT following_VBG :_: •_JJ S1_NNP =_SYM [a1_CD ]_SYM −_JJ [b1_CD ,_, c1_CD ]_SYM •_JJR S2_NNP =_SYM [a1_CD ,_, b1]_CD −_, [c1_CD ]_SYM •_JJR S3_. =_SYM [a1_CD ,_, c1_CD ]_SYM −_VBN [b1]_IN •_NNP S4_NNP =_SYM [a2_CD ]_SYM −_VBN [b2_CD ]_SYM Any_DT time_NN a_DT split_NN is_VBZ chosen_VBN ,_, it_PRP generates_VBZ two_CD child_NN nodes_NNS ._. For_IN such_JJ nodes_NNS ,_, the_DT set_NN of_IN possible_JJ splits_NNS is_VBZ ,_, in_IN the_DT worst_JJS case_NN ,_, equal_JJ to_TO 3_CD (_-LRB- the_DT same_JJ as_IN the_DT parent_NN node_NN except_IN the_DT one_CD that_WDT was_VBD chosen_VBN for_IN splitting_JJ )_-RRB- ._. This_DT consideration_NN leads_VBZ to_TO the_DT representation_NN shown_VBN in_IN Figure_NN 1_CD in_IN which_WDT ,_, for_IN simplicity_NN ,_, only_RB the_DT first_JJ two_CD levels_NNS of_IN the_DT possible_JJ trees_NNS are_VBP considered_VBN ._. It_PRP is_VBZ easy_JJ to_TO imagine_VB how_WRB the_DT complexity_NN grows_VBZ when_WRB we_PRP deal_VBP with_IN predictors_NNS that_WDT generate_VBP hundreds_NNS or_CC even_RB thousands_NNS of_IN splits_NNS (_-LRB- which_WDT is_VBZ a_DT common_JJ case_NN )_-RRB- ._. In_IN Figure_NN 1_CD ,_, the_DT space_NN of_IN all_DT possible_JJ trees_NNS is_VBZ represented_VBN by_IN a_DT connected_JJ graph_NN ._. Moving_VBG from_IN a_DT level_NN to_TO another_DT one_CD corresponds_NNS to_TO split_VB a_DT variable_JJ ._. The_DT arcs_NNS of_IN such_JJ a_DT graph_NN have_VBP the_DT same_JJ meaning_NN of_IN the_DT arcs_NNS of_IN the_DT TSP_NNP graph_NN (_-LRB- transition_NN from_IN a_DT state_NN to_TO another_DT one_CD or_CC ,_, even_RB better_JJR ,_, addition_NN of_IN a_DT component_NN to_TO a_DT partial_JJ solution_NN )_-RRB- ._. In_IN this_DT view_NN ,_, it_PRP would_MD be_VB correct_JJ to_TO deposit_VB pheromone_NN on_IN them_PRP ._. The_DT pheromone_NN trails_VBZ meaning_NN ,_, in_IN this_DT case_NN ,_, corresponds_NNS to_TO the_DT desirability_NN to_TO choose_VB the_DT corresponding_JJ split_NN from_IN a_DT certain_JJ node_NN ._. As_IN for_IN the_DT heuristic_JJ information_NN ,_, it_PRP is_VBZ possible_JJ to_TO refer_VB to_TO the_DT decrease_NN in_IN impurity_NN deriving_NN from_IN adding_VBG the_DT corresponding_JJ node_NN to_TO the_DT tree_NN ._. Such_PDT a_DT measure_NN has_VBZ a_DT meaning_NN which_WDT is_VBZ similar_JJ ,_, in_IN some_DT way_NN ,_, to_TO the_DT one_CD that_IN visibility_NN has_VBZ in_IN the_DT TSP_NNP ._. An_DT arc_NN is_VBZ much_RB more_RBR desirable_JJ as_IN higher_JJR the_DT impurity_NN decrease_NN is_VBZ ._. As_IN a_DT result_NN ,_, to_TO make_VB analogies_NNS with_IN the_DT TSP_NNP ,_, such_JJ impurity_NN decrease_NN can_MD be_VB seen_VBN as_IN an_DT inverse_JJ measure_NN of_IN the_DT distance_NN between_IN two_CD nodes_NNS ._. Once_RB the_DT construction_NN graph_NN has_VBZ been_VBN built_VBN ,_, and_CC pheromone_NN trails_NNS meaning_NN and_CC heuristic_JJ function_NN have_VBP been_VBN defined_VBN ,_, it_PRP is_VBZ possible_JJ to_TO attack_VB that_DT problem_NN using_VBG an_DT ACO_NNP algorithm_NN ._. It_PRP is_VBZ important_JJ to_TO note_VB that_IN ,_, because_IN of_IN the_DT specificity_NN of_IN the_DT problem_NN to_TO be_VB modelled_JJ (_-LRB- ants_NNS can_MD move_VB into_IN a_DT connected_JJ graph_NN and_CC there_EX is_VBZ a_DT measure_NN of_IN “visibility”_NN )_-RRB- ,_, the_DT search_NN of_IN the_DT best_JJS tree_NN can_MD be_VB seen_VBN as_IN a_DT shortest_NN path_NN research_NN ,_, like_IN in_IN TSP._NNP In_IN the_DT latter_NN ,_, ants_NNS are_VBP forced_VBN to_TO pass_VB only_RB one_CD time_NN for_IN each_DT city_NN while_IN ,_, in_IN our_PRP$ case_NN ,_, ants_NNS are_VBP forced_VBN to_TO choose_VB paths_NNS that_IN www.intechopen.com_NN Evolutionary_RB Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NNP 455_CD correspond_NN to_TO binary_JJ trees_NNS ,_, since_IN the_DT solutions_NNS to_TO build_VB must_MD be_VB in_IN the_DT form_NN of_IN tree_NN structures_NNS ._. All_PDT the_DT ants_NNS will_MD start_VB from_IN the_DT root_NN node_NN and_CC will_MD be_VB forced_VBN to_TO move_VB from_IN one_CD node_NN to_TO another_DT in_IN order_NN to_TO build_VB a_DT tour_NN that_IN corresponds_NNS to_TO a_DT tree_NN ._. Fig_VB ._. 1_CD ._. An_DT example_NN of_IN ACO_NNP algorithm_NN for_IN exploratory_JJ DTI_NNP :_: each_DT path_NN corresponds_VBZ to_TO a_DT 2-_JJ levels_NNS tree_NN ._. It_PRP is_VBZ important_JJ to_TO notice_VB the_DT basics_NNS of_IN the_DT ant_JJ moves_NNS in_IN the_DT graph_NN shown_VBN in_IN Figure_NN 1_CD ._. At_IN each_DT step_NN ,_, the_DT ant_JJ looks_NNS for_IN the_DT heuristic_JJ information_NN (_-LRB- impurity_NN decrease_NN )_-RRB- and_CC the_DT pheromone_NN trail_NN of_IN any_DT possible_JJ direction_NN and_CC decides_VBZ for_IN the_DT one_CD to_TO choose_VB (_-LRB- and_CC ,_, therefore_RB ,_, the_DT associated_JJ split_NN )_-RRB- on_IN the_DT basis_NN of_IN the_DT selected_VBN ACO_NNP algorithm_NN ._. Once_RB the_DT ant_JJ arrives_VBZ to_TO a_DT terminal_NN node_NN ,_, it_PRP recursively_RB starts_VBZ to_TO move_VB back_RB to_TO the_DT other_JJ unexplored_JJ nodes_NNS ._. In_IN different_JJ ACO_NNP algorithms_NNS ,_, pheromone_NN trails_NNS are_VBP initialized_VBN to_TO a_DT value_NN obtained_VBN by_IN manipulating_VBG the_DT quality_NN measure_NN (_-LRB- the_DT path’s_NN length_NN for_IN the_DT TSP_JJ case_NN )_-RRB- of_IN a_DT solution_NN obtained_VBN with_IN another_DT heuristic_JJ (_-LRB- Dorigo_NNP suggests_VBZ the_DT nearest-neighbour_JJ heuristic_JJ )_-RRB- ._. In_IN our_PRP$ case_NN ,_, the_DT greedy_JJ tree_NN induction_NN rule_NN solution_NN quality_NN is_VBZ used_VBN ._. Elitism_NNP will_MD also_RB be_VB implemented_VBN and_CC the_DT chosen_VBN parameters_NNS (_-LRB- due_JJ to_TO the_DT strong_JJ similarity_NN with_IN TSP)_NNP are_VBP the_DT same_JJ that_IN have_VBP been_VBN used_VBN successfully_RB for_IN the_DT TSP_NNP problem_NN ._. 4.3_CD Identification_NN of_IN a_DT parsimonious_JJ set_NN of_IN decision_NN trees_NNS in_IN multi-class_NN classification_NN In_IN many_JJ situations_NNS ,_, the_DT response_NN variable_JJ used_VBN in_IN classification_NN tree_NN modelling_NN rarely_RB presents_VBZ a_DT number_NN of_IN attributes_NNS that_WDT allow_VBP to_TO apply_VB the_DT recursive_JJ partitioning_NN algorithm_NN in_IN the_DT most_JJS accurate_JJ manner_NN ._. It_PRP is_VBZ well_RB known_VBN that_IN :_: a_DT )_-RRB- a_DT multi-class_JJ response_NN ,_, namely_RB a_DT nominal_JJ variables_NNS with_IN several_JJ classes_NNS ,_, usually_RB causes_VBZ prediction_NN inaccuracy_NN ;_: www.intechopen.com_NN Advances_NNS in_IN Evolutionary_NNP Algorithms_NNP 456_CD b_NN )_-RRB- multi-class_NN and_CC numeric_JJ predictors_NNS play_VBP often_RB the_DT role_NN of_IN splitting_JJ variables_NNS in_IN the_DT tree_NN growing_VBG process_NN in_IN disadvantage_NN of_IN two-classes_NNS ones_NNS ,_, causing_VBG selection_NN bias_NN ._. To_TO account_VB for_IN the_DT problems_NNS deriving_VBG from_IN the_DT prediction_NN inaccuracy_NN of_IN tree-based_JJ classifiers_NNS grown_VBN for_IN multi-class_JJ response_NN ,_, as_RB well_RB as_IN to_TO reduce_VB the_DT drawback_NN of_IN the_DT loss_NN of_IN interpretability_NN induced_VBN by_IN ensemble_JJ methods_NNS in_IN these_DT situations_NNS ,_, Mola_NNP and_CC Conversano_NNP (_-LRB- 2008_CD )_-RRB- introduced_VBD an_DT algorithm_NN based_VBN on_IN a_DT Sequential_JJ Automatic_NNP Search_NNP of_IN a_DT Subset_NNP of_IN Classifiers_NNS (_-LRB- SASSC_NNP )_-RRB- ._. It_PRP produces_VBZ a_DT partition_NN of_IN the_DT set_NN of_IN the_DT response_NN classes_NNS into_IN a_DT reduced_JJ number_NN of_IN disjoint_NN subgroups_NNS and_CC introduces_VBZ a_DT parameter_NN in_IN the_DT final_JJ classification_NN model_NN that_WDT improves_VBZ its_PRP$ prediction_NN accuracy_NN ,_, since_IN it_PRP allows_VBZ to_TO assign_VB each_DT new_JJ observation_NN to_TO the_DT most_JJS appropriate_JJ classifier_NN in_IN a_DT previously-identified_JJ reduced_JJ set_NN of_IN classifiers_NNS ._. It_PRP uses_VBZ a_DT data_NNS -_: driven_VBN heuristic_JJ based_VBN on_IN cross-validated_JJ classification_NN trees_NNS as_IN a_DT tool_NN to_TO induce_VB the_DT set_NN of_IN classifiers_NNS in_IN the_DT final_JJ classification_NN model_NN ._. SASSC_NNP produces_VBZ a_DT partition_NN of_IN the_DT set_NN of_IN the_DT response_NN classes_NNS into_IN a_DT reduced_JJ number_NN of_IN super-classes_NNS ._. It_PRP is_VBZ applicable_JJ to_TO a_DT dataset_NN X_NNP composed_VBD of_IN N_NNP observations_NNS characterized_VBD by_IN a_DT set_NN of_IN J_NNP (_-LRB- numeric_JJ or_CC nominal_JJ )_-RRB- splitting_JJ variables_NNS xj_NNS (_-LRB- j=1_CD ,…..,J)_NN and_CC a_DT response_NN variable_JJ y_NN presenting_VBG K_NNP classes_NNS ._. Such_JJ response_NN classes_NNS identify_VBP the_DT initial_JJ set_NN of_IN classes_NNS C(0_IN )_-RRB- =(_NNS c1,c2_VBD ,….,cK)_NNP ._. Partitioning_NNP X_NNP with_IN respect_NN to_TO C(0_VB )_-RRB- allows_VBZ to_TO identify_VB K_NNP disjoint_NN subsets_NNS X(_IN 0)k_JJ ,_, such_JJ that_IN :_: X(_NNP 0)k_NNP =_SYM {xs_VBZ :_: ys_NNS ∈_VBP ck}_NNS ,_, with_IN s=1_NN ,…..,N._NNP In_IN practice_NN ,_, X(_NNP 0)k_NNP is_VBZ the_DT set_NN of_IN observations_NNS presenting_VBG the_DT k-th_JJ class_NN of_IN y_NN ._. The_DT algorithms_NNS works_VBZ by_IN aggregating_VBG the_DT K_NNP classes_NNS in_IN pairs_NNS and_CC learns_VBZ a_DT classifier_NN to_TO each_DT subset_NN of_IN corresponding_JJ observations_NNS ._. The_DT “best_NN ”_NN aggregation_NN (_-LRB- super-class_NN )_-RRB- is_VBZ chosen_VBN as_IN the_DT one_CD minimizing_VBG the_DT generalization_NN error_NN estimated_VBN using_VBG V-fold_JJ cross-validation_NN ._. Suppose_VB that_DT ,_, in_IN the_DT A-th_JJ iteration_NN of_IN the_DT algorithm_NN such_JJ a_DT best_JJS aggregation_NN is_VBZ found_VBN for_IN the_DT pair_NN of_IN classes_NNS ci*_NNS and_CC cj*_NNS (_-LRB- with_IN i*≠_NN j_NN and_CC i*_NN ,_, j*_NN ∈_NN (_-LRB- 1_CD ,…._NN ,K)_NN )_-RRB- that_WDT allows_VBZ to_TO aggregate_VB the_DT subsets_NNS Xi*_NNP and_CC Xj*._NNP Denoting_NNP with_IN T(_NNP i*_, ,j*)_VBD the_DT decision_NN tree_NN minimizing_VBG the_DT cross-validated_JJ generalization_NN error_NN δ(_IN A)cv_NNP ,_, the_DT heuristic_JJ for_IN selecting_VBG the_DT “best_NN ”_VBZ decision_NN tree_NN can_MD be_VB formalized_VBN as_IN follows_VBZ :_: (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- {_NN }_NN ,_, (_-LRB- ,_, )_-RRB- *_NNP ,_, *_NNP arg_CC min_NN |cv_NN i_IN ji_RB j_RB i_IN j_NN i_IN j_NN Tδ=_NNP ∩X_NNP XA_NNP (_-LRB- 12_CD )_-RRB- The_DT SACCS_NNP algorithm_NN is_VBZ analytically_RB described_VBN in_IN Table_NN 1_CD ._. It_PRP proceeds_VBZ by_IN learning_VBG all_PDT the_DT possible_JJ decision_NN trees_NNS obtainable_VBN by_IN joining_VBG in_IN pairs_NNS the_DT K_NNP subgroups_NNS ,_, and_CC by_IN retaining_VBG the_DT one_CD satisfying_VBG the_DT selection_NN criteria_NNS introduced_VBN in_IN (_-LRB- 12_CD )_-RRB- ._. After_IN the_DT A-th_JJ aggregation_NN ,_, the_DT number_NN of_IN subgroups_NNS is_VBZ reduced_VBN to_TO K(A-1_JJ )_-RRB- -_: 1_CD ,_, since_IN the_DT subgroups_NNS of_IN observations_NNS presenting_VBG the_DT response_NN classes_NNS ci*_VBP and_CC cj*_NNS are_VBP discarded_VBN from_IN the_DT original_JJ partition_NN and_CC replaced_VBN by_IN the_DT subset_NN X(_IN A_DT )(_JJ i*_NN ,j*)_, =_SYM X(_JJ i*_NN )_-RRB- ∩_VBZ X(_JJ j*)_NNS identified_VBN by_IN the_DT super-class_NN c(_NN A_DT )_-RRB- =_SYM (_-LRB- c(_JJ i*_NN )_-RRB- ∩_VBZ c(_JJ j*)_NN )_-RRB- ._. The_DT initial_JJ set_NN of_IN classes_NNS C_NNP is_VBZ replaced_VBN by_IN C(_JJ A_DT )_-RRB- ,_, the_DT latter_NN being_VBG composed_VBN of_IN a_DT reduced_JJ number_NN of_IN classes_NNS since_IN some_DT of_IN the_DT original_JJ classes_NNS form_VBP the_DT superclasses_NNS coming_VBG out_RB from_IN the_DT A_NNP aggregations_NNS ._. Likewise_RB ,_, also_RB X(_DT A)k_NNP is_VBZ formed_VBN by_IN a_DT lower_JJR number_NN of_IN subsets_NNS as_IN a_DT consequence_NN of_IN the_DT A_NNP aggregations_NNS ._. The_DT algorithm_NN proceeds_VBZ sequentially_RB in_IN the_DT iteration_NN A+1_. by_IN searching_VBG for_IN the_DT most_JJS accurate_JJ decision_NN tree_NN over_IN all_DT the_DT possible_JJ ones_NNS obtainable_VBN by_IN joining_VBG in_IN pairs_NNS the_DT K(_JJ A_DT )_-RRB- subgroups_NNS ._. The_DT sequential_JJ search_NN is_VBZ repeated_VBN until_IN the_DT number_NN of_IN subgroups_NNS reduces_VBZ to_TO one_CD in_IN the_DT K-th_NNP www.intechopen.com_NN Evolutionary_NNP Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NNP 457_CD iteration_NN ._. The_DT decision_NN tree_NN learned_VBN on_IN the_DT last_JJ subgroup_NN corresponds_NNS to_TO the_DT one_CD obtainable_NN applying_VBG the_DT recursive_JJ partitioning_NN algorithm_NN on_IN the_DT original_JJ dataset_NN ._. The_DT output_NN of_IN the_DT procedure_NN is_VBZ a_DT sequence_NN of_IN sets_NNS of_IN response_NN classes_NNS C(_JJ 1_CD )_-RRB- ,_, ….,C(_JJ K−1_NNP )_-RRB- with_IN the_DT associated_JJ sets_NNS of_IN decision_NN trees_NNS T(_JJ 1_CD )_-RRB- ,…..,T(_JJ K−1_NNP )_-RRB- ._. The_DT latter_NN are_VBP derived_VBN by_IN learning_VBG K_NNP −_NNP k_NN trees_NNS (k_JJ =_SYM 1_CD ,_, ….._NNP ,_, K_NNP −_NNP 1_CD )_-RRB- on_IN disjoint_NN subgroups_NNS of_IN observations_NNS whose_WP$ response_NN classes_NNS complete_JJ the_DT initial_JJ set_NN of_IN classes_NNS C(0_IN )_-RRB- :_: these_DT response_NN classes_NNS identify_VBP the_DT super-classes_NNS relating_VBG to_TO the_DT sets_NNS of_IN classifiers_NNS T(k_NNP )_-RRB- ._. An_DT overall_JJ generalization_NN error_NN is_VBZ associated_VBN to_TO each_DT T(k_NN )_-RRB- :_: such_JJ an_DT error_NN is_VBZ also_RB based_VBN on_IN V-fold_NNP cross-validation_NN and_CC it_PRP is_VBZ computed_VBN as_IN a_DT weighted_JJ average_NN of_IN the_DT generalization_NN errors_NNS obtained_VBN from_IN each_DT of_IN the_DT K_NNP −_NNP k_NN decision_NN trees_NNS composing_VBG the_DT set_NN ._. In_IN accordance_NN to_TO the_DT previously_RB introduced_VBN notation_NN ,_, the_DT overall_JJ generalization_NN errors_NNS can_MD be_VB denoted_VBN as_IN Θ(_JJ 1)cv_CD ,_, ……_RB ,_, Θ(k)cv_NNP ,_, ……._NNP ,_, Θ(K-1)cv_NNP ._. Of_IN course_NN ,_, by_IN decreasing_VBG the_DT number_NN of_IN trees_NNS composing_VBG a_DT sequence_NN T(_JJ k_NN )_-RRB- (_-LRB- that_DT is_VBZ ,_, when_WRB moving_VBG k_NN from_IN 1_CD to_TO K−1_VB )_-RRB- the_DT corresponding_JJ Θ(k)cv_NN increases_NNS since_IN the_DT number_NN of_IN super-classes_NNS associated_VBN to_TO T(_JJ k_NN )_-RRB- is_VBZ also_RB decreasing_VBG ._. This_DT means_VBZ that_IN a_DT lower_JJR number_NN of_IN trees_NNS are_VBP learned_VBN on_IN more_JJR heterogeneous_JJ subsets_NNS of_IN observations_NNS ,_, since_IN each_DT of_IN those_DT subsets_NNS pertain_VBP to_TO a_DT relatively_RB large_JJ number_NN of_IN response_NN classes_NNS ._. {_NN }_NN (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- {_NN }_JJ (_-LRB- )_-RRB- {_NN }_JJ (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- {_NN }_JJ (_-LRB- )_-RRB- {_NN }_JJ (_-LRB- )_-RRB- (_-LRB- )_-RRB- 1_CD ;_: ;_: ,_, 1_CD ,_, ,_, 00_CD 0_CD 1_CD ,_, ,_, ;_: 1_CD ,_, ,_, *_JJ *_NNS *_IN **_NNP ,_, *_NNP 1_CD 1_CD 2_CD 1_CD 1_CD ,_, ,_, 1_CD 1_CD ,_, ,_, ;_: ;_: :_: 1_CD :_: |_NN min_NN 1_CD ,_, ,_, :_: ,_, i_FW j_FW K_NNP c_NN c_NN i_IN j_NNS i_IN j_NN K_NNP s_VBZ s_PRP kk_CC s_VBZ N_NNP k_NN K_NNP i_IN j_NN cv_NN i_IN ji_RB j_RB K_NNP s_VBZ s_PRP kk_CC k_VB K_NNP C_NNP c_NN c_NNS C_NNP C_NNP K_NNP K_NNP y_NNP c_NN K_NNP c_NN c_NN c_NN T_NNP K_NNP K_NNP C_NNP c_NN c_NNS c_SYM y_RB c_SYM C_NNP θ_NNS ∩_IN =_SYM ∅_CD ≠_CD ∈_NN =_SYM =_SYM −_JJR −_NN +_NN =_SYM −_FW =_SYM =_SYM =_SYM =_SYM ∈_VBN =_SYM ∩_JJR ∩_NN =_SYM =_SYM −_VBN =_SYM =_SYM =_SYM ∈_JJ Input_NN :_: Set_VB :_: X_NNP x_NN For_IN :_: in_IN to_TO X_NNP X_NNP X_NNP x_NN end_NN For_IN Output_NN :_: A_DT A_NNP …_NN …_NN …_IN A_DT A_NNP A_NNP A_NNP A_NNP A_NNP A_NNP …_NN …_NN A_DT …_NN …_NN (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )1_CD 1_CD 11_CD 1_CD ,_, ;_: ,_, ,_, ;_: ,_, ,_, K_NNP Kcv_NNP cvKC_NN T_NNP T−_NNP −_NNP −_NNP Θ_NNP Θ_NNP …_NN …_NNP Table_NNP 1_CD ._. The_DT SASSC_NNP algorithm_NN Taking_VBG this_DT inverse_NN relationship_NN into_IN account_NN ,_, the_DT analyst_NN can_MD be_VB aware_JJ of_IN the_DT overall_JJ prediction_NN accuracy_NN of_IN the_DT final_JJ model_NN on_IN the_DT basis_NN of_IN the_DT relative_JJ increase_NN in_IN Θ(k)cv_NN when_WRB moving_VBG from_IN 1_CD to_TO K−1_VB ._. In_IN this_DT respect_NN ,_, he_PRP can_MD select_VB the_DT suitable_JJ number_NN of_IN decision_NN trees_NNS to_TO be_VB included_VBN in_IN the_DT final_JJ classification_NN model_NN accordingly_RB ._. Supposing_VBG that_IN a_DT final_JJ subset_NN of_IN g_VBG decision_NN trees_NNS has_VBZ been_VBN selected_VBN (_-LRB- g<<K−1_NN )_-RRB- ,_, the_DT estimated_VBN classification_NN model_NN can_MD be_VB represented_VBN as_IN :_: (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )1_NN ,_, 1_CD 1_CD 1_CD ˆ_NN ˆ_IN ˆ_NNP ,_, ,_, i_IN i_IN i_FW Mg_NNP i_FW k_FW i_FW p_NN m_NN i_IN m_NN f_NN c_NN I_PRP x_SYM x_NN Rψ−_NNP =_SYM =_SYM =_SYM ∈∑∑x_NN …_NN (_-LRB- 13_CD )_-RRB- The_DT parameter_NN ψ_NN is_VBZ called_VBN “vehicle_NN parameter”_NN ._. It_PRP allows_VBZ to_TO assign_VB a_DT new_JJ observation_NN to_TO the_DT most_RBS suitable_JJ decision_NN tree_NN in_IN the_DT subset_NN g_NN ._. It_PRP is_VBZ defined_VBN by_IN a_DT set_NN of_IN g−1_DT dummy_JJ variables_NNS ._. Each_DT of_IN them_PRP equals_VBZ 1_CD if_IN the_DT object_NN belongs_VBZ to_TO the_DT i-th_JJ decision_NN tree_NN (_-LRB- i_FW =_SYM 1_CD ,…_CD ,_, g−1_CD )_-RRB- and_CC zero_CD otherwise_RB ._. The_DT Mi_NNP regions_NNS ,_, corresponding_JJ to_TO the_DT number_NN of_IN terminal_JJ nodes_NNS of_IN the_DT decision_NN www.intechopen.com_NN Advances_NNS in_IN Evolutionary_NNP Algorithms_NNP 458_IN tree_NN i_NN ,_, are_VBP created_VBN by_IN splits_NNS on_IN predictors_NNS (_-LRB- x1_CD ,…._NN ,xp_NN )_-RRB- ._. The_DT classification_NN tree_NN i_NN assigns_VBZ a_DT new_JJ observation_NN to_TO the_DT class_NN ,ˆk_NN ic_NN of_IN y_NN according_VBG to_TO the_DT region_NN i_IN mR_NN ._. I_PRP is_VBZ an_DT indicator_NN function_NN with_IN value_NN 1_CD if_IN an_DT observation_NN belongs_VBZ to_TO i_DT mR_NN and_CC value_NN 0_IN if_IN not_RB ._. i_IN mR_NN is_VBZ defined_VBN by_IN the_DT inputs_NNS used_VBN in_IN the_DT splits_NNS leading_VBG to_TO that_DT terminal_NN node_NN ._. The_DT modal_JJ class_NN of_IN the_DT observations_NNS in_IN a_DT region_NN i_NN mR_NN (_-LRB- also_RB called_VBN the_DT m-th_JJ terminal_NN node_NN of_IN the_DT i-th_JJ decision_NN tree_NN )_-RRB- is_VBZ usually_RB taken_VBN as_IN an_DT estimate_NN for_IN ,ˆk_NNP ic_JJ ._. This_DT notation_NN is_VBZ consistent_JJ with_IN that_DT used_VBN in_IN Hastie_NNP et_NNP al_NN ._. (_-LRB- 2001_CD )_-RRB- ._. The_DT estimation_NN of_IN τi_NNP is_VBZ based_VBN on_IN the_DT prediction_NN accuracy_NN of_IN each_DT decision_NN tree_NN in_IN the_DT final_JJ subset_NN g_NN ._. A_DT new_JJ observation_NN is_VBZ slipped_VBN into_IN each_DT of_IN the_DT g_NN trees_NNS ._. The_DT assigned_VBN class_NN ,ˆk_NN ic_NN is_VBZ found_VBN with_IN respect_NN to_TO the_DT tree_NN whose_WP$ terminal_NN node_NN better_RB classifies_VBZ the_DT new_JJ observation_NN ._. In_IN other_JJ words_NNS ,_, a_DT new_JJ observation_NN is_VBZ assigned_VBN to_TO the_DT purest_NN terminal_NN node_NN among_IN all_PDT the_DT g_JJ decision_NN trees_NNS ._. Another_DT option_NN of_IN the_DT algorithm_NN is_VBZ the_DT possibility_NN to_TO learn_VB decision_NN trees_NNS to_TO select_VB the_DT suitable_JJ pair_NN of_IN response_NN classes_NNS satisfying_VBG (_-LRB- 12_CD )_-RRB- using_VBG alternative_NN splitting_JJ criteria_NNS ._. As_IN for_IN CART_NNP ,_, it_PRP is_VBZ possible_JJ to_TO refer_VB to_TO both_DT the_DT Gini_NNP index_NN and_CC Twoing_NNP as_IN alternative_JJ splitting_JJ rules_NNS ._. It_PRP is_VBZ known_VBN that_IN ,_, unlike_IN Gini_NNP rule_NN ,_, Twoing_VBG searches_NNS for_IN the_DT two_CD classes_NNS that_WDT make_VBP up_RP together_RB more_JJR than_IN 50_CD %_NN of_IN the_DT data_NNS and_CC allows_VBZ us_PRP to_TO build_VB more_JJR balanced_VBN trees_NNS even_RB if_IN the_DT resulting_VBG recursive_JJ partitioning_NN algorithm_NN works_VBZ slower_RBR ._. As_IN an_DT example_NN ,_, if_IN the_DT total_JJ number_NN of_IN classes_NNS is_VBZ equal_JJ to_TO K_NNP ,_, Twoing_NNP uses_VBZ 2K−1_CD possible_JJ splits_NNS ._. Since_IN it_PRP has_VBZ been_VBN proved_VBN (_-LRB- Breiman_NNP et_NNP al_NN ._. ,_, 1984_CD ,_, pag.95_VBD )_-RRB- that_IN the_DT decision_NN tree_NN is_VBZ insensitive_JJ to_TO the_DT choice_NN of_IN the_DT splitting_JJ rule_NN ,_, it_PRP can_MD be_VB interesting_JJ to_TO see_VB how_WRB it_PRP works_VBZ in_IN a_DT framework_NN characterized_VBN by_IN the_DT search_NN of_IN the_DT most_RBS accurate_JJ decision_NN treers_NNS like_IN the_DT one_CD introduced_VBN in_IN SASSC._NNP 5_CD ._. Application_NNP on_IN real_JJ and_CC simulated_VBN datasets_NNS Genetic_JJ Algorithm_NNP ._. The_DT proposed_VBN GA_NNP has_VBZ been_VBN applied_VBN on_IN two_CD datasets_NNS for_IN which_WDT the_DT optimal_JJ best_JJS split_NN could_MD be_VB calculated_VBN and_CC for_IN a_DT more_RBR complex_JJ one_CD ,_, for_IN which_WDT it_PRP is_VBZ not_RB possible_JJ to_TO proceed_VB with_IN such_JJ a_DT brute_NN force_NN strategy_NN ._. The_DT first_JJ test_NN has_VBZ been_VBN done_VBN on_IN the_DT “Mushroom”_NNP dataset_NN ,_, available_JJ from_IN the_DT UCI_NNP Machine_NNP Learning_NNP Repository_NNP (_-LRB- source_NN http_NN ://archive_NN .ics_NNS .uci.edu/ml/_VBP )_-RRB- ._. This_DT dataset_NN has_VBZ a_DT two-class_JJ response_NN variable_JJ (_-LRB- “is_IN the_DT mushroom_NN poisonous_JJ ?”_NN )_-RRB- and_CC set_NN of_IN categorical_JJ and_CC numerical_JJ predictors_NNS ._. One_CD of_IN them_PRP (_-LRB- gill_NN colour_NN )_-RRB- has_VBZ 12_CD categories_NNS (attributes_NNS )_-RRB- ,_, which_WDT can_MD be_VB evaluated_VBN exhaustively_RB ._. The_DT GA_NNP algorithm_NN could_MD find_VB the_DT global_JJ best_JJS solution_NN (_-LRB- which_WDT was_VBD extracted_VBN by_IN using_VBG the_DT Rpart_NN package_NN of_IN the_DT R_NN software_NN )_-RRB- in_IN less_JJR than_IN 10_CD iterations_NNS ._. The_DT algorithm_NN has_VBZ then_RB been_VBN tested_VBN on_IN a_DT simulated_VBN dataset_NN which_WDT was_VBD obtained_VBN by_IN uniformly_RB generating_VBG a_DT response_NN variable_JJ with_IN 26_CD modalities_NNS and_CC a_DT nominal_JJ unordered_JJ predictor_NN with_IN 16_CD modalities_NNS for_IN 20,000_CD observations_NNS ._. By_IN letting_VBG be_VB 16_CD the_DT number_NN of_IN modalities_NNS of_IN the_DT splitting_NN predictor_NN it_PRP was_VBD possible_JJ ,_, also_RB in_IN this_DT case_NN ,_, to_TO find_VB the_DT (_-LRB- global_JJ )_-RRB- best_JJS split_NN by_IN making_VBG use_NN of_IN the_DT exhaustive_JJ enumeration_NN ._. Such_JJ experimental_JJ studies_NNS showed_VBD that_IN the_DT most_RBS efficient_JJ configuration_NN of_IN the_DT GA_NNP was_VBD the_DT following_VBG :_: •_JJ By_IN randomly_RB selecting_VBG the_DT initial_JJ population_NN (_-LRB- no_DT other_JJ solutions_NNS have_VBP been_VBN tried_VBN ,_, in_IN fact_NN )_-RRB- ._. •_'' By_IN setting_VBG the_DT number_NN of_IN solutions_NNS building_VBG the_DT population_NN to_TO be_VB equal_JJ to_TO the_DT number_NN of_IN necessary_JJ genes_NNS (_-LRB- the_DT number_NN of_IN categories_NNS of_IN the_DT predictor_NN )_-RRB- ._. •_'' By_IN setting_VBG a_DT crossover_JJ proportion_NN of_IN 0.80_CD ._. •_'' By_IN setting_VBG a_DT mutation_NN probability_NN equal_JJ to_TO 0.10_CD ._. •_'' By_IN selecting_VBG the_DT rank_NN for_IN choosing_VBG the_DT solutions_NNS to_TO be_VB recombined_VBN ._. www.intechopen.com_'' Evolutionary_NNP Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NNP 459_CD For_IN this_DT kind_NN of_IN problem_NN (_-LRB- 20,000_CD units_NNS ,_, 16_CD categories_NNS for_IN the_DT response_NN variable_JJ and_CC 26_CD categories_NNS for_IN the_DT splitting_JJ predictor_NN )_-RRB- the_DT global_JJ optimum_NN was_VBD reached_VBN in_IN less_JJR than_IN 30_CD iterations_NNS ._. When_WRB the_DT complexity_NN of_IN the_DT problem_NN grows_VBZ many_JJ iterations_NNS seems_VBZ to_TO be_VB required_VBN ,_, though_IN such_JJ number_NN never_RB appeared_VBD to_TO grow_VB exponentially_RB ._. The_DT GA_NNP has_VBZ been_VBN tested_VBN also_RB on_IN the_DT “Adult_NN ”_NN dataset_NN available_JJ from_IN the_DT UCI_NNP Machine_NN Learning_VBG website_JJ ._. This_DT dataset_NN has_VBZ been_VBN extracted_VBN from_IN the_DT US_NNP Census_NNP Bureau_NNP Database_NNP (_-LRB- source_NN :_: http_JJ ://www.census.gov/_NN )_-RRB- with_IN the_DT aim_NN of_IN predicting_VBG whether_IN a_DT person_NN earns_VBZ more_JJR than_IN 50,000_CD dollars_NNS per_IN year_NN ._. Such_JJ dataset_NN has_VBZ 325,614_CD observations_NNS and_CC some_DT categorical_JJ unordered_JJ splitting_NN predictors_NNS with_IN many_JJ attributes_NNS ._. In_IN particular_JJ ,_, the_DT native-country_JJ predictor_NN has_VBZ 42_CD attributes_NNS ._. State_NN Goes_VBZ to_TO State_NNP Goes_NNP to_TO United-States_NNP Left_NNP Cuba_NNP Left_VBD Jamaica_NNP Right_NNP India_NNP Left_NNP Unknown_NNP Country_NNP Left_VBD Mexico_NNP Right_NNP South_NNP Left_VBD Puerto-Rico_NNP Right_NNP Honduras_NNP Right_RB England_NNP Left_NNP Canada_NNP Left_VBD Germany_NNP Left_VBD Iran_NNP Left_VBD Philippines_NNP Left_VBD Italy_NNP Left_VBD Poland_NNP Left_VBD Columbia_NNP Right_NNP Cambodia_NNP Left_VBD Thailand_NNP Left_VBD Ecuador_NNP Right_RB Laos_NNP Right_RB Taiwan_NNP Left_VBD Haiti_NNP Right_NNP Portugal_NNP Right_RB Dominican-Republic_NNP Right_RB El-Salvador_NNP Right_NNP France_NNP Left_VBD Guatemala_NNP Right_NNP China_NNP Left_VBD Japan_NNP Left_VBD Yugoslavia_NNP Left_VBD Peru_NNP Right_NNP Outlying-US_NNP Right_RB Scotland_NNP Left_VBD Trinadad-Tobago_NNP Right_NNP Greece_NNP Left_VBD Nicaragua_NNP Right_NNP Vietnam_NNP Right_RB Hong_NNP Left_VBD Ireland_NNP Left_VBD Hungary_NNP Left_VBD Holland-Netherlands_NNP Right_NNP Table_NNP 2._JJS The_DT split_NN provided_VBN by_IN the_DT GA_NNP for_IN the_DT native-country_NN in_IN the_DT Adult_NN dataset_NN The_DT GA_NNP has_VBZ been_VBN run_VBN with_IN the_DT aim_NN of_IN trying_VBG to_TO find_VB a_DT good_JJ split_NN by_IN making_VBG use_NN of_IN the_DT native-_NNS country_NN splitting_NN predictor_NN that_IN both_DT R_NN and_CC SPSS_NNP ,_, for_IN instance_NN ,_, refused_VBD to_TO process_VB ._. As_IN previously_RB mentioned_VBN ,_, 30_CD iterations_NNS seemed_VBD to_TO be_VB not_RB enough_RB because_IN ,_, in_IN many_JJ runs_NNS of_IN the_DT algorithm_NN ,_, the_DT “probably_RB best_JJS ”_JJ solution_NN appeared_VBD after_IN iteration_NN 80_CD ._. The_DT solution_NN provided_VBN by_IN the_DT algorithm_NN is_VBZ shown_VBN in_IN Table_NN 2._. It_PRP gives_VBZ an_DT idea_NN of_IN the_DT complexity_NN of_IN the_DT problem_NN ._. The_DT corresponding_JJ decrease_NN in_IN the_DT node_NN impurity_NN is_VBZ 0.3628465_CD ._. The_DT algorithm_NN has_VBZ been_VBN tested_VBN over_IN many_JJ simulated_JJ dataset_NN and_CC the_DT number_NN of_IN required_VBN iterations_NNS for_IN the_DT algorithm_NN to_TO reach_VB convergence_NN has_VBZ been_VBN shown_VBN to_TO linearly_RB grow_VB as_IN a_DT function_NN of_IN the_DT number_NN of_IN attributes_NNS of_IN the_DT splitting_NN predictor_NN (_-LRB- the_DT number_NN of_IN observations_NNS in_IN the_DT dataset_NN appeared_VBD to_TO be_VB uninfluential_JJ )_-RRB- ._. www.intechopen.com_NN Advances_NNS in_IN Evolutionary_NNP Algorithms_NNP 460_CD Ant_NNP System_NNP ._. The_DT strong_JJ complexity_NN of_IN the_DT decision_NN tree_NN growing_VBG procedure_NN (_-LRB- Hyafil_NNP &_CC Rivest_NNP ,_, 1976_CD )_-RRB- does_VBZ not_RB allow_VB to_TO exhaustively_RB enumerate_VB and_CC evaluate_VB all_DT the_DT possible_JJ generable_JJ trees_NNS ,_, even_RB from_IN very_RB small_JJ datasets_NNS ._. In_IN this_DT respect_NN ,_, it_PRP is_VBZ not_RB possible_JJ to_TO check_VB whether_IN the_DT chosen_VBN heuristic_NN is_VBZ able_JJ to_TO find_VB the_DT global_JJ optimum_NN (_-LRB- in_IN the_DT same_JJ manner_NN as_IN it_PRP has_VBZ been_VBN previously_RB done_VBN for_IN the_DT genetic_JJ algorithm_NN )_-RRB- ._. In_IN the_DT first_JJ experiment_NN the_DT algorithm_NN has_VBZ been_VBN tested_VBN on_IN a_DT simulated_VBN dataset_NN of_IN 500_CD observations_NNS with_IN 11_CD nominal_JJ unordered_JJ predictors_NNS (_-LRB- with_IN a_DT number_NN of_IN attributes_NNS that_WDT ranges_VBZ between_IN 2_CD and_CC 9_CD )_-RRB- and_CC 2_CD numeric_JJ (_-LRB- continuous_JJ )_-RRB- predictors_NNS ._. It_PRP could_MD be_VB seen_VBN that_IN ,_, when_WRB the_DT required_VBN tree_NN depth_NN increases_VBZ ,_, the_DT differences_NNS between_IN the_DT global_JJ impurity_NN of_IN the_DT tree_NN obtained_VBN by_IN the_DT CART_NNP greedy_JJ heuristic_JJ and_CC the_DT one_CD obtained_VBN by_IN the_DT Ant_NNP System_NNP tend_VBP to_TO increase_VB ._. Table_NN 3_CD reports_NNS such_JJ results_NNS ._. Tree_NNP Depth_NNP CART_NNP Ant_NNP System_NNP 4_CD 0.158119_CD 0.153846_CD 5_CD 0.147435_CD 0.121794_CD 6_CD 0.100427_CD 0.085477_CD 7_CD 0.079059_CD 0.059829_CD 8_CD 0.044871_CD 0.029911_CD Table_NN 3.Global_JJ impurity_NN of_IN the_DT decision_NN trees_NNS extracted_VBN by_IN the_DT proposed_VBN algorithm_NN on_IN a_DT simulated_VBN dataset_NN Figure_NN 2_CD shows_VBZ the_DT result_NN obtained_VBN on_IN the_DT “Credit_NN ”_NN dataset_NN that_WDT can_MD be_VB found_VBN in_IN the_DT SPAD_NN software_NN (_-LRB- source_NN :_: www_JJ .spadsoft.com_NN )_-RRB- ._. This_DT dataset_NN has_VBZ 468_CD observations_NNS on_IN which_WDT 11_CD nominal_JJ variables_NNS have_VBP been_VBN observed_VBN together_RB with_IN a_DT two-class_JJ response_NN variable_JJ ._. The_DT aim_NN would_MD be_VB to_TO predict_VB such_JJ response_NN variable_JJ (_-LRB- “is_IN a_DT customer_NN good_JJ or_CC bad_JJ ?_. )_-RRB- ._. The_DT first_JJ decision_NN tree_NN is_VBZ the_DT one_CD found_VBN by_IN the_DT CART_NNP heuristic_NN and_CC the_DT second_JJ one_NN has_VBZ been_VBN extracted_VBN after_IN 200_CD iterations_NNS of_IN the_DT Ant_NNP System_NNP algorithm_NN ._. Table_NN 4_CD shows_NNS the_DT global_JJ impurity_NN of_IN the_DT trees_NNS extracted_VBN by_IN the_DT CART_NNP and_CC Ant_NNP heuristics_NNS ._. Fig_NN ._. 2._'' Decision_NNP Trees_NNP for_IN the_DT Credit_NNP dataset_NN obtained_VBD using_VBG the_DT CART_NNP heuristic_JJ (_-LRB- left_JJ panel_NN )_-RRB- and_CC after_IN 200_CD iterations_NNS of_IN the_DT Ant_NNP System_NNP algorithm_NN (_-LRB- right_JJ panel_NN )_-RRB- ._. www.intechopen.com_'' The_DT algorithms_NNS presented_VBN here_RB are_VBP in_IN an_DT early_JJ stage_NN of_IN development_NN ._. In_IN these_DT examples_NNS ,_, an_DT Ant_NNP System_NNP has_VBZ been_VBN proposed_VBN to_TO attack_VB the_DT problem_NN of_IN finding_VBG the_DT best_JJS exploratory_JJ decision_NN tree_NN and_CC it_PRP came_VBD out_RP that_IN the_DT Ant_NNP System-based_JJ decision_NN trees_NNS performed_VBN better_RB than_IN the_DT ones_NNS found_VBN by_IN the_DT CART_NNP greedy_JJ heuristic_JJ ._. Even_RB if_IN the_DT improvements_NNS weren’t_VBD too_RB large_JJ Evolutionary_JJ Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NNP 461_CD Tree_NNP Depth_NNP CART_NNP Ant_NNP System_NNP 2_CD 0.2948_CD 0.2734_CD 3_CD 0.2435_CD 0.2301_CD 4_CD 0.2029_CD 0.1816_CD 5_CD 0.1773_CD 0.1517_CD 6_CD 0.1645_CD 0.1539_CD Table_NN 4_CD ._. Global_JJ impurity_NN of_IN the_DT decision_NN trees_NNS extracted_VBN by_IN the_DT proposed_VBN algorithm_NN on_IN the_DT Credit_NNP dataset_NN SASSC_NNP algorithm_NN ._. In_IN the_DT following_NN ,_, the_DT SASSC_NNP algorithm_NN is_VBZ applied_VBN on_IN the_DT “Letter_NN Recognition_NNP ”_NNP dataset_NN from_IN the_DT UCI_NNP Machine_NN Learning_VBG Repository_NNP (_-LRB- source_NN http_NN ://archive_NN .ics_NNS .uci.edu/ml/_VBP )_-RRB- ._. This_DT dataset_NN is_VBZ originally_RB analyzed_VBN in_IN Frey_NNP &_CC Slate_NNP (_-LRB- 1991_CD )_-RRB- ,_, who_WP did_VBD not_RB achieve_VB a_DT good_JJ performance_NN since_IN the_DT correct_JJ classified_JJ observations_NNS did_VBD never_RB exceed_VB 85_CD %_NN ._. Later_RBR on_RB ,_, the_DT same_JJ dataset_NN is_VBZ analyzed_VBN in_IN Fogarty(_JJ 1992_CD )_-RRB- using_VBG nearest_JJS neighbours_NNS classification_NN ._. Obtained_VBD results_NNS give_VB over_IN 95.4_CD %_NN accuracy_NN compared_VBN to_TO the_DT best_JJS result_NN of_IN 82.7_CD %_NN reached_VBN in_IN Frey_NNP &_CC Slate(_NNP 1991_CD )_-RRB- ._. Nevertheless_RB ,_, no_DT information_NN about_IN the_DT interpretability_NN of_IN the_DT nearest_JJS neighbour_NN classification_NN model_NN is_VBZ provided_VBN and_CC the_DT computational_JJ inefficiency_NN of_IN such_JJ a_DT procedure_NN is_VBZ deliberately_RB admitted_VBN by_IN the_DT authors_NNS ._. In_IN the_DT Letter_NNP Recognition_NNP analysis_NN ,_, the_DT task_NN is_VBZ to_TO classify_VB 20_CD ,_, 000_CD black-and-white_JJ rectangular_JJ pixel_NN displays_NNS into_IN one_CD of_IN the_DT 26_CD letters_NNS in_IN the_DT English_NNP alphabet_NN ._. The_DT character_NN images_NNS are_VBP based_VBN on_IN 20_CD different_JJ fonts_NNS and_CC each_DT letter_NN within_IN these_DT 20_CD fonts_NNS was_VBD randomly_RB distorted_VBN to_TO produce_VB a_DT file_NN of_IN 20,000_CD unique_JJ stimuli_NNS ._. Each_DT stimulus_NN was_VBD converted_VBN into_IN 16_CD numerical_JJ attributes_NNS that_WDT have_VBP to_TO be_VB submitted_VBN to_TO a_DT decision_NN tree_NN ._. Dealing_VBG with_IN K_NNP =_SYM 26_CD response_NN classes_NNS ,_, SASSC_NNP provides_VBZ 25_CD sequential_JJ aggregations_NNS ._. Classification_NN trees_NNS aggregated_VBN at_IN each_DT single_JJ step_NN were_VBD chosen_VBN according_VBG to_TO 10-fold_JJ cross_NN validation_NN ._. A_DT tree_NN was_VBD aggregated_VBN to_TO the_DT sequence_NN if_IN it_PRP provided_VBD the_DT lowest_JJS cross_NN validated_VBD generalization_NN error_NN with_IN respect_NN to_TO the_DT other_JJ trees_NNS obtainable_JJ from_IN different_JJ aggregations_NNS of_IN (_-LRB- subgroups_NNS of_IN )_-RRB- response_NN classes_NNS ._. The_DT results_NNS of_IN the_DT SASSC_NNP algorithm_NN are_VBP summarized_VBN in_IN Figure_NN 3._. It_PRP compares_VBZ the_DT performance_NN of_IN the_DT SASSC_NNP model_NN formed_VBD by_IN g=2_VBG up_RP to_TO g=6_VB superclasses_NNS with_IN that_DT of_IN CART_NNP using_VBG ,_, in_IN all_DT cases_NNS ,_, either_CC Gini_NNP or_CC Twoing_NNP as_IN splitting_JJ rules_NNS ._. Bagging_NN (_-LRB- Brieman_NNP ,_, 1996_CD )_-RRB- and_CC Random_NNP Forest_NNP (_-LRB- Breiman_NNP ,_, 2001_CD )_-RRB- are_VBP used_VBN as_IN benchmarking_VBG methods_NNS as_RB well_RB ._. Computations_NNS have_VBP been_VBN carried_VBN out_RP using_VBG the_DT R_NN software_NN for_IN statistical_JJ computing_NN ._. The_DT SASSC_NNP model_NN using_VBG 2_CD superclasses_NNS consistently_RB improves_VBZ the_DT results_NNS of_IN CART_NNP using_VBG the_DT Gini_NNP (_-LRB- Twoing_NN )_-RRB- splitting_NN rule_NN since_IN the_DT generalization_NN error_NN reduces_VBZ to_TO 0.49_CD (_-LRB- 0.34_CD )_-RRB- from_IN 0.52_CD (_-LRB- 0.49_CD )_-RRB- ._. As_IN expected_VBN ,_, the_DT choice_NN of_IN the_DT splitting_NN rule_NN (_-LRB- Gini_NNP or_CC Twoing_NNP )_-RRB- is_VBZ relevant_JJ when_WRB the_DT number_NN of_IN superclasses_NNS g_VBG is_VBZ relatively_RB small_JJ (_-LRB- 2_CD ≤_NN g_NN ≤_IN 4)_CD ,_, whereas_IN it_PRP becomes_VBZ negligible_JJ for_IN higher_JJR values_NNS of_IN g_VBG (_-LRB- results_NNS for_IN g_VBG ≥_JJ 5_CD are_VBP almost_RB identical_JJ )_-RRB- ._. Focusing_NNP on_IN the_DT Gini_NNP splitting_NN criterion_NN ,_, the_DT SASSC’s_NNP generalization_NN error_NN further_RB reduces_VBZ to_TO 0.11_CD when_WRB the_DT number_NN of_IN subsets_NNS increases_NNS to_TO 6_CD ._. For_IN comparative_JJ purposes_NNS ,_, Bagging_NNP and_CC Random_NNP Forest_NNP have_VBP been_VBN www.intechopen.com_IN (_-LRB- from_IN 2_CD %_NN to_TO 5_CD %_NN in_IN all_DT of_IN the_DT simulation_NN studies_NNS )_-RRB- such_JJ algorithm_NN could_MD be_VB still_RB useful_JJ for_IN the_DT situations_NNS in_IN which_WDT high_JJ accuracy_NN is_VBZ required_VBN from_IN the_DT decision_NN tree_NN would_MD ._. Ant_NNP System_NNP ,_, on_IN the_DT other_JJ hand_NN ,_, is_VBZ the_DT simplest_JJS (yet_NN less_RBR efficient_JJ )_-RRB- ACO_NNP technique_NN ,_, so_RB that_IN the_DT use_NN of_IN more_JJR powerful_JJ ACO_NNP algorithms_NNS (_-LRB- which_WDT is_VBZ currently_RB under_IN development_NN )_-RRB- would_MD reasonably_RB bring_VB better_JJR results_NNS ._. It_PRP is_VBZ well_RB known_VBN that_IN ACO_NNP algorithms_NNS reach_VBP their_PRP$ maximum_JJ efficiency_NN when_WRB coupled_VBN with_IN local_JJ search_NN techniques_NNS or_CC can_MD improve_VB their_PRP$ efficiency_NN by_IN making_VBG use_NN of_IN candidate_NN lists_NNS ._. Advances_NNS in_IN Evolutionary_NNP Algorithms_NNP 462_CD trained_VBN using_VBG 6_CD and_CC 10_CD classifiers_NNS respectively_RB and_CC ,_, in_IN these_DT cases_NNS ,_, obtained_VBD generalization_NN errors_NNS are_VBP worse_JJR than_IN those_DT deriving_VBG from_IN SASSC_NNP with_IN g_VBG =_SYM 6_CD ._. As_IN for_IN Bagging_NNP and_CC Random_NNP Forest_NNP ,_, increasing_VBG the_DT number_NN of_IN trees_NNS used_VBN to_TO classify_VB each_DT subset_NN of_IN randomly_RB drawn_VBN objects_NNS improves_VBZ the_DT performance_NN of_IN these_DT two_CD methods_NNS in_IN terms_NNS of_IN prediction_NN accuracy_NN ._. The_DT reason_NN is_VBZ that_IN their_PRP$ predictions_NNS derive_VBP form_NN (_-LRB- “in-sample”_NN )_-RRB- independent_JJ bootstrap_NN replications_NNS ._. Instead_RB ,_, cross-validation_JJ predictions_NNS in_IN SASSC_NNP derives_NNS from_IN aggregations_NNS of_IN classifications_NNS made_VBN on_IN “out-of-sample_JJ ”_JJ observations_NNS that_WDT are_VBP excluded_VBN from_IN the_DT tree_NN growing_VBG procedure_NN ._. Thus_RB ,_, it_PRP is_VBZ natural_JJ to_TO expect_VB that_DT cross-validation_NN predictions_NNS are_VBP more_RBR inaccurate_JJ than_IN bagged_JJ ones_NNS ._. Of_IN course_NN ,_, increasing_VBG the_DT number_NN of_IN subsets_NNS of_IN the_DT response_NN classes_NNS in_IN SASSC_NNP reduces_VBZ the_DT cross-validated_JJ generalization_NN error_NN but_CC ,_, at_IN the_DT same_JJ time_NN ,_, increases_VBZ the_DT complexity_NN of_IN the_DT final_JJ classification_NN model_NN ._. In_IN spite_NN of_IN a_DT relatively_RB lower_JJR accuracy_NN ,_, interpretability_NN of_IN the_DT results_NNS in_IN SASSC_NNP with_IN g_VBG =_SYM 6_CD is_VBZ strictly_RB preserved_VBN ._. Figure_NN 3._VBZ The_DT generalization_NN errors_NNS for_IN the_DT Letter_NNP Recognition_NNP dataset_NN provided_VBN by_IN alternative_JJ approaches_NNS :_: as_IN for_IN SASSC_NNP ,_, subscript_NN G(_JJ T_NNP )_-RRB- indicates_VBZ the_DT Gini_NNP (_-LRB- Twoing_NN )_-RRB- splitting_NN rule_NN ,_, whereas_IN apex_NN g_NN indicates_VBZ the_DT number_NN of_IN superclasses_NNS (_-LRB- i_FW .e_FW ._. ,_, decision_NN trees_NNS )_-RRB- identified_VBN by_IN the_DT algorithm_NN ._. The_DT subscript_NN for_IN Bagging_NNP and_CC Random_NNP Forest_NNP indicates_VBZ the_DT number_NN of_IN trees_NNS used_VBN to_TO obtain_VB the_DT classification_NN by_IN majority_NN voting_NN ._. 6_CD ._. Discussion_NNP and_CC conclusions_NNS In_IN the_DT last_JJ two_CD decades_NNS ,_, computational_JJ enhancements_NNS highly_RB contributed_VBD to_TO the_DT increase_NN in_IN popularity_NN of_IN DTI_NNP algorithms_NNS ._. This_DT cause_NN the_DT successful_JJ use_NN of_IN Decision_NNP Tree_NNP Induction_NNP (DTI_NNP )_-RRB- using_VBG recursive_JJ partitioning_NN algorithms_NNS in_IN many_JJ diverse_JJ areas_NNS such_JJ as_IN radar_NN signal_NN classification_NN ,_, character_NN recognition_NN ,_, remote_JJ sensing_NN ,_, medical_JJ diagnosis_NN ,_, expert_JJ systems_NNS ,_, and_CC speech_NN recognition_NN ,_, to_TO name_VB only_RB a_DT few_JJ ._. But_CC recursive_JJ partitioning_NN and_CC DTI_NNP are_VBP two_CD faces_NNS of_IN www.intechopen.com_NN Evolutionary_NNP Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NNP 463_VBD the_DT same_JJ medal_NN ._. While_IN the_DT computational_JJ time_NN has_VBZ been_VBN rapidly_RB reducing_VBG ,_, the_DT statistician_NN is_VBZ making_VBG more_JJR use_NN of_IN computationally_RB intensive_JJ methods_NNS to_TO find_VB out_RP unbiased_JJ and_CC accurate_JJ classification_NN rules_NNS for_IN unlabelled_JJ objects_NNS ._. Nevertheless_RB ,_, DTI_NNP cannot_MD result_VB in_IN finding_VBG out_RP simply_RB a_DT number_NN (_-LRB- the_DT misclassification_NN error_NN )_-RRB- ,_, but_CC also_RB an_DT accurate_JJ and_CC interpretable_JJ model_NN ._. Software_NNP enhancements_VBZ based_VBN on_IN interactive_JJ user_NN interface_NN and_CC customized_VBD routines_NNS should_MD empower_VB the_DT effectiveness_NN of_IN trees_NNS with_IN respect_NN to_TO interpretability_NN ,_, identification_NN and_CC robustness_NN ._. The_DT latter_JJ considerations_NNS have_VBP been_VBN the_DT inspiration_NN for_IN the_DT algorithms_NNS presented_VBN in_IN this_DT chapter_NN aimed_VBD at_IN the_DT improvement_NN of_IN DTI_NNP effectiveness_NN ._. They_PRP lead_VBP to_TO easily_RB interpretable_JJ solutions_NNS for_IN rather_RB complicated_JJ data_NNS analysis_NN problems_NNS and_CC can_MD be_VB fruitfully_RB used_VBN in_IN different_JJ fields_NNS of_IN Knowledge_NNP Discovery_NNP from_IN Databases_NNPS (_-LRB- KDD_NNP )_-RRB- and_CC data_NNS mining_NN such_JJ as_IN ,_, for_IN example_NN ,_, web_NN mining_NN and_CC Customer_NNP Relationship_NNP Management_NNP (_-LRB- CRM_NN )_-RRB- ._. A_DT Genetic_NNP Algorithm_NNP for_IN multi-attribute_JJ predictor_NN splitting_NN is_VBZ proposed_VBN in_IN this_DT chapter_NN ._. It_PRP can_MD be_VB said_VBN that_IN the_DT proposed_VBN GA_NNP works_VBZ very_RB well_RB in_IN presence_NN of_IN treatable_JJ splitting_JJ predictors_NNS ,_, for_IN which_WDT the_DT exhaustive_JJ enumeration_NN is_VBZ affordable_JJ ._. The_DT algorithm_NN always_RB reaches_VBZ the_DT global_JJ optimum_NN very_RB quickly_RB ._. This_DT makes_VBZ possible_JJ to_TO think_VB positively_RB ,_, even_RB if_IN nothing_NN can_MD be_VB said_VBN ,_, of_IN course_NN ,_, about_IN the_DT case_NN in_IN which_WDT the_DT number_NN of_IN attributes_NNS gets_VBZ too_RB large_JJ for_IN the_DT exhaustive_JJ enumeration_NN and_CC evaluation_NN ._. Obtained_'' results_NNS can_MD be_VB considered_VBN definitely_RB useful_JJ in_IN those_DT cases_NNS where_WRB there_EX are_VBP no_DT other_JJ ways_NNS to_TO attack_VB the_DT problem_NN ._. Future_NN research_NN directions_NNS will_MD include_VB exhaustive_JJ enumerations_NNS on_IN bigger_JJR datasets_NNS on_IN a_DT grid_NN computing_VBG infrastructure_NN ._. In_IN addition_NN an_DT Ant_NNP Colony_NNP Optimization_NNP algorithm_NN is_VBZ also_RB proposed_VBN for_IN exploratory_NN tree_NN growing_VBG ._. Such_PDT algorithm_NN could_MD be_VB useful_JJ for_IN the_DT situations_NNS in_IN which_WDT high_JJ accuracy_NN is_VBZ required_VBN from_IN the_DT decision_NN tree_NN would_MD ._. Ant_NNP System_NNP ,_, on_IN the_DT other_JJ hand_NN ,_, is_VBZ the_DT simplest_JJS (yet_NN less_RBR efficient_JJ )_-RRB- ACO_NNP technique_NN ,_, so_RB that_IN the_DT use_NN of_IN more_JJR powerful_JJ ACO_NNP algorithms_NNS (_-LRB- which_WDT is_VBZ currently_RB under_IN development_NN )_-RRB- would_MD reasonably_RB bring_VB better_JJR results_NNS ._. It_PRP is_VBZ well_RB known_VBN that_IN ACO_NNP algorithms_NNS reach_VBP their_PRP$ maximum_JJ efficiency_NN when_WRB coupled_VBN with_IN local_JJ search_NN techniques_NNS or_CC can_MD improve_VB their_PRP$ efficiency_NN by_IN making_VBG use_NN of_IN candidate_NN lists_NNS ._. Finally_RB ,_, a_DT sequential_JJ search_NN algorithm_NN for_IN modelling_VBG multi-attribute_JJ response_NN through_IN DTI_NNP has_VBZ also_RB been_VBN introduced_VBN ._. The_DT motivation_NN underlying_VBG the_DT formalization_NN of_IN the_DT SASSC_NNP algorithm_NN derives_NNS from_IN the_DT following_JJ intuition_NN :_: basically_RB ,_, since_IN standard_JJ classification_NN trees_NNS unavoidably_RB lead_VBP to_TO prediction_NN inaccuracy_NN in_IN the_DT presence_NN of_IN multi-class_JJ response_NN ,_, it_PRP would_MD be_VB favourable_JJ to_TO look_VB for_IN a_DT relatively_RB reduced_JJ number_NN of_IN decision_NN trees_NNS each_DT one_CD relating_VBG to_TO a_DT subset_NN of_IN classes_NNS of_IN the_DT response_NN variable_JJ ,_, the_DT so_RB called_VBN super-classes_NNS ._. Reducing_VBG the_DT number_NN of_IN response_NN classes_NNS for_IN each_DT of_IN those_DT trees_NNS naturally_RB leads_VBZ to_TO improve_VB the_DT overall_JJ prediction_NN accuracy_NN ._. To_TO further_RBR enforce_VB this_DT guess_NN ,_, an_DT appropriate_JJ criterion_NN to_TO derive_VB the_DT correct_JJ number_NN of_IN super-classes_NNS and_CC the_DT most_RBS parsimonious_JJ tree_NN structure_NN for_IN each_DT of_IN them_PRP has_VBZ to_TO be_VB found_VBN ._. In_IN this_DT respect_NN ,_, a_DT sequential_JJ approach_NN that_IN automatically_RB proceeds_VBZ through_IN subsequent_JJ aggregations_NNS of_IN the_DT response_NN classes_NNS might_MD be_VB a_DT natural_JJ starting_VBG point_NN ._. The_DT analysis_NN of_IN the_DT Letter_NNP Recognition_NNP dataset_NN demonstrated_VBD that_IN the_DT SASSC_NNP algorithm_NN can_MD be_VB applied_VBN pursuing_VBG two_CD complementary_JJ goals_NNS :_: 1_CD )_-RRB- a_DT content-related_JJ goal_NN ,_, resulting_VBG in_IN the_DT specification_NN of_IN a_DT classification_NN model_NN that_WDT provides_VBZ a_DT good_JJ interpretation_NN of_IN the_DT results_NNS without_IN disregarding_VBG accuracy_NN ;_: 2_CD )_-RRB- a_DT performance-related_JJ goal_NN ,_, dealing_VBG with_IN the_DT development_NN of_IN a_DT model_NN resulting_VBG effective_JJ in_IN terms_NNS of_IN predictive_JJ accuracy_NN without_IN neglecting_VBG interpretability_NN ._. Taking_VBG these_DT considerations_NNS into_IN account_NN ,_, SASSC_NNP appears_VBZ as_IN a_DT valuable_JJ alternative_NN to_TO evaluate_VB whether_IN a_DT restricted_JJ number_NN of_IN independent_JJ classifiers_NNS improves_VBZ the_DT generalization_NN error_NN of_IN a_DT classification_NN model_NN ._. www.intechopen.com_'' arsencihuy@gmail.com_NN Highlight_NNP arsencihuy@gmail.com_NN Highlight_NNP arsencihuy@gmail.com_NN Highlight_NNP arsencihuy@gmail.com_NN Highlight_NNP arsencihuy@gmail.com_NN Highlight_NNP arsencihuy@gmail.com_NN Highlight_NNP Advances_NNP in_IN Evolutionary_NNP Algorithms_NNP 464_CD 7._. References_NNP Breiman_NNP ,_, L._NNP ,_, Friedman_NNP ,_, J.H._NNP ,_, Olshen_NNP ,_, R.A._NNP ,_, &_CC Stone_NNP C.J._NNP (_-LRB- 1984_CD )_-RRB- Classification_NN and_CC Regression_NNP Trees_NNP ,_, Wadsworth_NNP ,_, Belmont_NNP CA._NNP Breiman_NNP ,_, L._NNP (_-LRB- 1996_CD )_-RRB- Bagging_CC Predictors_NNP ,_, Machine_NNP Learning_NNP ,_, 24_CD ,_, 123-140_CD ._. Breiman_NNP ,_, ,_, L._NNP (_-LRB- 2001_CD )_-RRB- ._. Random_NNP Forests_NNS ,_, Machine_NNP Learning_NNP ,_, 45_CD ,_, 5-32_CD ._. Cappelli_NNP ,_, C._NNP ,_, Mola_NNP ,_, F._NNP ,_, &_CC Siciliano_NNP ,_, R._NNP (_-LRB- 2002_CD )_-RRB- ,_, A_DT Statistical_NNP Approach_NNP to_TO Growing_VBG a_DT Reliable_JJ Honest_NNP Tree_NNP ,_, Computational_NNP Statistics_NNPS and_CC Data_NNP Analysis_NNP ,_, 38_CD ,_, 285-299_CD ._. Chan_NNP ,_, K._NNP Y_NNP ._. &_CC Loh_NNP ,_, W._NNP Y_NNP ._. (_-LRB- 2004_CD )_-RRB- ._. LOTUS_NNP :_: An_DT algorithm_NN for_IN building_VBG accurate_JJ and_CC comprehensible_JJ logistic_JJ regression_NN trees_NNS ._. Journal_NNP of_IN Computational_NNP and_CC Graphical_NNP Statistics_NNPS ,_, 13_CD ,_, 826–852_CD ._. Choi_NNP ,_, Y._NNP ,_, Ahn_NNP ,_, H._NNP &_CC Chen_NNP ,_, J.J._NNP (_-LRB- 2005_CD )_-RRB- ._. Regression_NNP trees_NNS for_IN analysis_NN of_IN count_NN data_NNS with_IN extra_JJ Poisson_NNP variation_NN ._. Computational_NNP Statistics_NNPS and_CC Data_NNP Analysis_NNP ,_, 49_CD ,_, 893–915_CD ._. Colorni_NNP ,_, A._NN ,_, Dorigo_NNP ,_, M._NNP ,_, Maffioli_NNP ,_, F._NNP ,_, Maniezzo_NNP ,_, V._NNP ,_, Righini_NNP ,_, G._NNP ,_, &_CC Trubian_NNP ,_, M._NNP (_-LRB- 1996_CD )_-RRB- ._. Heuristics_NNP from_IN nature_NN for_IN hard_JJ combinatorial_JJ problems_NNS ._. International_NNP Transactions_NNPS in_IN Operational_NNP Research_NNP ,_, March_NNP ,_, 1-21_NNP ._. Conversano_NNP ,_, C._NNP (_-LRB- 2002_CD )_-RRB- Bagged_JJ mixture_NN of_IN classifiers_NNS using_VBG Model_NNP Scoring_NNP Criteria_NNP ._. Patterns_NNP Analysis_NNP &_CC Applications_NNP ,_, 5_CD ,_, 4_CD ,_, 351-362_CD ._. Dietterich_NNP ,_, T.G._NNP (_-LRB- 2000_CD )_-RRB- Ensemble_NNP methods_NNS in_IN machine_NN learning_NN ._. In_IN J.Kittler_NNP and_CC F.Roli_NNP ,_, (_-LRB- Eds_NNP ._. )_-RRB- ,_, Multiple_NNP Classifier_NNP System_NNP ._. First_NNP International_NNP Workshop_NNP ,_, MCS_NNP 2000_CD ,_, Cagliari_NNP ,_, vol_NN ._. 1857_CD of_IN Lecture_NNP notes_NNS in_IN computer_NN science_NN ._. Springer-Verlag_NNP ._. Dorigo_NNP ,_, M._NNP &_CC Stutzle_NNP ,_, T._NNP (_-LRB- 2004_CD )_-RRB- ._. Ant_NNP Colony_NNP Optimization_NNP ._. The_DT MIT_NNP Press_NNP ,_, London_NNP ._. 1-15_CD Dorigo_NNP ,_, M._NNP (_-LRB- 1992_CD )_-RRB- ._. Optimization_NNP ,_, Learning_VBG and_CC Natural_NNP Algorithms_NNP ._. PhD_NNP thesis_DT ,_, Politecnico_NNP di_VBD Milano_NNP ,_, Italy_NNP ._. Fogarty_NNP ,_, T._NNP (_-LRB- 1992_CD )_-RRB- First_RB Nearest_RB Neighbor_NNP Classification_NNP on_IN Frey_NNP and_CC Slate’s_NNP Letter_NNP Recognition_NNP Problem_NNP (_-LRB- Technical_NNP Note_NNP )_-RRB- ._. Machine_NNP Learning_NNP ,_, 9_CD ,_, 387-388_CD ._. Fogel_NNP ,_, L._NNP J._NNP (_-LRB- 1997_CD )_-RRB- ._. A_DT retrospective_JJ view_NN and_CC outlook_NN on_IN evolutionary_JJ algorithms_NNS ._. In_IN Fuzzy_NNP Days_NNPS ,_, 337–342_CD ._. Fogel_NNP ,_, D._NNP B._NNP &_CC Fogel_NNP ,_, L._NNP (_-LRB- 1993_CD )_-RRB- ._. Evolutionary_NNP computation_NN ._. IEEE_NN Transactions_NNS on_IN Neural_JJ Networks_NNS ,_, 5(_JJ 1_CD )_-RRB- :1–2_CD ._. Freund_NNP ,_, Y._NNP ,_, &_CC Schapire_NNP ,_, R._NNP (_-LRB- 1996_CD )_-RRB- ,_, Experiments_NNS with_IN a_DT new_JJ boosting_VBG algorithm_NN ,_, Machine_NNP Learning_NNP :_: Proceedings_NNS of_IN the_DT Thirteenth_NNP International_NNP Conference_NNP ,_, 148-156_CD ._. Frey_NNP ,_, P.W._NNP &_CC Slate_NNP ,_, D.J._NNP Letter_NNP Recognition_NNP Using_VBG Holland-style_NNP Adaptive_NNP Classifiers_NNP ._. Machine_NNP Learning_NNP ,_, 6_CD ,_, 161-182_CD ._. Gama_NNP ,_, J._NNP (_-LRB- 2004_CD )_-RRB- ,_, Functional_JJ trees_NNS ,_, Machine_NNP Learning_NNP ,_, 55_CD ,_, 219–250_CD ._. Hastie_NNP ,_, T._NNP ,_, Friedman_NNP ,_, J._NNP H._NNP ,_, &_CC Tibshirani_NNP ,_, R._NNP ,_, (_-LRB- 2001_CD )_-RRB- ._. The_DT Elements_NNP of_IN Statistical_NNP Learning_NNP :_: Data_NNP Mining_NNP ,_, Inference_NNP and_CC Prediction_NNP ,_, Springer_NNP ._. Hothorn_NNP ,_, T._NNP ,_, Hornik_NNP ,_, K._NNP &_CC Zeileis_NNP ,_, A._NN (_-LRB- 2006_CD )_-RRB- ._. Unbiased_'' recursive_JJ partitioning_NN :_: A_DT conditional_JJ inference_NN framework_NN ,_, Journal_NNP of_IN Computational_NNP and_CC Graphical_NNP Statistics_NNPS ,_, 15_CD ,_, 651–674_CD ._. Hyafil_NNP &_CC Rivest_NNP (_-LRB- 1976_CD )_-RRB- ._. Constructing_NNP optimal_NNP binary_JJ decision_NN trees_NNS is_VBZ NPcomplete_JJ ._. IPL:_NNP Information_NNP Processing_NNP Letters_NNP ,_, 15-17_CD ._. Klaschka_NNP ,_, J._NNP ,_, Siciliano_NNP ,_, R._NNP ,_, &_CC Antoch_NNP ,_, J._NNP (_-LRB- 1998_CD )_-RRB- :_: Computational_JJ Enhancements_NNS in_IN Tree_NNP -_: Growing_VBG Methods_NNS ,_, in_IN :_: Rizzi_NNP ,_, A._NN ,_, Vichi_NNP ,_, M._NNP &_CC Bock_NNP ,_, H.H._NNP (_-LRB- Eds_NNP ._. )_-RRB- ,_, Advances_NNP in_IN Data_NNP Science_NNP and_CC Classification_NNP :_: Proceedings_NNS of_IN the_DT 6th_JJ Conference_NNP of_IN the_DT International_NNP Federation_NNP of_IN Classification_NNP Society_NNP ,_, Springer-Verlag_NNP ,_, Berlin_NNP Heidelberg_NNP ._. 295-302_CD Loh_NNP ,_, W.Y_NNP ._. (_-LRB- 2002_CD )_-RRB- ._. Regression_NNP trees_NNS with_IN unbiased_JJ variable_JJ selection_NN and_CC interaction_NN detection_NN ._. Statistica_NNP Sinica_NNP ,_, 12_CD ,_, 361-386_CD ._. www.intechopen.com_IN Evolutionary_JJ Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NNP 465_CD Mehta_NNP ,_, M._NNP ,_, Agrawal_NNP ,_, R._NNP &_CC Rissanen_NNP J._NNP (_-LRB- 1996_CD )_-RRB- ._. SLIQ_NNP ._. A_DT Fast_NNP Scalable_NNP Classifier_NNP for_IN Data_NNP Mining_NNP ._. In_IN Proceedings_NNP of_IN the_DT International_NNP Conference_NNP on_IN Extending_VBG Database_NNP Technology_NNP EDBT_NNP ,_, 18-32_CD ._. Michalewicz_NNP ,_, Z._NNP (_-LRB- 1996_CD )_-RRB- ._. Genetic_NNP Algorithms_NNP +_NNP Data_NNP Structures_NNP =_SYM Evolution_NNP Programs_NNP ._. Springer-_NNP Verlag_NNP ,_, third_JJ edition_NN ._. Miele_NNP ,_, R._NNP ,_, Mola_NNP ,_, F._NNP ,_, Siciliano_NNP ,_, R._NNP (_-LRB- 2005_CD )_-RRB- ._. J-Fast_NNP :_: An_DT Interactive_NNP Software_NNP for_IN Classification_NNP and_CC Regression_NNP Trees_NNP ._. In_IN Proceedings_NNP of_IN the_DT Classification_NN and_CC Data_NNP Analysis_NNP Group_NNP (_-LRB- CLADAG_NN )_-RRB- of_IN the_DT Italian_NNP Statistical_NNP Society_NNP ._. Parma_NNP ,_, Italy_NNP ,_, 437-440_CD Miele_NNP ,_, R._NNP (_-LRB- 2007_CD )_-RRB- ._. Nature_NNP Inspired_NNP Optimization_NN Algorithms_NNP for_IN Classification_NNP and_CC Regression_NNP Trees_NNP ._. Ph.D._NNP Thesis_NNP ._. Univeristy_NNP of_IN Naples_NNP “Federico_NNP II”_NNP ._. Mola_NNP ,_, F._NNP ,_, &_CC Conversano_NNP ,_, C._NNP (_-LRB- 2008_CD )_-RRB- Sequential_JJ Automatic_NNP Search_NNP of_IN a_DT Subset_NNP of_IN Classifiers_NNS in_IN Multiclass_NNP Learning_NNP ,_, in_IN :_: Brito_NNP P._NNP &_CC Aluja-Banet_NNP T._NNP (_-LRB- Eds_NNP ._. )_-RRB- COMPSTAT_NN 2008_CD Proceedings_NNS in_IN Computational_NNP Statistics_NNPS ,_, Physica-Verlag_NNP ,_, to_TO appear_VB ._. Mola_NNP ,_, F._NNP ,_, &_CC Siciliano_NNP ,_, R._NNP (_-LRB- 1997_CD )_-RRB- ._. A_DT fast_JJ splitting_NN algorithm_NN for_IN classification_NN trees_NNS ._. Statistics_NNPS and_CC Computing_NNP ,_, 7_CD ,_, 209–216_CD ._. Oliver_NNP ,_, J.J._NNP ,_, &_CC Hand_NNP ,_, D._NNP J._NNP (_-LRB- 1995_CD )_-RRB- ._. On_IN Pruning_NNP and_CC Averaging_NNP Decision_NNP Trees_NNP ,_, in_IN Machine_NN Learning_VBG :_: Proceedings_NNS of_IN the_DT 12th_JJ International_NNP Workshop,430-437_NNP ._. Quinlan_NNP ,_, J.R._NNP ,_, (_-LRB- 1983_CD )_-RRB- ._. Learning_NNP Efficient_NNP Classification_NNP Procedures_NNP and_CC Their_PRP$ Application_NNP to_TO Chess_NNP and_CC Games_NNPS ._. In_IN Michalski_NNP R.S._NNP ,_, Carbonell_NNP J.G._NNP &_CC Mitchell_NNP T.M._NNP (ed_JJ ._. )_-RRB- :_: Machine_NN Learning_VBG :_: An_DT Artificial_JJ Intelligence_NNP Approach_NNP ,_, 1_CD ,_, Tioga_NNP Publishing_NNP ,_, 463-482_CD ._. Quinlan_NNP ,_, J.R._NNP ,_, (_-LRB- 1987_CD )_-RRB- ._. Simplifying_NNP decision_NN tree_NN ._. International_NNP Journal_NNP of_IN Man-Machine_NNP Studies_NNPS ,_, 27_CD ,_, 221–234_CD ._. Quinlan_NNP ,_, J._NNP R._NNP (_-LRB- 1993_CD )_-RRB- ._. C4.5_'' :_: Programs_NNS for_IN Machine_NN Learning_NNP ,_, Morgan_NNP Kaufmann_NNP ._. Siciliano_NNP ,_, R._NNP ,_, (_-LRB- 1998_CD )_-RRB- ._. Exploratory_NNP versus_FW decision_NN trees_NNS ._. In_IN :_: Payne_NNP ,_, R._NNP ,_, Green_NNP ,_, P._NNP (_-LRB- Eds_NNP ._. )_-RRB- ,_, COMPSTAT_NNP 1998_CD Proceedings_NNS in_IN Computational_NNP Statistics_NNPS ._. Physica-Verlag_NNP ,_, 113–124_CD ._. Siciliano_NNP ,_, R._NNP &_CC Mola_NNP ,_, F._NNP (_-LRB- 2000_CD )_-RRB- ._. Multivariate_NNP Data_NNP Analysis_NNP through_IN Classification_NNP and_CC Regression_NNP Trees_NNP ,_, Computational_NNP Statistics_NNPS and_CC Data_NNP Analysis_NNP ,_, 32_CD ,_, 285-301_CD ,_, Elsevier_NNP Science_NNP ,_, 2000_CD ._. Su_NNP ,_, X._NNP ,_, Wang_NNP ,_, M._NNP &_CC Fan_NNP ,_, J._NNP (_-LRB- 2004_CD )_-RRB- ._. Maximum_NNP likelihood_NN regression_NN trees_NNS ._. Journal_NNP of_IN Computational_NNP and_CC Graphical_NNP Statistics_NNPS ,_, 13_CD ,_, 586–598._DT Vose_NNP ,_, M._NNP D._NNP (_-LRB- 1999_CD )_-RRB- ._. The_DT simple_JJ genetic_JJ algorithm_NN :_: foundations_NNS and_CC theory_NN ._. MIT_NNP Press_NNP ,_, Cambridge_NNP ,_, MA._NNP Appendix_NNP :_: The_DT J-FAST_NN software_NN The_DT algorithms_NNS presented_VBD in_IN this_DT chapter_NN have_VBP been_VBN implemented_VBN in_IN the_DT Java_NNP language_NN ._. In_IN order_NN to_TO make_VB it_PRP possible_JJ to_TO test_VB them_PRP on_IN real_JJ datasets_NNS a_DT Java_NNP segmentation_NN framework_NN ,_, called_VBD J-FAST_NNP ,_, has_VBZ been_VBN developed_VBN ._. The_DT first_JJ aim_NN of_IN this_DT software_NN is_VBZ to_TO take_VB care_NN of_IN all_DT the_DT necessary_JJ operations_NNS to_TO perform_VB before_IN and_CC after_IN running_VBG the_DT recursive_JJ partitioning_NN algorithm_NN ._. These_DT can_MD be_VB summarized_VBN as_IN follows_VBZ :_: reading_VBG data_NNS from_IN text_NN files_NNS and_CC spreadsheets_NNS ;_: processing_VBG data_NNS before_IN carrying_VBG out_RP the_DT tree_NN growing_VBG process_NN ;_: specifying_VBG the_DT type_NN of_IN recursive_JJ partitioning_NN algorithm_NN to_TO be_VB applied_VBN (_-LRB- i_FW .e_FW ._. ,_, classification_NN or_CC regression_NN tree_NN )_-RRB- ;_: interpretation_NN of_IN the_DT results_NNS ._. The_DT J-FAST_NNP program_NN is_VBZ a_DT Java-based_JJ recursive_JJ partitioning_NN software_NN ,_, which_WDT is_VBZ particularly_RB research_NN oriented_VBN ._. It_PRP mainly_RB consists_VBZ of_IN a_DT flexible_JJ ,_, efficient_JJ and_CC transparent_JJ cross-platform_JJ application_NN for_IN building_NN classification_NN and_CC regression_NN trees_NNS using_VBG any_DT kind_NN of_IN heuristic_JJ in_IN the_DT tree_NN growing_VBG process_NN (_-LRB- like_IN the_DT CART_NNP greedy_JJ algorithm_NN or_CC the_DT FAST_NNP branch_NN and_CC bound_VBD www.intechopen.com_NN Advances_NNS in_IN Evolutionary_JJ Algorithms_NNP 466_CD heuristic_JJ or_CC any_DT other_JJ one_CD written_VBN by_IN the_DT user_NN )_-RRB- ._. It_PRP also_RB allows_VBZ to_TO interactively_RB visualize_VB and_CC compare_VB the_DT results_NNS ._. J-FAST_NN divides_VBZ the_DT recursive_JJ partitioning_NN procedure_NN into_IN three_CD main_JJ sections_NNS ._. The_DT data-importing_NN Graphical_NNP User_NNP Interface_NNP (_-LRB- see_VBP Figure_NN 4_CD )_-RRB- allows_VBZ to_TO read_VB data_NNS from_IN Excel-like_JJ spreadsheets_NNS and_CC plain_JJ text_NN files_NNS and_CC automatically_RB recognises_VBZ the_DT nature_NN of_IN the_DT variables_NNS by_IN distinguishing_VBG the_DT categorical_JJ ,_, numerical_JJ or_CC alphanumerical_JJ columns_NNS of_IN a_DT data_NN matrix_NN ._. J-Fast_NN also_RB allows_VBZ the_DT user_NN to_TO specify_VB the_DT Decision_NNP Tree_NNP Induction_NNP model_NN by_IN choosing_VBG the_DT response_NN variable_JJ ,_, as_RB well_RB as_IN which_WDT predictor(_JJ s_VBZ )_-RRB- should_MD be_VB treated_VBN as_IN ordinal_JJ ,_, nominal_JJ or_CC as_IN excluded_VBN from_IN the_DT analysis_NN ._. Fig_VB ._. 4_CD ._. J-Fast_NNP data_NNS importing_VBG Graphical_NNP User_NNP Interface_NNP A_DT second_JJ GUI_NN visualizes_VBZ some_DT information_NN about_IN the_DT chosen_VBN DTI_NNP model_NN and_CC provides_VBZ some_DT descriptive_NN statistics_NNS about_IN the_DT analyzing_NN data_NNS ._. It_PRP also_RB allows_VBZ the_DT user_NN to_TO specify_VB which_WDT are_VBP the_DT features_NNS of_IN the_DT DTI_NNP model_NN under_IN specification_NN ,_, such_JJ as_IN the_DT learning_NN sample_NN rate_NN ,_, the_DT stopping_NN conditions_NNS ,_, the_DT possibility_NN of_IN obtaining_VBG a_DT verbose_JJ output_NN ._. It_PRP also_RB asks_VBZ the_DT user_NN to_TO choose_VB between_IN all_PDT the_DT recursive_JJ partitioning_NN heuristics_NNS that_WDT are_VBP present_JJ into_IN the_DT class_NN path_NN ._. Then_RB ,_, the_DT software_NN starts_VBZ the_DT tree_NN growing_VBG procedure_NN ._. The_DT third_JJ component_NN of_IN the_DT J-FAST_NN software_NN is_VBZ the_DT results_NNS navigator_NN ._. It_PRP allows_VBZ the_DT user_NN to_TO interactively_JJ display_NN and_CC navigate_NN into_IN the_DT results_NNS of_IN the_DT analysis_NN ._. The_DT results_NNS navigator_NN GUI_NNP (_-LRB- see_VB Figure_NN 5_CD )_-RRB- consists_VBZ of_IN two_CD windows_NNS ._. The_DT first_JJ one_CD is_VBZ the_DT main_JJ results_NNS window_NN ._. It_PRP visualises_VBZ the_DT obtained_VBN decision_NN tree_NN ,_, charts_NNS the_DT misclassification_NN rates_NNS and_CC the_DT selected_VBN node’s_NNS information_NN panel_NN (_-LRB- there_EX is_VBZ a_DT button_NN for_IN visualizing_VBG the_DT splitting_JJ rule_NN to_TO reach_VB the_DT node_NN ,_, the_DT misclassification_NN rate_NN for_IN the_DT node_NN ,_, etc._FW )_-RRB- ._. The_DT second_JJ component_NN is_VBZ the_DT Tree_NNP Console_NNP Window_NNP (_-LRB- Figure_NN 6_CD )_-RRB- ._. It_PRP contains_VBZ buttons_NNS that_IN allow_VBP the_DT user_NN to_TO navigate_VB through_IN the_DT pruning_NN sequence_NN and_CC access_NN directly_RB the_DT best_JJS ,_, the_DT trivial_JJ and_CC the_DT maximal_NN tree_NN ._. For_IN each_DT tree_NN in_IN the_DT pruning_NN sequence_NN ,_, the_DT node_NN that_WDT is_VBZ going_VBG to_TO be_VB pruned_VBN is_VBZ highlighted_JJ ._. By_IN clicking_VBG www.intechopen.com_NN Evolutionary_RB Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NNP 467_CD on_IN the_DT node_NN ,_, the_DT interface_NN allows_VBZ to_TO get_VB the_DT data_NNS units_NNS which_WDT fall_VBP in_IN that_DT node_NN and_CC to_TO write_VB them_PRP into_IN a_DT file_NN in_IN order_NN to_TO continue_VB the_DT analysis_NN of_IN such_JJ units_NNS using_VBG another_DT software_NN ._. It_PRP is_VBZ also_RB possible_JJ ,_, from_IN the_DT second_JJ step_NN GUI_NNP ,_, to_TO simultaneously_RB start_VB more_JJR than_IN one_CD analysis_NN in_IN order_NN to_TO obtain_VB different_JJ tree_NN navigators_NNS simultaneously_RB on_IN the_DT screen_NN ._. This_DT feature_NN is_VBZ particularly_RB useful_JJ for_IN comparing_VBG trees_NNS grown_VBN from_IN different_JJ datasets_NNS or_CC on_IN the_DT same_JJ dataset_NN but_CC with_IN using_VBG different_JJ DTI_NNP specifications_NNS ._. Fig_NN ._. 5_CD ._. J-Fast_NNP data_NNS results_NNS navigator_NN Graphical_NNP User_NNP Interface_NNP J-FAST_NNP is_VBZ more_JJR than_IN a_DT simple_JJ recursive_JJ partitioning_NN software_NN ._. Because_IN of_IN the_DT fact_NN that_IN it_PRP has_VBZ been_VBN mainly_RB designed_VBN to_TO support_VB the_DT research_NN activity_NN ,_, it_PRP offers_VBZ many_JJ useful_JJ functions_NNS like_IN the_DT possibility_NN of_IN saving_VBG created_VBN objects_NNS (_-LRB- trees_NNS ,_, datasets_NNS ,_, nodes_NNS ,_, etc._FW )_-RRB- via_IN the_DT Java_NNP serialization_NN mechanism_NN in_IN order_NN to_TO better_JJR analyze_VB using_VBG other_JJ ad-hoc_NN written_VBN Java_NNP programs_NNS (_-LRB- some_DT of_IN them_PRP have_VBP already_RB been_VBN implemented_VBN ,_, like_IN a_DT different_JJ tree_NN interface_NN called_VBN “TreeSurfer”_NNP )_-RRB- ._. Interactivity_NNP with_IN the_DT R_NN statistical_JJ software_NN is_VBZ also_RB provided_VBN :_: by_IN right-clicking_NN on_IN a_DT node_NN it_PRP is_VBZ possible_JJ to_TO send_VB the_DT corresponding_JJ data_NN to_TO R_NN in_IN order_NN to_TO continue_VB the_DT analysis_NN ._. This_DT is_VBZ particularly_RB useful_JJ if_IN another_DT statistical_JJ analysis_NN (_-LRB- i_FW .e_NN ._. a_DT logit_JJ model_NN )_-RRB- has_VBZ to_TO be_VB made_VBN on_IN a_DT particular_JJ segment_NN (_-LRB- node_NN )_-RRB- extracted_VBN from_IN the_DT obtained_VBN decision_NN tree_NN ._. J-FAST_NNP has_VBZ to_TO be_VB also_RB considered_VBN as_IN a_DT Java_NNP objects_VBZ Library_JJ (_-LRB- or_CC API_NNP -_: Application_NNP Program_NN Interface_NN )_-RRB- ,_, for_IN building_VBG Classification_NNP and_CC Regression_NNP Trees_NNP ._. Any_DT researcher_NN which_WDT is_VBZ able_JJ to_TO program_VB in_IN Java_NNP could_MD use_VB the_DT classes_NNS from_IN the_DT J-FAST_NNP API_NNP in_IN order_NN to_TO get_VB trees_NNS without_IN having_VBG to_TO write_VB all_DT the_DT necessary_JJ code_NN ._. In_IN addition_NN ,_, the_DT J-FAST_NNP platform_NN offers_VBZ many_JJ useful_JJ objects_NNS ._. The_DT most_RBS important_JJ ones_NNS are_VBP :_: •_NNP Statistics_NNPS :_: it_PRP provides_VBZ univariate_JJ and_CC bivariate_JJ descriptive_NN statistics_NNS ._. •_NN DataSet_NNP :_: it_PRP stores_VBZ data_NNS for_IN recursive_JJ partitioning_NN purposes_NNS (_-LRB- response_NN variable_JJ ,_, predictors_NNS ,_, etc._FW )_-RRB- ._. •_NNP Split_NNP :_: it_PRP specifies_VBZ the_DT type_NN of_IN split_NN (_-LRB- binary_JJ ,_, ternary_JJ ,etc._NN )_-RRB- www.intechopen.com_NN Advances_NNS in_IN Evolutionary_JJ Algorithms_NNP 468_CD •_, TreeGrower_NNP :_: it_PRP is_VBZ a_DT class_NN for_IN growing_VBG decision_NN trees_NNS •_JJ Pruner_NNP :_: it_PRP is_VBZ class_NN that_IN for_IN decision_NN tree_NN pruning_NN •_NNP TreeViewer_NNP :_: it_PRP is_VBZ a_DT interactive_JJ interface_NN class_NN •_JJ Utility_NN :_: it_PRP encompasses_VBZ many_JJ useful_JJ function_NN like_IN reading_VBG data_NNS from_IN plain_JJ text_NN files_NNS ,_, Excel-like_NNP spreadsheets_NNS ,_, etc_FW ._. •_'' TreeBuild_NNP interface_NN :_: it_PRP defines_VBZ all_PDT the_DT rules_NNS to_TO follow_VB for_IN the_DT programmer_NN to_TO write_VB his_PRP$ own_JJ heuristic_JJ ._. Fig_VB ._. 6_CD ._. J-Fast_NNP tree_NN console_NN window_NN Graphical_NNP User_NNP Interface_NNP www.intechopen.com_NN Advances_NNS in_IN Evolutionary_NNP Algorithms_NNP Edited_NNP by_IN Xiong_NNP Zhihui_NNP ISBN_NNP 978-953-7619-11-4_CD Hard_NNP cover_NN ,_, 284_CD pages_NNS Publisher_NNP InTech_NNP Published_NNP online_NNP 01_CD ,_, November_NNP ,_, 2008_CD Published_VBN in_IN print_NN edition_NN November_NNP ,_, 2008_CD InTech_NNP Europe_NNP University_NNP Campus_NNP STeP_NNP Ri_NNP Slavka_NNP Krautzeka_NNP 83/A_. 51000_CD Rijeka_NNP ,_, Croatia_NNP Phone_NNP :_: +385_CD (_-LRB- 51_CD )_-RRB- 770_CD 447_CD Fax_NNP :_: +385_CD (_-LRB- 51_CD )_-RRB- 686_CD 166www.intechopen.com_IN InTech_NNP China_NNP Unit_NNP 405_CD ,_, Office_NNP Block_NNP ,_, Hotel_NNP Equatorial_NNP Shanghai_NNP No.65_NNP ,_, Yan_NNP An_NNP Road_NNP (_-LRB- West_NNP )_-RRB- ,_, Shanghai_NNP ,_, 200040_CD ,_, China_NNP Phone_NNP :_: +86-21-62489820_CD Fax_NNP :_: +86-21-62489821_CD With_IN the_DT recent_JJ trends_NNS towards_IN massive_JJ data_NNS sets_NNS and_CC significant_JJ computational_JJ power_NN ,_, combined_VBN withevolutionary_IN algorithmic_JJ advances_NNS evolutionary_JJ computation_NN is_VBZ becoming_VBG much_RB more_RBR relevant_JJ to_TO practice_VB ._. Aimof_IN the_DT book_NN is_VBZ to_TO present_VB recent_JJ improvements_NNS ,_, innovative_JJ ideas_NNS and_CC concepts_NNS in_IN a_DT part_NN of_IN a_DT huge_JJ EA_NN field_NN ._. How_WRB to_TO reference_NN In_IN order_NN to_TO correctly_VB reference_NN this_DT scholarly_NN work_NN ,_, feel_VB free_JJ to_TO copy_VB and_CC paste_VB the_DT following_VBG :_: Francesco_NNP Mola_NNP ,_, Raffaele_NNP Miele_NNP and_CC Claudio_NNP Conversano_NNP (_-LRB- 2008_CD )_-RRB- ._. Evolutionary_NNP Algorithms_NNP in_IN Decision_NNP TreeInduction_NNP ,_, Advances_NNS in_IN Evolutionary_NNP Algorithms_NNP ,_, Xiong_NNP Zhihui_NNP (_-LRB- Ed._NNP )_-RRB- ,_, ISBN_NNP :_: 978-953-7619-11-4_CD ,_, InTech,Available_NNP from_IN :http_NNP ://www.intechopen.com/books/advances_in_evolutionary_algorithms/evolutionary_algorithms_in_decision_tree_induction_NN
