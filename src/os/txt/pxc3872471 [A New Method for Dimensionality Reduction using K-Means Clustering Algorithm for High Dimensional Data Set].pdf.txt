International_NNP Journal_NNP of_IN Computer_NNP Applications_NNPS (_-LRB- 0975_CD –_NN 8887_CD )_-RRB- Volume_NN 13–_CD No.7_NN ,_, January_NNP 2011_CD 41_CD A_DT New_NNP Method_NNP for_IN Dimensionality_NNP Reduction_NNP using_VBG K-_NNP Means_NNPS Clustering_NNP Algorithm_NNP for_IN High_NNP Dimensional_NNP Data_NNP Set_NNP D.Napoleon_NNP Assistant_NNP Professor_NNP Department_NNP of_IN Computer_NNP Science_NNP Bharathiar_NNP University_NNP Coimbatore_NNP –_NNP 641_CD 046_CD S.Pavalakodi_NNP Research_NNP Scholar_NNP Department_NNP of_IN Computer_NNP Science_NNP Bharathiar_NNP University_NNP Coimbatore–641046_NNP ABSTRACT_NNP Clustering_NNP is_VBZ the_DT process_NN of_IN finding_VBG groups_NNS of_IN objects_NNS such_JJ that_IN the_DT objects_NNS in_IN a_DT group_NN will_MD be_VB similar_JJ to_TO one_CD another_DT and_CC different_JJ from_IN the_DT objects_NNS in_IN other_JJ groups_NNS ._. Dimensionality_NN reduction_NN is_VBZ the_DT transformation_NN of_IN high-dimensional_JJ data_NNS into_IN a_DT meaningful_JJ representation_NN of_IN reduced_VBN dimensionality_NN that_IN corresponds_NNS to_TO the_DT intrinsic_JJ dimensionality_NN of_IN the_DT data_NNS ._. K-means_'' clustering_VBG algorithm_NN often_RB does_VBZ not_RB work_VB well_RB for_IN high_JJ dimension_NN ,_, hence_RB ,_, to_TO improve_VB the_DT efficiency_NN ,_, apply_VB PCA_NNP on_IN original_JJ data_NNS set_VBN and_CC obtain_VB a_DT reduced_VBN dataset_NN containing_VBG possibly_RB uncorrelated_JJ variables_NNS ._. In_IN this_DT paper_NN principal_JJ component_NN analysis_NN and_CC linear_NN transformation_NN is_VBZ used_VBN for_IN dimensionality_NN reduction_NN and_CC initial_JJ centroid_NN is_VBZ computed_VBN ,_, then_RB it_PRP is_VBZ applied_VBN to_TO K-Means_NNP clustering_NN algorithm_NN ._. Keywords_NNPS Clustering_NNP ;_: Dimensionality_NNP Reduction_NNP ,_, Principal_NNP component_NN analysis_NN ,_, k-means_NNS algorithm_NN ,_, Amalgamation_NNP ._. 1_CD ._. INTRODUCTION_NNP Data_NNP Mining_NNP refers_VBZ to_TO the_DT mining_NN or_CC discovery_NN of_IN new_JJ information_NN in_IN terms_NNS of_IN patterns_NNS or_CC rules_NNS from_IN vast_JJ amounts_NNS of_IN data_NNS ._. Data_NNP mining_NN is_VBZ a_DT process_NN that_IN takes_VBZ data_NNS as_IN input_NN and_CC outputs_VBZ knowledge_NN ._. One_CD of_IN the_DT earliest_JJS and_CC most_RBS cited_VBN definitions_NNS of_IN the_DT data_NNS mining_NN process_NN ,_, which_WDT highlights_VBD some_DT of_IN its_PRP$ distinctive_JJ characteristics_NNS ,_, is_VBZ provided_VBN by_IN Fayyad_NNP ,_, Piatetsky-Shapiro_NNP and_CC Smyth_NNP (_-LRB- 1996_CD )_-RRB- ,_, who_WP define_VB it_PRP as_IN “the_DT nontrivial_JJ process_NN of_IN identifying_VBG valid_JJ ,_, novel_JJ ,_, potentially_RB useful_JJ ,_, and_CC ultimately_RB understandable_JJ patterns_NNS in_IN data_NNS .”Some_DT popular_JJ and_CC widely_RB used_VBN data_NNS mining_NN clustering_NN techniques_NNS such_JJ as_IN hierarchical_JJ and_CC k_VB -_: means_VBZ clustering_VBG techniques_NNS are_VBP statistical_JJ techniques_NNS and_CC can_MD be_VB applied_VBN on_IN high_JJ dimensional_JJ datasets_NNS [6]_VBP ._. A_DT good_JJ survey_NN on_IN clustering_VBG methods_NNS is_VBZ found_VBN in_IN Xu_NNP et_NNP al_NN ._. (_-LRB- 2005_CD )_-RRB- ._. High_NNP dimensional_JJ data_NNS are_VBP often_RB transformed_VBN into_IN lower_JJR dimensional_JJ data_NNS via_IN the_DT principal_JJ component_NN analysis_NN (PCA_NNP )(_NNP Jolliffe_NNP ,_, 2002_CD )_-RRB- (_-LRB- or_CC singular_JJ value_NN decomposition_NN )_-RRB- where_WRB coherent_JJ patterns_NNS can_MD be_VB detected_VBN more_RBR clearly_RB [14]_JJ ._. Such_JJ unsupervised_JJ dimension_NN reduction_NN is_VBZ used_VBN in_IN very_RB broad_JJ areas_NNS such_JJ as_IN meteorology_NN ,_, image_NN processing_NN ,_, genomic_JJ analysis_NN ,_, and_CC information_NN retrieval_JJ [9]_NN ._. It_PRP is_VBZ also_RB common_JJ that_IN PCA_NNP is_VBZ used_VBN to_TO project_VB data_NNS to_TO a_DT lower_JJR dimensional_JJ subspace_NN and_CC K-means_NNP is_VBZ then_RB applied_VBN in_IN the_DT subspace_NN (_-LRB- Zha_NNP et_NNP al_NN ._. ,_, 2002_CD )[_NN 8]_NN ._. In_IN other_JJ cases_NNS ,_, data_NNS are_VBP embedded_VBN in_IN a_DT low-dimensional_JJ space_NN such_JJ as_IN the_DT eigenspace_CD of_IN the_DT graph_NN Laplacian_NN ,_, and_CC K-means_NNP is_VBZ then_RB applied_VBN (_-LRB- Ng_NNP et_NNP al_NN ._. ,_, 2001_CD )[_, 3].The_DT main_JJ basis_NN of_IN PCA-based_JJ dimension_NN reduction_NN is_VBZ that_IN PCA_NNP picks_VBZ up_RP the_DT dimensions_NNS with_IN the_DT largest_JJS variances_NNS ._. Mathematically_NN ,_, this_DT is_VBZ equivalent_JJ to_TO finding_VBG the_DT best_JJS low_JJ rank_NN approximation_NN (_-LRB- in_IN L2_JJ norm_NN )_-RRB- of_IN the_DT data_NNS via_IN the_DT singular_JJ value_NN decomposition_NN (_-LRB- SVD_NN )_-RRB- (_-LRB- Eckart_NNP &_CC Young_NNP ,_, 1936_CD )_-RRB- ._. However_RB ,_, this_DT noise_NN reduction_NN property_NN alone_RB is_VBZ inadequate_JJ to_TO explain_VB the_DT effectiveness_NN of_IN PCA[5_DT ]_JJ Dimension_NNP reduction_NN is_VBZ the_DT process_NN of_IN reducing_VBG the_DT number_NN of_IN random_JJ variables_NNS under_IN consideration_NN ,_, and_CC can_MD be_VB divided_VBN into_IN feature_NN selection_NN and_CC feature_NN extraction_NN [4]_VBD ._. As_IN dimensionality_NN increases_NNS ,_, query_NN performance_NN in_IN the_DT index_NN structures_NNS degrades_VBZ ._. Dimensionality_NNP reduction_NN algorithms_NNS are_VBP the_DT only_JJ known_JJ solution_NN that_WDT supports_VBZ scalable_JJ object_NN retrieval_JJ and_CC satisfies_VBZ precision_NN of_IN query_NN results_NNS [16]_VBP ._. Feature_NNP transforms_VBZ the_DT data_NNS in_IN the_DT high-dimensional_JJ space_NN to_TO a_DT space_NN of_IN fewer_JJR dimensions_NNS [9].The_IN data_NNS transformation_NN may_MD be_VB linear_JJ ,_, as_IN in_IN principal_JJ component_NN analysis_NN (PCA_NN )_-RRB- ,_, but_CC any_DT nonlinear_JJ dimensionality_NN reduction_NN techniques_NNS also_RB exist_VBP [18]_NN ._. In_IN general_JJ ,_, handling_VBG high_JJ dimensional_JJ data_NNS using_VBG clustering_VBG techniques_NNS obviously_RB a_DT difficult_JJ task_NN in_IN terms_NNS of_IN higher_JJR number_NN of_IN variables_NNS involved_VBN ._. In_IN order_NN to_TO improve_VB the_DT efficiency_NN the_DT noisy_JJ and_CC outlier_JJ data_NNS may_MD be_VB removed_VBN and_CC minimize_VB the_DT execution_NN time_NN ,_, we_PRP have_VBP to_TO reduce_VB the_DT no_NN ._. of_IN variables_NNS in_IN the_DT original_JJ data_NNS set_VBN ._. To_TO do_VB so_RB ,_, we_PRP can_MD choose_VB dimensionality_NN reduction_NN methods_NNS such_JJ as_IN principal_JJ component_NN analysis_NN (PCA_NN )_-RRB- ,_, Singular_NNP value_NN decomposition_NN (_-LRB- SVD)_NNP ,_, and_CC factor_NN analysis_NN (_-LRB- FA_NNP )_-RRB- ._. Among_IN this_DT ,_, PCA_NNP is_VBZ preferred_VBN to_TO our_PRP$ analysis_NN and_CC the_DT results_NNS of_IN PCA_NNP are_VBP applied_VBN to_TO a_DT popular_JJ model_NN based_VBN clustering_VBG technique_NN [7]_VBD ._. Principal_NNP component_NN analysis_NN (PCA_NN )_-RRB- is_VBZ a_DT widely_RB used_VBN statistical_JJ technique_NN for_IN unsupervised_JJ dimension_NN reduction_NN ._. K-means_'' clustering_NN is_VBZ a_DT commonly_RB used_VBN data_NNS clustering_NN for_IN unsupervised_JJ learning_NN tasks_NNS ._. Here_RB we_PRP prove_VBP that_IN principal_JJ components_NNS are_VBP the_DT continuous_JJ solutions_NNS to_TO the_DT discrete_JJ cluster_NN membership_NN indicators_NNS for_IN K-means_DT clustering_NN [5].The_DT main_JJ linear_NN technique_NN for_IN dimensionality_NN reduction_NN ,_, principal_JJ component_NN analysis_NN ,_, performs_VBZ a_DT linear_JJ mapping_NN of_IN the_DT data_NNS to_TO a_DT lower_JJR dimensional_JJ space_NN in_IN such_JJ a_DT way_NN ,_, that_IN the_DT variance_NN of_IN the_DT data_NNS in_IN the_DT low-dimensional_JJ representation_NN is_VBZ maximized_VBN ._. In_IN practice_NN ,_, the_DT correlation_NN matrix_NN of_IN the_DT data_NNS is_VBZ constructed_VBN and_CC the_DT eigenvectors_NNS on_IN this_DT matrix_NN are_VBP computed_VBN ._. The_DT eigenvectors_NNS that_IN correspond_NN to_TO the_DT largest_JJS eigenvalues_NNS (_-LRB- the_DT principal_JJ components_NNS )_-RRB- can_MD now_RB be_VB used_VBN to_TO reconstruct_VB a_DT large_JJ fraction_NN of_IN the_DT variance_NN of_IN the_DT original_JJ data_NNS ._. Moreover_RB ,_, the_DT first_JJ few_JJ eigenvectors_NNS can_MD often_RB be_VB interpreted_VBN in_IN terms_NNS of_IN the_DT large-scale_JJ physical_JJ behavior_NN of_IN the_DT system_NN ._. The_DT original_JJ space_NN (_-LRB- with_IN dimension_NN of_IN the_DT number_NN of_IN points_NNS )_-RRB- has_VBZ been_VBN reduced_VBN (_-LRB- with_IN data_NNS loss_NN ,_, but_CC hopefully_RB retaining_VBG the_DT most_RBS important_JJ variance_NN )_-RRB- to_TO the_DT space_NN spanned_VBN by_IN a_DT few_JJ eigenvectors_NNS ._. Many_JJ applications_NNS need_VBP to_TO use_VB unsupervised_JJ techniques_NNS where_WRB there_EX is_VBZ no_DT previous_JJ knowledge_NN about_IN patterns_NNS inside_IN samples_NNS and_CC its_PRP$ International_NNP Journal_NNP of_IN Computer_NNP Applications_NNPS (_-LRB- 0975_CD –_NN 8887_CD )_-RRB- Volume_NN 13–_CD No.7_NN ,_, January_NNP 2011_CD 42_CD grouping_NN ,_, so_RB clustering_VBG can_MD be_VB useful_JJ ._. Clustering_NNP is_VBZ grouping_VBG samples_NNS base_NN on_IN their_PRP$ similarity_NN as_IN samples_NNS in_IN different_JJ groups_NNS should_MD be_VB dissimilar_JJ ._. Both_DT similarity_NN and_CC dissimilarity_NN need_NN to_TO be_VB elucidated_VBN in_IN clear_JJ way_NN ._. High_NNP dimensionality_NN is_VBZ one_CD of_IN the_DT major_JJ causes_NNS in_IN data_NNS complexity_NN ._. Technology_NNP makes_VBZ it_PRP possible_JJ to_TO automatically_RB obtain_VB a_DT huge_JJ amount_NN of_IN measurements_NNS ._. However_RB ,_, they_PRP often_RB do_VBP not_RB precisely_RB identify_VB the_DT relevance_NN of_IN the_DT measured_JJ features_NNS to_TO the_DT specific_JJ phenomena_NNS of_IN interest_NN ._. Data_NNP observations_NNS with_IN thousands_NNS of_IN features_NNS or_CC more_JJR are_VBP now_RB common_JJ ,_, such_JJ as_IN profiles_NNS clustering_VBG in_IN recommender_NN systems_NNS ,_, personality_NN similarity_NN ,_, genomic_JJ data_NNS ,_, financial_JJ data_NNS ,_, web_NN document_NN data_NNS and_CC sensor_NN data_NNS ._. However_RB ,_, high-dimensional_JJ data_NNS poses_VBZ different_JJ challenges_NNS for_IN clustering_VBG algorithms_NNS that_WDT require_VBP specialized_JJ solutions_NNS ._. Recently_RB ,_, some_DT researchers_NNS have_VBP given_VBN solutions_NNS on_IN high-dimensional_JJ problem_NN ._. Our_PRP$ main_JJ objective_NN is_VBZ proposing_VBG a_DT framework_NN to_TO combine_VB relational_JJ definition_NN of_IN clustering_VBG with_IN dimension_NN reduction_NN method_NN to_TO overcome_VB aforesaid_NN difficulties_NNS and_CC improving_VBG efficiency_NN and_CC accuracy_NN in_IN K-Means_NNP algorithm_NN to_TO apply_VB in_IN high_JJ dimensional_JJ datasets_NNS ._. Kmeans_NNS clustering_VBG algorithm_NN is_VBZ applied_VBN to_TO reduced_JJ datasets_NNS which_WDT is_VBZ done_VBN by_IN principal_JJ component_NN analysis_NN dimension_NN reduction_NN method_NN ._. 2._'' METHODOLOGIES_NNS Cluster_NNP analysis_NN is_VBZ one_CD of_IN the_DT major_JJ data_NNS analysis_NN methods_NNS widely_RB used_VBD for_IN many_JJ practical_JJ applications_NNS in_IN emerging_VBG areas[12].Clustering_NN is_VBZ the_DT process_NN of_IN finding_VBG groups_NNS of_IN objects_NNS such_JJ that_IN the_DT objects_NNS in_IN a_DT group_NN will_MD be_VB similar_JJ to_TO one_CD another_DT and_CC different_JJ from_IN the_DT objects_NNS in_IN other_JJ groups_NNS ._. A_DT good_JJ clustering_NN method_NN will_MD produce_VB high_JJ quality_NN clusters_NNS with_IN high_JJ intra-cluster_JJ similarity_NN and_CC low_JJ inter-cluster_NN similarity_NN [17]_NN ._. The_DT quality_NN of_IN a_DT clustering_NN result_NN depends_VBZ on_IN both_DT the_DT similarity_NN measure_NN used_VBN by_IN the_DT method_NN and_CC its_PRP$ implementation_NN and_CC also_RB by_IN its_PRP$ ability_NN to_TO discover_VB some_DT or_CC all_DT of_IN the_DT hidden_JJ patterns_NNS [15]_FW ._. 2.1_CD Clustering_NNP Cluster_NNP analysis_NN is_VBZ one_CD of_IN the_DT major_JJ data_NNS analysis_NN methods_NNS widely_RB used_VBD for_IN many_JJ practical_JJ applications_NNS in_IN emerging_VBG areas[12].Clustering_NN is_VBZ the_DT process_NN of_IN finding_VBG groups_NNS of_IN objects_NNS such_JJ that_IN the_DT objects_NNS in_IN a_DT group_NN will_MD be_VB similar_JJ to_TO one_CD another_DT and_CC different_JJ from_IN the_DT objects_NNS in_IN other_JJ groups_NNS ._. A_DT good_JJ clustering_NN method_NN will_MD produce_VB high_JJ quality_NN clusters_NNS with_IN high_JJ intra-cluster_JJ similarity_NN and_CC low_JJ inter-cluster_NN similarity_NN [17]_NN ._. The_DT quality_NN of_IN a_DT clustering_NN result_NN depends_VBZ on_IN both_DT the_DT similarity_NN measure_NN used_VBN by_IN the_DT method_NN and_CC its_PRP$ implementation_NN and_CC also_RB by_IN its_PRP$ ability_NN to_TO discover_VB some_DT or_CC all_DT of_IN the_DT hidden_JJ patterns_NNS [15]_FW ._. 2.2_CD K-Means_NNP Clustering_NNP Algorithm_NNP K-means_NNP is_VBZ a_DT commonly_RB used_VBN partitioning_NN based_VBN clustering_VBG technique_NN that_WDT tries_VBZ to_TO find_VB a_DT user_NN specified_VBN number_NN of_IN clusters_NNS (_-LRB- k_NN )_-RRB- ,_, which_WDT are_VBP represented_VBN by_IN their_PRP$ centroids_NNS ,_, by_IN minimizing_VBG the_DT square_JJ error_NN function_NN [13]_VBZ ._. Although_IN K-means_NNP is_VBZ simple_JJ and_CC can_MD be_VB used_VBN for_IN a_DT wide_JJ variety_NN of_IN data_NNS types_NNS ._. The_DT K-means_NNP algorithm_NN is_VBZ one_CD of_IN the_DT partitioning_NN based_VBN ,_, nonhierarchical_JJ clustering_NN methods_NNS ._. Given_VBN a_DT set_NN of_IN numeric_JJ objects_NNS X_NNP and_CC an_DT integer_NN number_NN k_NN ,_, the_DT K-means_NNP algorithm_NN searches_NNS for_IN a_DT partition_NN of_IN X_NNP into_IN k_NN clusters_NNS that_WDT minimizes_VBZ the_DT within_IN groups_NNS sum_NN of_IN squared_JJ errors_NNS ._. The_DT K-means_NNP algorithm_NN starts_VBZ by_IN initializing_VBG the_DT k_NN cluster_NN centers_NNS [1]_VBP ._. The_DT input_NN data_NNS points_NNS are_VBP then_RB allocated_VBN to_TO one_CD of_IN the_DT existing_VBG clusters_NNS according_VBG to_TO the_DT square_NN of_IN the_DT Euclidean_JJ distance_NN from_IN the_DT clusters_NNS ,_, choosing_VBG the_DT closest_JJS ._. The_DT mean_JJ (centroid_NN )_-RRB- of_IN each_DT cluster_NN is_VBZ then_RB computed_VBN so_RB as_IN to_TO update_VB the_DT cluster_NN center_NN [1]_VBD ._. This_DT update_NN occurs_VBZ as_IN a_DT result_NN of_IN the_DT change_NN in_IN the_DT membership_NN of_IN each_DT cluster_NN ._. The_DT processes_NNS of_IN re-assigning_VBG the_DT input_NN vectors_NNS and_CC the_DT update_NN of_IN the_DT cluster_NN centers_NNS is_VBZ repeated_VBN until_IN no_DT more_JJR change_NN in_IN the_DT value_NN of_IN any_DT of_IN the_DT cluster_NN centers_NNS ._. The_DT steps_NNS of_IN the_DT K-_NNP means_VBZ algorithm_VBN are_VBP written_VBN below_IN :_: Input_NN :_: X_NNP =_SYM {d1_CD ,_, d2_CC ,……..,dn_NNP }_VBD //_RB set_VBN of_IN n_NN data_NNS items_NNS ._. Output_NN :_: A_DT set_NN of_IN k_NN clusters_NNS Step_NNP 1_CD :_: Initialization_NN :_: choose_VB randomly_RB K_NNP input_NN vectors_NNS (_-LRB- data_NN points_NNS )_-RRB- to_TO initialize_VB the_DT clusters_NNS ._. Step_NN 2_CD :_: Nearest-neighbor_NNP search_NN :_: for_IN each_DT input_NN vector_RB ,_, find_VB the_DT cluster_NN center_NN that_WDT is_VBZ closest_JJS ,_, and_CC assign_NN that_IN input_NN vector_NN to_TO the_DT corresponding_JJ cluster_NN ._. Step_NN 3_CD :_: Mean_NNP update_VB :_: update_VB the_DT cluster_NN centers_NNS in_IN each_DT cluster_NN using_VBG the_DT mean_JJ (centroid_NN )_-RRB- of_IN the_DT input_NN vectors_NNS assigned_VBN to_TO that_DT cluster_NN Step_NNP 4_CD :_: Stopping_NNP rule_NN :_: repeat_NN steps_NNS 2_CD and_CC 3_CD until_IN no_DT more_JJR change_NN in_IN the_DT value_NN of_IN the_DT means_NNS ._. 2.3_CD Principal_NNP Component_NNP Analysis_NNP Principal_NNP component_NN analysis_NN (PCA_NNP )_-RRB- involves_VBZ a_DT mathematical_JJ procedure_NN that_IN transforms_NNS a_DT number_NN of_IN possibly_RB correlated_JJ variables_NNS into_IN a_DT smaller_JJR number_NN of_IN uncorrelated_JJ variables_NNS called_VBD principal_JJ components_NNS ._. The_DT first_JJ principal_JJ component_NN accounts_NNS for_IN as_IN much_JJ of_IN the_DT variability_NN in_IN the_DT data_NNS as_IN possible_JJ ,_, and_CC each_DT succeeding_VBG component_NN accounts_NNS for_IN as_IN much_JJ of_IN the_DT remaining_VBG variability_NN as_IN possible_JJ ._. Depending_VBG on_IN the_DT field_NN of_IN application_NN ,_, it_PRP is_VBZ also_RB named_VBN the_DT discrete_NN KarhunenLoève_NNP transform_VB (KLT)_NNP ,_, the_DT Hostelling_NNP transform_VB or_CC proper_JJ orthogonal_JJ decomposition_NN (_-LRB- POD_NNP ).PCA_NNP was_VBD invented_VBN in_IN 1901_CD by_IN Karl_NNP Pearson_NNP .[4_. ]_SYM Now_RB it_PRP is_VBZ mostly_RB used_VBN as_IN a_DT tool_NN in_IN exploratory_JJ data_NNS analysis_NN and_CC for_IN making_VBG predictive_JJ models_NNS ._. PCA_NN involves_VBZ the_DT calculation_NN of_IN the_DT eigenvalue_JJ decomposition_NN of_IN a_DT data_NN covariance_NN matrix_NN or_CC singular_JJ value_NN decomposition_NN of_IN a_DT data_NN matrix_NN ,_, usually_RB after_IN mean_JJ centering_NN the_DT data_NNS for_IN each_DT attribute_NN ._. The_DT results_NNS of_IN a_DT PCA_NNP are_VBP usually_RB discussed_VBN in_IN terms_NNS of_IN component_NN scores_NNS and_CC loadings_NNS ._. PCA_NN is_VBZ the_DT simplest_JJS of_IN the_DT true_JJ eigenvector-based_JJ multivariate_JJ analyses_NNS ._. Often_RB ,_, its_PRP$ operation_NN can_MD be_VB thought_VBN of_IN as_IN revealing_VBG the_DT internal_JJ structure_NN of_IN the_DT data_NNS in_IN a_DT way_NN which_WDT best_JJS explains_VBZ the_DT variance_NN in_IN the_DT data_NNS ._. If_IN a_DT multivariate_JJ dataset_NN is_VBZ visualized_VBN as_IN a_DT set_NN of_IN coordinates_NNS in_IN a_DT high-dimensional_JJ data_NN space_NN (_-LRB- 1_CD axis_NN per_IN variable_JJ )_-RRB- ,_, PCA_NNP supplies_VBZ the_DT user_NN with_IN a_DT lower-dimensional_JJ picture_NN ,_, a_DT "_`` shadow_NN "_'' of_IN this_DT object_NN when_WRB viewed_VBN from_IN its_PRP$ (_-LRB- in_IN some_DT sense_NN )_-RRB- most_RBS informative_JJ viewpoint.PCA_NN is_VBZ closely_RB related_VBN to_TO factor_NN analysis_NN ;_: indeed_RB ,_, some_DT statistical_JJ packages_NNS deliberately_RB conflate_VB the_DT two_CD techniques_NNS ._. True_JJ factor_NN analysis_NN makes_VBZ different_JJ assumptions_NNS about_IN the_DT underlying_JJ structure_NN and_CC solves_VBZ eigenvectors_NNS of_IN a_DT slightly_RB different_JJ matrix_NN ._. 2.4_CD Principal_NNP Components_NNP Technically_NNP ,_, a_DT principal_JJ component_NN (PCS)_NN can_MD be_VB defined_VBN as_IN a_DT linear_NN combination_NN of_IN optimally_RB weighted_VBN observed_JJ variables_NNS which_WDT maximize_VB the_DT variance_NN of_IN the_DT linear_NN combination_NN and_CC which_WDT have_VBP zero_CD covariance_NN with_IN the_DT previous_JJ PCs_NNS ._. The_DT first_JJ component_NN extracted_VBN in_IN a_DT International_NNP Journal_NNP of_IN Computer_NNP Applications_NNPS (_-LRB- 0975_CD –_NN 8887_CD )_-RRB- Volume_NN 13–_CD No.7_NN ,_, January_NNP 2011_CD 43_CD principal_JJ component_NN analysis_NN accounts_NNS for_IN a_DT maximal_JJ amount_NN of_IN total_JJ variance_NN in_IN the_DT observed_JJ variables_NNS ._. The_DT second_JJ component_NN extracted_VBN will_MD account_VB for_IN a_DT maximal_JJ amount_NN of_IN variance_NN in_IN the_DT data_NNS set_VBN that_DT was_VBD not_RB accounted_VBN for_IN by_IN the_DT first_JJ component_NN and_CC it_PRP will_MD be_VB uncorrelated_VBN with_IN the_DT first_JJ component_NN ._. The_DT remaining_VBG components_NNS that_WDT are_VBP extracted_VBN in_IN the_DT analysis_NN display_NN the_DT same_JJ two_CD characteristics_NNS :_: each_DT component_NN accounts_VBZ for_IN a_DT maximal_JJ amount_NN of_IN variance_NN in_IN the_DT observed_JJ variables_NNS that_WDT was_VBD not_RB accounted_VBN for_IN by_IN the_DT preceding_VBG components_NNS ,_, and_CC is_VBZ uncorrelated_JJ with_IN all_DT of_IN the_DT preceding_VBG components_NNS ._. When_WRB the_DT principal_JJ component_NN analysis_NN will_MD complete_VB ,_, the_DT resulting_VBG components_NNS will_MD display_VB varying_VBG degrees_NNS of_IN correlation_NN with_IN the_DT observed_JJ variables_NNS ,_, but_CC are_VBP completely_RB uncorrelated_VBN with_IN one_CD another_DT ._. PCs_NNS are_VBP calculated_VBN using_VBG the_DT Eigen_NNP value_NN decomposition_NN of_IN a_DT data_NN covariance_NN matrix/_NN correlation_NN matrix_NN or_CC singular_JJ value_NN decomposition_NN of_IN a_DT data_NN matrix_NN ,_, usually_RB after_IN mean_JJ centering_NN the_DT data_NNS for_IN each_DT attribute_NN ._. Covariance_NNP matrix_NN is_VBZ preferred_VBN when_WRB the_DT variances_NNS of_IN variables_NNS are_VBP very_RB high_JJ compared_VBN to_TO correlation_NN ._. It_PRP would_MD be_VB better_JJR to_TO choose_VB the_DT type_NN of_IN correlation_NN when_WRB the_DT variables_NNS are_VBP of_IN different_JJ types_NNS ._. Similarly_RB the_DT SVD_NNP method_NN is_VBZ used_VBN for_IN numerical_JJ accuracy_NN [19].After_IN finding_VBG principal_JJ components_NNS reduced_VBN dataset_NN is_VBZ applied_VBN to_TO kmeans_NNS clustering_VBG ._. Here_RB also_RB we_PRP have_VBP proposed_VBN a_DT new_JJ method_NN to_TO find_VB the_DT initial_JJ centroids_NNS to_TO make_VB the_DT algorithm_NN more_RBR effective_JJ and_CC efficient_JJ ._. The_DT main_JJ advantage_NN of_IN this_DT approach_NN stems_VBZ from_IN the_DT fact_NN that_IN this_DT framework_NN is_VBZ able_JJ to_TO obtain_VB better_JJR clustering_NN with_IN reduced_JJ complexity_NN and_CC also_RB provides_VBZ better_JJR accuracy_NN and_CC efficiency_NN for_IN high_JJ dimensional_JJ datasets_NNS 3._. DATASET_NNP DESCRIPTION_NNP Experiments_NNS are_VBP conducted_VBN on_IN a_DT breast_NN cancer_NN data_NNS set_VBN which_WDT data_NNS is_VBZ gathered_VBN from_IN uci_NNS web_NN site_NN ._. This_DT web_NN site_NN is_VBZ for_IN finding_VBG suitable_JJ partners_NNS who_WP are_VBP very_RB similar_JJ from_IN point_NN of_IN personality’s_JJ view_NN for_IN a_DT person_NN ._. Based_VBN on_IN 8_CD pages_NNS of_IN psychiatric_JJ questions_NNS personality_NN of_IN people_NNS for_IN different_JJ aspects_NNS is_VBZ extracted_VBN ._. Each_DT group_NN of_IN questions_NNS is_VBZ related_VBN to_TO one_CD dimension_NN of_IN personality_NN ._. To_TO trust_NN of_IN user_NN some_DT questions_NNS is_VBZ considered_VBN and_CC caused_VBN reliability_NN of_IN answers_NNS are_VBP increased_VBN ._. Data_NNP are_VBP organized_VBN in_IN a_DT table_NN with_IN 90_CD columns_NNS for_IN attributes_NNS of_IN people_NNS and_CC 704_CD rows_NNS which_WDT are_VBP for_IN samples_NNS ._. There_EX are_VBP missing_VBG values_NNS in_IN this_DT table_NN because_IN some_DT questions_NNS have_VBP not_RB been_VBN answered_VBN ,_, so_RB we_PRP replaced_VBD them_PRP with_IN 0._CD On_IN the_DT other_JJ hand_NN we_PRP need_VBP to_TO calculate_VB length_NN of_IN each_DT vector_NN base_NN on_IN its_PRP$ dimensions_NNS for_IN further_JJ process_NN ._. All_DT attributes_NNS value_NN in_IN this_DT table_NN is_VBZ ordinal_JJ and_CC we_PRP arranged_VBD them_PRP with_IN value_NN from_IN 1_CD to_TO 5_CD ,_, therefore_RB normalizing_, has_VBZ not_RB been_VBN done_VBN ._. There_EX is_VBZ not_RB any_DT correlation_NN among_IN attributes_NNS and_CC it_PRP concretes_VBZ an_DT orthogonal_JJ space_NN for_IN using_VBG Euclidean_JJ distance_NN ._. All_DT samples_NNS are_VBP included_VBN same_JJ number_NN of_IN attributes_NNS ._. 4_CD ._. EXPERIMENTAL_NNP SETUP_NNP In_IN all_DT experiments_NNS we_PRP use_VBP MATLAB_NNP software_NN as_IN a_DT powerful_JJ tool_NN to_TO compute_VB clusters_NNS and_CC windows_NNS XP_RB with_IN Pentium_NNP 2.1_CD GHZ._NNP Reduced_NNP datasets_NNS done_VBN by_IN principal_JJ component_NN analysis_NN reduction_NN method_NN is_VBZ applied_VBN to_TO kmeans_NNS clustering_VBG ._. As_IN a_DT similarity_NN metric_JJ ,_, Euclidean_JJ distance_NN has_VBZ been_VBN used_VBN in_IN kmeans_NNS algorithm.The_DT steps_NNS of_IN the_DT Amalgamation_NNP k-means_NNS clustering_VBG algorithm_NN are_VBP as_IN follows_VBZ ._. Input_NNP :_: X_NNP =_SYM {d1_CD ,_, d2_CC ,……..,dn_NNP }_VBD //_RB set_VBN of_IN n_NN data_NNS items_NNS ._. Output_NN :_: A_DT set_NN of_IN k_NN clusters_NNS Phase-1_NN :_: Apply_NNP Pca_NNP to_TO Reduce_VB the_DT Dimension_NNP of_IN the_DT Breast_NNP Cancer_NNP Data_NNP Set_NNP Step_NNP 1_CD :_: Organize_NNP the_DT dataset_NN in_IN a_DT matrix_NN X_NNP ._. Step_NNP 2_CD :_: Normalize_VB the_DT data_NNS set_VBN using_VBG Z-score_NNP ._. Step_NNP 3_CD :_: Calculate_VB the_DT singular_JJ value_NN decomposition_NN of_IN the_DT data_NNS matrix_NN ._. X_NNP =UDV_NNP T_NNP Step_NNP 4_CD :_: Calculate_VB the_DT variance_NN using_VBG the_DT diagonal_JJ elements_NNS of_IN D._NNP Step_NNP 5_CD :_: Sort_VB variances_NNS in_IN decreasing_VBG order_NN ._. Step_NNP 6_CD :_: Choose_VB the_DT p_NN principal_JJ components_NNS from_IN V_NNP with_IN largest_JJS variances_NNS ._. Step_NN 7_CD :_: Form_IN the_DT transformation_NN matrix_NN W_NNP consisting_VBG of_IN those_DT p_JJ PCs_NNS ._. Step_NN 8_CD :_: Find_VB the_DT reduced_JJ projected_VBN dataset_NN Y_PRP in_IN a_DT new_JJ coordinate_VB axis_NN by_IN applying_VBG W_NNP to_TO X_NNP ._. Phase-2_NNP :_: Find_VB the_DT Initial_JJ Centroids_NNP Step_NNP 1_CD :_: For_IN a_DT data_NN set_VBN with_IN dimensionality_NN ,_, d_VBD ,_, compute_VB the_DT variance_NN of_IN data_NNS in_IN each_DT dimension(_NN column_NN )_-RRB- ._. Step_NNP 2_CD :_: Find_VB the_DT column_NN with_IN maximum_JJ variance_NN and_CC call_VB it_PRP as_IN max_NN and_CC sort_NN it_PRP in_IN any_DT order_NN ._. Ste_NNP p_NN 3_CD :_: Divide_VB the_DT data_NNS points_NNS of_IN cvmax_NN into_IN K_NNP subsets_NNS ,_, where_WRB K_NNP is_VBZ the_DT desired_VBN number_NN of_IN clusters_NNS ._. Step_NN 4_CD :_: Find_VB the_DT median_NN of_IN each_DT subset_NN ._. Step_NN 5_CD :_: Use_VB the_DT corresponding_JJ data_NNS points_NNS (vectors_NNS )_-RRB- for_IN Step_NNP 6_CD :_: each_DT median_NN to_TO initialize_VB the_DT cluster_NN centers_NNS ._. Phase-3_NN :_: Apply_NNP K-Means_NNP Clustering_NNP With_IN Reduced_NNP Datasets_NNPS ._. Step_NNP 1_CD :_: Initialization_NN :_: choose_VB randomly_RB K_NNP input_NN vectors_NNS (_-LRB- data_NN points_NNS )_-RRB- to_TO initialize_VB the_DT clusters_NNS ._. Step_NN 2_CD :_: Nearest-neighbor_NNP search_NN :_: for_IN each_DT input_NN vector_RB ,_, find_VB the_DT cluster_NN center_NN that_WDT is_VBZ closest_JJS ,_, and_CC assign_NN that_IN input_NN vector_NN to_TO the_DT corresponding_JJ cluster_NN ._. Step_NN 3_CD :_: Mean_NNP update_VB :_: update_VB the_DT cluster_NN centers_NNS in_IN each_DT cluster_NN using_VBG the_DT mean_JJ (centroid_NN )_-RRB- of_IN the_DT input_NN vectors_NNS assigned_VBN to_TO that_DT cluster_NN ._. Step_VB 4_CD :_: Stopping_NNP rule_NN :_: repeat_NN steps_NNS 2_CD and_CC 3_CD until_IN no_DT more_JJR change_NN in_IN the_DT value_NN of_IN the_DT means_NNS ._. 4.1_CD Experimental_NNP Results_NNS Breast_NNP cancer_NN original_JJ dataset_NN is_VBZ reduced_VBN using_VBG principal_JJ component_NN analysis_NN reduction_NN method_NN ._. Dataset_NNP consists_VBZ of_IN 569_CD instances_NNS and_CC 30_CD attributes_NNS ._. Here_RB the_DT Sum_NNP of_IN Squared_NNP Error_NNP (_-LRB- SSE)_NNP ,_, representing_VBG distances_NNS between_IN data_NNS points_NNS and_CC their_PRP$ cluster_NN centers_NNS have_VBP used_VBN to_TO measure_VB the_DT clustering_VBG quality_NN ._. International_NNP Journal_NNP of_IN Computer_NNP Applications_NNPS (_-LRB- 0975_CD –_NN 8887_CD )_-RRB- Volume_NN 13–_CD No.7_NN ,_, January_NNP 2011_CD 44_CD Step_NNP 1_CD :_: Normalizing_VBG the_DT original_JJ data_NNS set_VBN Using_VBG the_DT Normalization_NNP process_NN ,_, the_DT initial_JJ data_NNS values_NNS are_VBP scaled_VBN so_RB as_IN to_TO fall_VB within_IN a_DT small-specified_JJ range_NN ._. An_DT attribute_NN value_NN V_NNP of_IN an_DT attribute_NN A_DT is_VBZ normalized_JJ to_TO V’_VB using_VBG Z-Score_JJ as_IN follows_VBZ :_: V’=_JJ (V-mean_JJ (_-LRB- A_DT )_-RRB- )_-RRB- /std_NN (_-LRB- A_DT )_-RRB- (_-LRB- 1_CD )_-RRB- It_PRP performs_VBZ two_CD things_NNS i_IN .e_NNP ._. data_NNS centering_NN ,_, which_WDT reduces_VBZ the_DT square_NN mean_JJ error_NN of_IN approximating_VBG the_DT input_NN data_NNS and_CC data_NNS scaling_NN ,_, which_WDT standardizes_VBZ the_DT variables_NNS to_TO have_VB unit_NN variance_NN before_IN the_DT analysis_NN takes_VBZ place_NN ._. This_DT normalization_NN prevents_VBZ certain_JJ features_NNS to_TO dominate_VB the_DT analysis_NN because_IN of_IN their_PRP$ large_JJ numerical_JJ values_NNS ._. Step_NN 2_CD :_: Calculating_VBG the_DT PCs_NNS using_VBG Singular_NNP Value_NNP Decomposition_NNP of_IN the_DT normalized_JJ data_NNS matrix_NN The_DT number_NN of_IN PCs_NNS obtained_VBN is_VBZ same_JJ with_IN the_DT number_NN of_IN original_JJ variables_NNS ._. To_TO eliminate_VB the_DT weaker_JJR components_NNS from_IN this_DT PC_NN set_NN we_PRP have_VBP calculated_VBN the_DT corresponding_JJ variance_NN ,_, percentage_NN of_IN variance_NN and_CC cumulative_JJ variances_NNS in_IN percentage_NN ,_, which_WDT is_VBZ shown_VBN in_IN Table_NN 1_CD ._. Then_RB we_PRP have_VBP considered_VBN the_DT PCs_NNS having_VBG variances_VBZ less_JJR than_IN the_DT mean_JJ variance_NN ,_, ignoring_VBG the_DT others_NNS ._. The_DT variance_NN in_IN percentage_NN is_VBZ evaluated_VBN and_CC the_DT cumulative_JJ variance_NN in_IN percentage_NN first_JJ value_NN is_VBZ same_JJ as_IN percentage_NN in_IN variance_NN ,_, second_JJ value_NN is_VBZ summation_NN of_IN cumulative_JJ variance_NN in_IN percentage_NN and_CC variance_NN in_IN percentage_NN ._. Similarly_RB other_JJ values_NNS of_IN cumulative_JJ variance_NN is_VBZ calculated_VBN ._. Step_NNP 3_CD :_: Finding_VBG the_DT reduced_VBN data_NNS set_VBN using_VBG the_DT reduced_JJ PCs_NNS The_DT transformation_NN matrix_NN with_IN reduced_JJ PCs_NNS is_VBZ formed_VBN and_CC this_DT transformation_NN matrix_NN is_VBZ applied_VBN to_TO the_DT normalized_JJ data_NNS set_VBN to_TO produce_VB the_DT new_JJ reduced_JJ projected_VBN dataset_NN ,_, which_WDT can_MD be_VB used_VBN for_IN further_JJ data_NNS analysis_NN ,also_RB applied_VBD the_DT PCA_NNP on_IN three_CD biological_JJ dataset_NN and_CC the_DT reduced_VBN no_NN ._. of_IN attributes_NNS obtained_VBN for_IN each_DT dataset_NN ._. Step_VB 4_CD :_: Finding_NNP intial_, centroids_NNS The_DT proposed_VBN algorithm_NN finds_VBZ a_DT set_NN of_IN medians_NNS extracted_VBN from_IN the_DT dimension_NN with_IN maximum_JJ variance_NN to_TO initialize_VB clusters_NNS of_IN the_DT k_NN -_: means[10]_NN ._. The_DT method_NN can_MD give_VB better_JJR results_NNS when_WRB applied_VBN to_TO k_VB -_: means_VBZ ._. Step_NNP 5_CD :_: Reduced_VBN datasets_NNS are_VBP applied_VBN to_TO k-means_NNS algorithm_IN with_IN computed_VBN centroids_NNS The_DT reduced_JJ breast_NN cancer_NN dataset_NN is_VBZ applied_VBN to_TO the_DT standard_JJ k-means_NNS clustering[2_VBP ]_JJ to_TO ._. The_DT SSE_NNP value_NN obtained_VBN and_CC the_DT time_NN taken_VBN in_IN ms_NNS for_IN reduced_JJ breast_NN cancer_NN datasets_NNS with_IN original_JJ Amalamation_NNP k-means_NNS is_VBZ given_VBN in_IN Table_NN 2_CD Table_NN 1.The_CD Variances_NNP ,_, Variances_NNP in_IN Percentages_NNP ,_, and_CC Cumulative_JJ Variances_NNP in_IN Percentages_NNP Corresponding_NNP to_TO Pcs_NNP Table_NNP 2._VBD Shows_NNP Results_NNS Of_IN Amalgamation_NNP Of_IN K-means_NNP With_IN Number_NNP Of_IN Clusters_NNP ,_, SSE_NNP and_CC Execution_NNP Time_NNP Amalgamation_NNP K_NNP –Means_NNP Algorithm_NNP Dataset_NNP No_DT of_IN Clusters_NNP SSE_NNP Execution_NNP Time(_NNP in_IN ms_NNS )_-RRB- Breast_NNP Cancer_NNP Reduced_NNP Dataset_NNP 1_CD 12603_CD 0.598_CD 2_CD 9513_CD 0.623_CD 3_CD 7641_CD 0.791_CD 4_CD 4841_CD 0.771_CD 5_CD 811_CD 0.889_CD International_NNP Journal_NNP of_IN Computer_NNP Applications_NNPS (_-LRB- 0975_CD –_NN 8887_CD )_-RRB- Volume_NN 13–_CD No.7_NN ,_, January_NNP 2011_CD 45_CD The_DT above_IN results_NNS show_VBP that_IN the_DT Amalgamation_NNP kmeans_VBZ algorithm_NN provides_VBZ sum_NN of_IN squared_JJ error_NN distance_NN and_CC Execution_NNP time_NN of_IN corresponding_JJ clusters_NNS ._. Figure_NN 1_CD ._. shows_NNS graph_NN of_IN SSE_NNP and_CC Number_NNP of_IN clusters_NNS ._. In_IN this_DT figure_NN ,_, when_WRB number_NN of_IN clusters_NNS increases_NNS ,_, sum_NN of_IN squared_JJ error_NN distance_NN values_NNS decreases_VBZ .Figure_NN 2.shows_VBZ number_NN of_IN clusters_NNS increases_NNS ,_, Execution_NNP time_NN increases_NNS ._. Figure_NN 1_CD ._. Shows_NNP SSE_NNP and_CC Number_NNP of_IN Clusters_NNP Figure_NNP 2._VBD Shows_NNP Execution_NNP Time_NNP and_CC Number_NNP Of_IN Clusters_NNP The_DT following_VBG Figure_NN 3._. And_CC Figure_NNP 4_CD ._. shows_VBZ the_DT Cluster_NNP Results_NNS for_IN BREAST_NN CANCER_NNP DataSet_NNP in_IN 2Dand_NNP 3D_IN using_VBG Amalgamation_NNP K-_NNP Means_VBZ Algorithm_NNP with_IN the_DT number_NN of_IN clusters_NNS K=5_IN Figure_NN 3._. Shows_. Clusters_NNS For_IN Breast_NNP Cancer_NNP Dataset_NNP Using_VBG Amalgamation_NNP K-means_NNP Algorithm_NNP in_IN 2D_NNP Figure_NNP 4_CD ._. Shows_NNP Clusters_NNP for_IN Breast_NNP Cancer_NNP Dataset_NNP Using_VBG Amalgamation_NNP K-means_NNP Algorithm_NNP in_IN 3D_NNP 5_CD ._. CONCLUSION_NN In_IN this_DT paper_NN a_DT dimensionality_NN reduction_NN through_IN PCA_NNP ,_, is_VBZ applied_VBN to_TO k_VB -_: means_VBZ algorithm_NN ._. Using_VBG Dimension_NNP reduction_NN of_IN principal_JJ component_NN analysis_NN ,_, original_JJ breast_NN cancer_NN dataset_NN is_VBZ compact_JJ to_TO reduced_JJ data_NNS set_VBN which_WDT was_VBD partitioned_VBN in_IN to_TO k_VB clusters_NNS in_IN such_JJ a_DT way_NN that_IN the_DT sum_NN of_IN the_DT total_JJ clustering_JJ errors_NNS for_IN all_DT clusters_NNS was_VBD reduced_VBN as_RB much_RB as_IN possible_JJ while_IN inter_NN distances_NNS between_IN clusters_NNS are_VBP maintained_VBN to_TO be_VB as_RB large_JJ as_IN possible_JJ ._. We_PRP propose_VBP a_DT new_JJ algorithm_NN to_TO initialize_VB the_DT clusters_NNS which_WDT is_VBZ then_RB applied_VBN to_TO k-means_NNS algorithm_NN ._. The_DT experimental_JJ results_NNS show_VBP that_IN principal_JJ component_NN analysis_NN is_VBZ used_VBN to_TO reduce_VB attributes_NNS and_CC reduced_VBN dataset_NN is_VBZ applied_VBN to_TO k-means_NNS clustering_VBG with_IN computed_JJ centroids_NNS ._. Evolving_NN some_DT dimensional_JJ reduction_NN methods_NNS like_IN canon_NN pies_NNS can_MD be_VB used_VBN for_IN high_JJ dimensional_JJ datasets_NNS is_VBZ suggested_VBN as_IN future_JJ work_NN ._. 6_CD ._. REFERENCES_NNS [1_. ]_NN Bradley_NNP ,_, P._NNP S._NNP ,_, Bennett_NNP ,_, K._NNP P._NNP ,_, &_CC Demiriz_NNP ,_, A._NN (_-LRB- 2000_CD ).Constrained_VBN k-means_NNS clustering_VBG (_-LRB- Technical_NNP ReportMSR-TR-2000-65_NNP )_-RRB- ._. Microsoft_NNP Research_NNP ,_, Redmond_NNP ,_, WA_NNP ._. [2_CD ]_NNP C_NNP Ding_NNP ,”Principal_NNP Component_NNP Analysis_NNP and_CC Effective_JJ K-means_NNP Clustering_NNP ”_NNP [3_VBD ]_SYM Chao_NNP Shi_NNP and_CC Chen_NNP Lihui_NNP ,_, 2005_CD ._. Feature_NNP dimension_NN reduction_NN for_IN microarray_NN data_NNS analysis_NN using_VBG locally_RB linear_JJ embedding_VBG ,_, 3rd_JJ Asia_NNP Pacific_NNP Bioinformatics_NNP Conference_NNP ,_, pp_RP ._. 211-217_CD ._. [4_'' ]_SYM Chris_NNP Ding_NNP and_CC Xiaofeng_NNP He_PRP ,_, “K-Means_NNP Clustering_NNP via_IN Principal_NNP Component_NNP Analysis”_NNP ,_, In_IN proceedings_NNS of_IN the_DT 21st_JJ International_NNP Conference_NNP on_IN Machine_NNP Learning_NNP ,_, Banff_NNP ,_, Canada_NNP ,_, 2004_CD [5_CD ]_NN Davy_NNP Michael_NNP and_CC Luz_NNP Saturnine_NNP ,_, 2007_CD ._. Dimensionality_NNP reduction_NN for_IN active_JJ learning_NN with_IN nearest_JJS neighbor_NN classifier_NN in_IN text_NN categorization_NN problems_NNS ,_, Sixth_NNP International_NNP Conference_NNP on_IN Machine_NNP Learning_NNP and_CC Applications_NNP ,_, pp_RP ._. 292-297_CD [6_CD ]_SYM IEEEI.T_NNP Jolliffe_NNP ,_, “Principal_JJ Component_JJ Analysis”_NNS ,_, Springer_NNP ,_, second_JJ edition_NN ._. International_NNP Journal_NNP of_IN Computer_NNP Applications_NNPS (_-LRB- 0975_CD –_NN 8887_CD )_-RRB- Volume_NN 13–_CD No.7_NN ,_, January_NNP 2011_CD 46_CD [7_IN ]_VBN Kiri_NNP Wagsta_NNP -_: Claire_NNP Cardie_NNP ,”Constrained_VBD K-means_NNP Clustering_NNP with_IN Background_NNP Knowledge_NNP ”_, [8_CD ]_SYM .Maaten_VBN L.J.P._NNP ,_, Postma_NNP E.O._NNP and_CC Herik_NNP H.J._NNP van_NNP den_NN ,_, 2007_CD ._. Dimensionality_NNP reduction_NN :_: A_DT comparative_JJ review”_NN ,_, Tech_NNP ._. rep._NNP University_NNP of_IN Maastricht_NNP ._. [9_'' ]_SYM Moth’d_NNP Belal_NNP ._. Al-Daoud_NNP ,_, (_-LRB- 2005_CD ).A_NNP New_NNP Algorithm_NNP for_IN Cluster_NNP Initialization_NNP ,_, World_NNP Academy_NNP of_IN Science_NNP ,_, Engineering_NNP and_CC Technology_NNP ._. [10]_'' ._. O_UH Shamir_NNP ,”Model_NNP Selection_NNP and_CC Stability_NNP in_IN k-means_NNS Clustering_VBG ”_IN [11]_NNP Rand_NNP ,_, W._NNP M._NNP (_-LRB- 1971_CD )_-RRB- ._. Objective_NNP criteria_NNS for_IN the_DT evaluation_NN of_IN clustering_NN met_VBD hods_NNS ._. Journal_NNP of_IN the_DT AmericanStatistical_NNP Association_NNP ,_, 66_CD ,_, 846-850_CD ._. [12]_IN .RM_JJ Suresh_JJ ,_, K_NNP Dinakaran_NNP ,_, P_NNP Valarmathie_NNP ,“Model_NN based_VBN modified_VBN k-means_NNS clustering_VBG for_IN microarray_NN data”_NNS ,_, [13]_VBP International_NNP Conference_NNP on_IN Information_NNP Management_NNP and_CC Engineering_NNP ,_, Vol_NNP .13_CD ,_, pp_RP 271-273_CD ,_, 2009_CD ,_, [14].Valarmathie_NNP P._NNP ,_, Srinath_NNP M._NNP and_CC Dinakaran_NNP K._NNP ,_, 2009_CD ._. An_DT increased_VBN performance_NN of_IN clustering_VBG high_JJ dimensional_JJ data_NNS through_IN dimensionality_NN reduction_NN technique_NN ,_, Journal_NNP of_IN Theoretical_NNP and_CC Applied_NNP Information_NNP Technology_NNP ,_, Vol_NNP ._. 13_CD ,_, pp_RP ._. 271-273_CD [14]_CD ._. Wagsta__NNP ,_, K._NNP ,_, &_CC Cardie_NNP ,_, C._NNP (_-LRB- 2000_CD )_-RRB- ._. Clustering_NNP with_IN instance_NN -_: level_NN constraints_NNS ._. Proceedings_NNS of_IN the_DT Seventeenth_NNP International_NNP Conference_NNP on_IN Machine_NN Learning_VBG (_-LRB- pp_RP ._. 1103{1110_CD )_-RRB- ._. Palo_NNP Alto_NNP ,_, CA_NNP :_: Morgan_NNP Kaufmann_NNP ._. [15_CD ]_SYM Wray_NNP Buntine_NNP ,_, ”_NNP K-means_NNP Clustering_NNP and_CC PCA”_NNP ,_, National_NNP ICT_NNP Australia_NNP [16]_VBD ._. Xu_NNP R._NNP and_CC Wunsch_NNP D._NNP ,_, 2005_CD ._. Survey_NNP of_IN clustering_VBG algorithms_NNS ,_, IEEE_NNP Trans_NNP ._. Neural_NNP Networks_NNP ,_, Vol_NN ._. 16_CD ,_, No._NN 3_CD ,_, pp_RP ._. 645-678_CD ._. [17]_'' Yan_NNP Jun_NNP ,_, Zhang_NNP Benyu_NNP ,_, Liu_NNP Ning_NNP ,_, Yan_NNP Shuicheng_NNP ,_, Cheng_NNP Qiansheng_NNP ,_, Fan_NNP Weiguo_NNP ,_, Yang_NNP Qiang_NNP ,_, Xi_NNP Wensi_NNP ,_, and_CC Chen_NNP Zheng_NNP ,2006_CD ._. Effective_JJ and_CC efficient_JJ dimensionality_NN reduction_NN for_IN large-scale_JJ and_CC streaming_VBG data_NNS preprocessing_NN ,_, IEEE_NN transactions_NNS on_IN Knowledge_NNP and_CC Data_NNP Engineering_NNP ,_, Vol_NNP ._. 18_CD ,_, No._NN 3_CD ,_, pp_RP ._. 320-_CD 333_CD ._. [18]_'' Yeung_NNP Ka_NNP Yee_NNP and_CC Ruzzo_NNP Walter_NNP L._NNP ,_, 2000_CD ._. An_DT empirical_JJ study_NN on_IN principal_JJ component_NN analysis_NN for_IN clustering_VBG gene_NN expressionData”,Tech_NN ._. Report_NNP ,_, University_NNP of_IN Washington_NNP ._.
