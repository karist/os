Fast_NN or_CC Accurate_NNP ?_. –_'' A_DT Comparative_JJ Evaluation_NN of_IN PoS_NNP Tagging_NNP Models_NNP Tobias_NNP Horsmann_NNP Nicolai_NNP Erbs_NNP Torsten_NNP Zesch_NNP Language_NNP Technology_NNP Lab_NNP Department_NNP of_IN Computer_NNP Science_NNP and_CC Applied_NNP Cognitive_NNP Science_NNP University_NNP of_IN Duisburg-Essen_NNP ,_, Germany_NNP {tobias_NNP .horsmann_NNP ,nicolai_NNP .erbs_VBZ ,torsten.zesch_JJ }@uni-due_JJ .de_NN Abstract_NNP We_PRP perform_VBP a_DT comparison_NN of_IN 27_CD PoS_NNP tag-_NNS ger_NN models_NNS for_IN English_NNP and_CC German_NNP offered_VBN by_IN 9_CD different_JJ implementations_NNS ._. By_IN eval-_DT uating_NN on_IN a_DT mix_NN of_IN corpora_NNS from_IN different_JJ domains_NNS ,_, we_PRP simulate_VBP a_DT black-box_JJ usage_NN where_WRB researchers_NNS select_VBP a_DT tagger_NN (_-LRB- because_IN of_IN popularity_NN ,_, ease_NN of_IN use_NN ,_, etc._FW )_-RRB- and_CC apply_VB it_PRP to_TO all_DT sorts_NNS of_IN text_NN ._. Surprisingly_RB ,_, a_DT manu_NN -_: ally_NN created_VBN rule-based_NN model_NN outperforms_VBZ all_DT learned_JJ models_NNS with_IN respect_NN to_TO accuracy_NN and_CC speed_NN ._. Within_IN the_DT group_NN of_IN learned_JJ models_NNS ,_, we_PRP find_VBP the_DT expected_VBN trade-off_NN be-_: tween_CD fast_JJ models_NNS with_IN relatively_RB low_JJ accu-_NNS racy_NN and_CC slower_JJR models_NNS with_IN higher_JJR accu-_NNS racy_NN ._. Our_PRP$ evaluation_NN provides_VBZ researchers_NNS with_IN a_DT basis_NN for_IN selecting_VBG taggers_NNS according_VBG to_TO their_PRP$ needs_NNS ._. 1_CD Introduction_NN Part-of-Speech_NNP (_-LRB- PoS_NNP )_-RRB- tagging_NN is_VBZ one_CD of_IN the_DT most_RBS important_JJ steps_NNS in_IN Natural_JJ Language_NN Processing_NNP (_-LRB- NLP)_NN ._. Consequently_RB ,_, researchers_NNS can_MD choose_VB from_IN a_DT wide_JJ range_NN of_IN available_JJ PoS_NNP taggers_NNS ,_, popular_JJ choices_NNS include_VBP TreeTagger_NNP (_-LRB- Schmid_NNP ,_, 1995_CD )_-RRB- ,_, Stan-_NNP ford_NN Tagger_NN (_-LRB- Toutanova_NNP et_NNP al_NN ._. ,_, 2003_CD )_-RRB- ,_, or_CC ClearNLP_NNP (_-LRB- Choi_NNP and_CC Palmer_NNP ,_, 2012_CD )_-RRB- ._. The_DT decision_NN for_IN a_DT certain_JJ tool_NN is_VBZ mainly_RB influenced_VBN by_IN tagging_VBG accuracy_NN ,_, but_CC other_JJ practical_JJ issues_NNS like_IN ease_NN of_IN use_NN ,_, speed_NN ,_, appli-_DT cability_NN to_TO target_VB language_NN and_CC domain_NN ,_, or_CC availabil-_DT ity_NN for_IN a_DT certain_JJ hardware_NN platform_NN might_MD also_RB play_VB a_DT role_NN ._. In_IN this_DT paper_NN ,_, we_PRP focus_VBP on_IN tagging_VBG accuracy_NN vs._IN speed_NN and_CC perform_VB a_DT comparative_JJ evaluation_NN of_IN 27_CD tagging_NN models_NNS for_IN English_NNP and_CC German_NNP ,_, offered_VBN by_IN 9_CD different_JJ PoS_NNP tagger_NN implementations_NNS ._. We_PRP evaluate_VB on_IN a_DT range_NN of_IN English_NNP and_CC German_NNP corpora_NN from_IN three_CD different_JJ broad_JJ domains_NNS (_-LRB- formal_JJ writing_NN ,_, speech_NN transcripts_NNS ,_, and_CC social_JJ media_NNS )_-RRB- ._. To_TO our_PRP$ knowledge_NN ,_, this_DT is_VBZ the_DT most_RBS comprehen-_POS sive_JJ evaluation_NN to_TO date_NN ._. Giesbrecht_NNP and_CC Evert_NNP (_-LRB- 2009_CD )_-RRB- compared_VBN German_JJ models_NNS of_IN five_CD PoS_NNP taggers_NNS and_CC Miguel_NNP and_CC Roxas_NNP (_-LRB- 2007_CD )_-RRB- compared_VBN four_CD Tagalog_NNP taggers_NNS on_IN a_DT single_JJ corpus_JJ ._. PoS_NNP tagging_VBG A_DT PoS_NNP tagger_NN is_VBZ an_DT application_NN that_IN assigns_NNS the_DT word_NN class_NN (_-LRB- i_FW .e_NN ._. the_DT PoS_NNP tag_NN )_-RRB- to_TO each_DT token_NN in_IN a_DT sentence_NN ._. PoS_'' taggers_NNS can_MD loosely_RB be_VB categorized_VBN into_IN unsupervised_JJ ,_, supervised_JJ ,_, and_CC rule_VB -_: based_VBN taggers_NNS ._. Unsupervised_NN taggers_NNS (_-LRB- Goldwater_NNP and_CC Griffiths_NNS ,_, 2007_CD ;_: Biemann_NNP ,_, 2006_CD ;_: Das_NNP and_CC Petrov_NNP ,_, 2011_CD )_-RRB- ana_NN -_: lyze_VBP large_JJ quantities_NNS of_IN plain_JJ text_NN and_CC group_NN words_NNS by_IN their_PRP$ context_NN similarity_NN ._. The_DT assumption_NN is_VBZ that_IN words_NNS that_WDT are_VBP grouped_VBN together_RB share_VBP the_DT same_JJ word_NN class_NN ._. However_RB ,_, this_DT word_NN class_NN is_VBZ not_RB made_VBN explicit_JJ in_IN this_DT case_NN ,_, which_WDT is_VBZ why_WRB unsupervised_JJ taggers_NNS are_VBP rarely_RB used_VBN on_IN their_PRP$ own_JJ but_CC usually_RB added_VBN as_IN features_NNS in_IN a_DT supervised_JJ setting_NN (_-LRB- Ritter_NNP et_NNP al_NN ._. ,_, 2011_CD )_-RRB- ._. Supervised_NNPS taggers_NNS are_VBP machine_NN learning_VBG appli-_NNS cations_NNS that_WDT require_VBP manually_RB annotated_JJ training_NN data_NNS ._. The_DT tagger_NN takes_VBZ the_DT annotated_VBN text_NN and_CC ex_FW -_: tracts_NNS text_NN properties_NNS (_-LRB- so_RB called_JJ features_NNS )_-RRB- that_WDT are_VBP provided_VBN to_TO the_DT machine_NN learning_NN classifier_NN which_WDT learns_VBZ a_DT model_NN that_IN maps_NNS the_DT feature_NN representation_NN of_IN tokens_NNS to_TO the_DT corresponding_JJ PoS_NNP tags_NNS ._. When_WRB running_VBG the_DT tagger_NN ,_, the_DT same_JJ feature_NN representa_NN -_: tion_NN is_VBZ extracted_VBN from_IN the_DT raw_JJ input_NN text_NN and_CC the_DT trained_JJ model_NN is_VBZ applied_VBN to_TO select_VB a_DT tag_NN for_IN every_DT token_JJ based_VBN on_IN the_DT feature_NN values_NNS ._. A_DT model_NN is_VBZ thus_RB best_RB applied_VBN to_TO input_NN text_NN that_WDT is_VBZ as_IN similar_JJ to_TO the_DT training_NN data_NNS as_IN possible_JJ ._. In_IN case_NN of_IN a_DT mismatch_NN ,_, e.g_NN ._. a_DT model_NN trained_VBN on_IN newswire_NN applied_VBN to_TO speech_NN transcripts_NNS ,_, the_DT extracted_VBN feature_NN values_NNS might_MD not_RB match_VB with_IN the_DT expected_VBN ones_NNS ._. As_IN a_DT consequence_NN ,_, the_DT tagging_NN accuracy_NN is_VBZ considerably_RB reduced_VBN ._. Rule-based_JJ taggers_NNS utilize_VBP sets_NNS of_IN patterns_NNS or_CC rules_NNS to_TO assign_VB tags_NNS ._. In_IN principle_NN ,_, they_PRP are_VBP very_RB similar_JJ to_TO the_DT supervised_JJ taggers_NNS ,_, only_RB that_IN the_DT un-_NNP derlying_NN model_NN is_VBZ not_RB automatically_RB learned_VBN but_CC hand-curated_JJ ._. Research_NNP question_NN In_IN this_DT paper_NN ,_, we_PRP focus_VBP on_IN su-_NNS pervised_VBN and_CC rule-based_JJ taggers_NNS ,_, and_CC ask_VB the_DT ques_NNS -_: tion_NN :_: which_WDT is_VBZ the_DT best_JJS tagger_NN ?_. However_RB ,_, as_IN we_PRP have_VBP learned_VBN above_IN ,_, supervised_JJ taggers_NNS are_VBP machine_NN learning_VBG applications_NNS that_WDT use_VBP a_DT tagging_NN model_NN ._. Thus_RB ,_, many_JJ taggers_NNS come_VBN with_IN several_JJ models_NNS that_WDT are_VBP optimized_VBN for_IN different_JJ domains_NNS or_CC offer_NN trade-_NNS offs_NNS between_IN accuracy_NN and_CC speed_NN ._. Thus_RB ,_, the_DT state_NN -_: ment_NN Tagger_NN X_NNP performs_VBZ well_RB needs_VBZ to_TO be_VB rephrased_VBN as_IN Tagger_NNP X_NNP using_VBG model_NN Y_PRP performs_VBZ well_RB on_IN corpus_JJ Z._NNP As_IN the_DT performance_NN of_IN a_DT tagger_NN relies_VBZ on_IN a_DT com-_NNS plex_JJ mix_NN of_IN machine_NN learning_NN ,_, feature_NN representa_NN -_: tion_NN ,_, and_CC the_DT applied_VBN external_JJ resources_NNS ,_, we_PRP cannot_MD analytically_RB decide_VB which_WDT tagger_NN is_VBZ the_DT best_JJS ._. In-_NNP stead_RB ,_, we_PRP perform_VBP an_DT empirical_JJ evaluation_NN that_WDT will_MD provide_VB researchers_NNS with_IN a_DT sound_JJ basis_NN for_IN their_PRP$ choice_NN of_IN a_DT PoS_NNP tagger_NN ._. 2_CD Experimental_NNP setup_NN In_IN our_PRP$ experiment_NN ,_, we_PRP want_VBP to_TO evaluate_VB the_DT tag-_NNS ger_NN models_NNS of_IN various_JJ PoS_NNP tagger_NN implementations_NNS against_IN a_DT large_JJ number_NN of_IN corpora_NN from_IN various_JJ text_NN domains_VBZ ._. We_PRP base_VBP our_PRP$ experiments_NNS on_IN the_DT DKPro_NNP Core_NNP framework_NN (_-LRB- Eckart_NNP de_IN Castilho_NNP and_CC Gurevych_NNP ,_, 2014_CD )_-RRB- that_WDT is_VBZ based_VBN on_IN UIMA_NNP (_-LRB- Ferrucci_NNP and_CC Lally_NNP ,_, 2004_CD )_-RRB- ._. DKPro_NNP Core_NNP provides_VBZ wrappers_NNS for_IN a_DT wide_JJ range_NN of_IN taggers_NNS shielding_VBG the_DT user_NN from_IN the_DT intri-_NNS cate_VBP details_NNS of_IN installing_NN and_CC invoking_VBG the_DT taggers_NNS and_CC offering_VBG simple_JJ ,_, unified_JJ usage_NN by_IN providing_VBG a_DT shared_VBN interface_NN ._. A_DT UIMA_NNP workflow_NN follows_VBZ a_DT pipeline_NN principle_NN where_WRB documents_NNS are_VBP passed_VBN through_RP and_CC processed_VBN by_IN an_DT arbitrary_JJ number_NN of_IN processing_NN components_NNS ._. 2.1_CD Processing_NNP pipeline_NN In_IN our_PRP$ setup_NN ,_, each_DT corpus_NN is_VBZ read_VBN and_CC transformed_VBN into_IN the_DT internal_JJ representation_NN of_IN DKPro_NNP Core_NNP which_WDT is_VBZ based_VBN on_IN stand-off_JJ annotations_NNS ._. The_DT tag-_NNS ging_NN is_VBZ done_VBN by_IN a_DT wrapper-component_JJ that_IN encap_NN -_: sulates_VBZ the_DT PoS_NNP taggers_NNS and_CC allows_VBZ for_IN using_VBG all_DT tag-_NNS gers_NNS over_IN a_DT common_JJ interface_NN ._. The_DT wrapper_NN trans_NNS -_: forms_NNS the_DT internal_JJ representation_NN of_IN the_DT text_NN into_IN the_DT format_NN which_WDT the_DT tagger_NN requires_VBZ and_CC transforms_VBZ the_DT tagged_VBN text_NN back_RB into_IN the_DT internal_JJ representa_NN -_: tion_NN for_IN further_JJ processing_NN ._. We_PRP then_RB apply_VBP a_DT post-_NNS processing_VBG step_NN (_-LRB- Ritter_NNP et_NNP al_NN ._. ,_, 2011_CD )_-RRB- that_WDT uses_VBZ regular_JJ expressions_NNS to_TO recognize_VB and_CC correctly_RB tag_VB special_JJ entities_NNS like_IN email_NN addresses_NNS ,_, URLs_NNP ,_, and_CC Twitter-_NNP specific_JJ phenomena_NNS like_IN hashtags_NNS ,_, at-mentions_NNS ,_, and_CC retweets_NNS ._. A_DT final_JJ evaluation_NN component_NN compares_VBZ the_DT assigned_VBN tags_NNS to_TO the_DT gold_NN tags_NNS from_IN the_DT corpus_FW ._. Directly_RB before_IN and_CC after_IN the_DT tagger_NN component_NN ,_, we_PRP inject_VBP time_NN measuring_VBG components_NNS in_IN order_NN to_TO ensure_VB that_IN only_RB the_DT actual_JJ time_NN spent_VBN for_IN tagging_NN is_VBZ measured_VBN ._. However_RB ,_, our_PRP$ measuring_NN includes_VBZ the_DT time_NN that_IN the_DT wrapper_NN needs_VBZ to_TO feed_VB the_DT data_NNS to_TO the_DT underlying_VBG tagger_NN implementation_NN ._. In_IN case_NN of_IN Java_NNP taggers_NNS ,_, this_DT is_VBZ usually_RB just_RB a_DT method_NN call_NN ,_, but_CC in_IN case_NN of_IN wrapped_VBN C_NNP binaries_NNS there_EX might_MD be_VB a_DT con-_NNS siderable_JJ overhead_NN ._. Thus_RB ,_, the_DT runtime_NN reported_VBD in_IN this_DT study_NN might_MD differ_VB than_IN when_WRB running_VBG a_DT tagger_NN without_IN the_DT wrapper_NN ._. A_DT further_JJ issue_NN that_WDT might_MD affect_VB the_DT time_NN mea_NN -_: surement_NN is_VBZ document_NN size_NN ._. Some_DT taggers_NNS are_VBP fastest_JJS when_WRB fed_VBN with_IN small_JJ chunks_NNS of_IN data_NNS ,_, while_IN others_NNS are_VBP optimized_JJ for_IN processing_VBG large_JJ docu-_NNS ments_NNS as_IN a_DT whole_NN ._. In_IN order_NN to_TO account_VB for_IN this_DT difference_NN ,_, we_PRP run_VBP all_DT experiments_NNS twice_RB :_: (_-LRB- i_NN )_-RRB- with_IN each_DT sentence_NN as_IN a_DT unit_NN of_IN processing_NN ,_, and_CC (_-LRB- ii_NNS )_-RRB- the_DT entire_JJ corpus_JJ as_IN a_DT unit_NN of_IN processing_NN ._. We_PRP then_RB re_VBP -_: port_NN the_DT run_NN that_WDT takes_VBZ less_JJR time_NN .1_CD 2.2_CD Tagger_NN implementations_NNS and_CC models_NNS We_PRP now_RB describe_VBP the_DT PoS_NNP taggers_NNS and_CC their_PRP$ models_NNS used_VBN in_IN this_DT study_NN (_-LRB- see_VB Table_NN 1_CD for_IN an_DT overview_NN )_-RRB- ._. If_IN available_JJ ,_, we_PRP provide_VBP information_NN about_IN the_DT do_VBP -_: main_JJ of_IN the_DT training_NN data_NNS that_WDT were_VBD used_VBN to_TO train_VB the_DT models_NNS ._. Arktools_NNS (_-LRB- Owoputi_NNP et_NNP al_NN ._. ,_, 2013_CD )_-RRB- is_VBZ tailored_VBN to_TO tag_VB social_JJ media_NNS messages_NNS ._. Three_CD models_NNS are_VBP available_JJ ,_, the_DT first_JJ one_CD is_VBZ trained_VBN on_IN Twitter_NNP data_NNS by_IN (_-LRB- Gimpel_NNP et_NNP al_NN ._. ,_, 2011_CD ;_: Owoputi_NNP et_NNP al_NN ._. ,_, 2013_CD )_-RRB- ,_, which_WDT use_VBP the_DT coarse-grained_JJ Gimpel_NNP tagset_NN ._. The_DT other_JJ two_CD use_VBP the_DT Penn_NNP Treebank_NNP (_-LRB- PTB_NN )_-RRB- tagset_NN and_CC are_VBP trained_VBN on_IN annotated_JJ IRC_NNP chat_NN data_NNS by_IN (_-LRB- Forsyth_NNP and_CC Martell_NNP ,_, 2007_CD )_-RRB- and_CC Tweets_NNS by_IN (_-LRB- Ritter_NNP et_NNP al_NN ._. ,_, 2011_CD )_-RRB- ._. ClearNLP_NNP (_-LRB- Choi_NNP and_CC Palmer_NNP ,_, 2012_CD )_-RRB- provides_VBZ two_CD English_JJ models_NNS ._. One_NN trained_VBN on_IN medical_JJ text_NN and_CC one_NN trained_VBN on_IN a_DT mixture_NN of_IN text_NN from_IN various_JJ genres_NNS that_WDT is_VBZ mostly_RB news-related_JJ ._. Hepple_NNP (_-LRB- Hepple_NNP ,_, 2000_CD )_-RRB- is_VBZ a_DT rule-based_JJ tagger_NN similar_JJ to_TO the_DT Brill-Tagger_NNP (_-LRB- Brill_NNP ,_, 1992_CD )_-RRB- ._. HunPos_NNP (_-LRB- Halácsy_NNP et_NNP al_NN ._. ,_, 2007_CD )_-RRB- is_VBZ an_DT open-source_JJ reimplementation_NN of_IN the_DT TNT_NNP tagger_NN (_-LRB- Brants_NNPS ,_, 2000_CD )_-RRB- ._. Newswire_NNP models_NNS are_VBP available_JJ for_IN English_NNP trained_VBN on_IN the_DT WSJ_NNP and_CC for_IN German_JJ trained_VBN on_IN the_DT Tiger_NNP corpus_FW ._. LBJ_NNP (_-LRB- Roth_NNP and_CC Zelenko_NNP ,_, 1998_CD )_-RRB- provides_VBZ a_DT model_NN for_IN English_NNP trained_VBN on_IN newswire_NN text_NN ._. 1Note_VB that_IN the_DT accuracy_NN in_IN both_DT cases_NNS is_VBZ always_RB equal_JJ ,_, as_IN the_DT same_JJ sentences_NNS are_VBP tagged_VBN ._. Tool_NNP Language_NNP Trained_NNP on_IN Modelname_NNP Tagset_NNP Domain_NNP Abbr_NNP ._. Ark_NNP en_FW Owoputi_NNP default_NN Gimpel_NNP social_JJ A-1_NN Irc_NNP irc_IN PTB-NPS_NNP social_JJ A-2_NN Ritter_NNP ritter_NN PTB-RIT_NNP social_JJ A-3_NN ClearNLP_NNP en_IN Medical_NNP text_NN mayo_NN PTB_RB clinical_JJ C-1OntoNotes_NNS ontonotes_VBZ PTB_NNP news_NN C-2_NN Hepple_NNP en_IN rule-based_JJ PTB_NNP -_: Hepple_NNP HunPos_NNP en_IN WSJ_NNP wsj_, PTB_NNP news_NN Hunde_NNP Tiger_NNP tiger_NN STTS_NNS news_NN Mate_NN en_IN CoNLL2009_DT conll2009_CD PTB_NNP mixed_JJ Matede_NNP Tiger_NNP tiger_NN STTS_NNS news_NN Lbj_NN en_IN WSJ_NNP -_: PTB_NN news_NN Lbj_NNP OpenNLP_NNP en_IN unknown_JJ maxent_JJ PTB_NNS unknown_JJ O-1unknown_JJ perceptron_NN PTB_NNS unknown_JJ O-2_NNP de_NNP Tiger_NNP maxent_NN STTS_NNS news_NN O-3Tiger_NNP perceptron_NN STTS_NNS news_NN O-4_CD Stanford_NNP en_FW WSJ_NNP bidirectional-distsim_, PTB_NNP news_NN St-1_NN WSJ_NNP caseless-left3w.-distsim_POS PTB_NNP news_NN St-2_NNP unknown_JJ fast_JJ PTB_NNS unknown_JJ St-3_JJ Twitter/WSJ_NNP twitter-fast_NN PTB-RIT_NNP mixed_JJ St-4_NNP Twitter/WSJ_NNP twitter_VBD PTB-RIT_NNP mixed_JJ St-5_. WSJ_NNP wsj-0-18-caseless-left3w.-distsim_POS PTB_NNP news_NN St-6_NNP de_NNP Negra_NNP dewac_NN STTS_NNS news_NN St-7_. unknown_JJ fast-caseless_JJ STTS_NNS news_NN St-8_CC Negra_NNP fast_RB STTS_VBZ news_NN St-9_: Negra_NNP hgc_POS STTS_NNS news_NN St-10_NNP TreeTagger_NNP en_IN unknown_JJ le_JJ PTB-TT_JJ news_NN Treede_NNP unknown_JJ le_NN STTS_NNS news_NN Table_NN 1_CD :_: Tagger_NN models_NNS used_VBN in_IN our_PRP$ experiments_NNS ._. Mate_NN (_-LRB- Björkelund_NNP et_NNP al_NN ._. ,_, 2010_CD )_-RRB- provides_VBZ an_DT En-_NNP glish_JJ model_NN trained_VBN on_IN CoNLL2009_DT (_-LRB- Hajicˇ_NNP et_NNP al_NN ._. ,_, 2009_CD )_-RRB- and_CC a_DT German_JJ model_NN trained_VBN on_IN the_DT Tiger_NNP newswire_NN corpus_FW ._. OpenNLP_NNP is_VBZ an_DT Apache_NNP project_NN that_WDT provides_VBZ a_DT wide_JJ range_NN of_IN NLP_NNP tools_NNS including_VBG a_DT tagger.2_NN It_PRP provides_VBZ models_NNS for_IN English_NNP and_CC German_NNP based_VBN on_IN two_CD different_JJ classifiers_NNS (_-LRB- Maximum_NNP Entropy_NNP and_CC Perceptron_NNP )_-RRB- ._. The_DT German_NNP models_NNS are_VBP trained_VBN on_IN the_DT Tiger_NNP corpus_FW ._. We_PRP could_MD not_RB find_VB any_DT information_NN about_IN the_DT training_NN data_NNS of_IN the_DT English_NNP models_NNS ._. Stanford_NNP (_-LRB- Toutanova_NNP et_NNP al_NN ._. ,_, 2003_CD )_-RRB- provides_VBZ sev-_DT eral_JJ English_NNP and_CC German_NNP models_NNS for_IN their_PRP$ tagger_NN ._. The_DT models_NNS differ_VBP with_IN respect_NN to_TO lowercasing_JJ of_IN all_DT tokens_NNS ,_, adding_VBG distributional_JJ knowledge_NN ,_, or_CC using_VBG a_DT bidirectional_JJ model_NN ._. Two_CD social_JJ media_NNS models_NNS are_VBP trained_VBN by_IN Derczynski_NNP et_NNP al_NN ._. (_-LRB- 2013_CD ).3_CD The_DT origin_NN of_IN some_DT models_NNS is_VBZ unknown_JJ ._. TreeTagger_NNP (_-LRB- Schmid_NNP ,_, 1994_CD ;_: Schmid_NNP ,_, 1995_CD )_-RRB- provides_VBZ an_DT English_JJ model_NN trained_VBN on_IN the_DT Penn-_NNP Treebank_NNP and_CC further_RBR proprietary_JJ resources_NNS as_RB well_RB 2https_IN ://opennlp.apache_NNP .org_NNP 3https_VBZ ://gate_JJ .ac.uk/wiki/twitter-postagger_NN .html_NN as_IN a_DT German_JJ model_NN for_IN which_WDT little_JJ information_NN is_VBZ available_JJ ._. 2.3_CD Tagsets_NNPS A_DT tagset_NN is_VBZ a_DT collection_NN of_IN labels_NNS which_WDT represent_VBP word_NN classes_NNS ._. A_DT coarse-grained_JJ tagset_NN might_MD only_RB distinguish_VB main_JJ word_NN classes_NNS such_JJ as_IN adjectives_NNS or_CC verbs_NNS ,_, while_IN more_RBR fine-grained_JJ tagsets_NNS also_RB make_VBP distinctions_NNS within_IN the_DT broad_JJ word_NN classes_NNS ,_, e.g_NN ._. dis_SYM -_: tinguishing_NN between_IN verbs_NNS in_IN present_JJ and_CC past_JJ tense_NN ._. Many_JJ English_JJ models_NNS are_VBP trained_VBN on_IN corpora_JJ an-_CC notated_JJ with_IN the_DT PTB_NNP tagset_NN ,_, which_WDT distinguishes_VBZ 48_CD tags_NNS (_-LRB- Marcus_NNP et_NNP al_NN ._. ,_, 1993_CD )_-RRB- ._. Some_DT models_NNS add_VBP additional_JJ tags_NNS to_TO the_DT PTB_NNP in_IN order_NN to_TO distinguish_VB further_RB language_NN phenomena_NNS ._. Schmid_NNP (_-LRB- 1994_CD )_-RRB- as-_DT signs_NNS the_DT inflection_NN forms_NNS of_IN the_DT words_NNS be_VB ,_, do_VB ,_, have_VB an_DT own_JJ tag_NN instead_RB of_IN the_DT default_NN verb_NN tags_NNS ._. Like-_DT wise_JJ ,_, the_DT word_NN that_WDT is_VBZ tagged_VBN with_IN an_DT own_JJ tag_NN if_IN it_PRP occurs_VBZ as_IN preposition_NN ._. Ritter_NNP et_NNP al_NN ._. (_-LRB- 2011_CD )_-RRB- added_VBD four_CD additional_JJ tags_NNS to_TO label_VB the_DT phenomenons_NNS that_WDT frequently_RB occur_VBP in_IN Twitter_NNP messages_NNS like_IN hashtags_NNS or_CC URLs_NNP ._. Forsyth_NNP and_CC Martell_NNP (_-LRB- 2007_CD )_-RRB- prefix_VBP PTB_NNP tags_NNS with_IN an_DT extra_JJ character_NN in_IN case_NN the_DT word-form_NN Tokens_NNP Domain_NNP Corpus_NNP in_IN (_-LRB- 103_CD )_-RRB- Tagset_NNP en_FW written_VBN BNC-News_NNP 100_CD C5_. Brown_NNP 1,100_CD Brown_NNP MASC-Essay_NNP 37_CD PTB_NNS MASC-Fiction_NNP 38_CD PTB_NNP MASC-Govern_NNP ._. 28_CD PTB_NNP MASC-Journal_NNP 24_CD PTB_NNP MASC-Non-Fict_NNP ._. 30_CD PTB_NN MASC-TechDoc_NNP 23_CD PTB_NNP MASC-Travel_NNP 28_CD PTB_NNP spoken_VBN MASC-Convers_NNS ._. 100_CD PTB_NNP MASC-Court_NNP 35_CD PTB_NNP MASC-Debate_NNP 36_CD PTB_NNP MASC-F2Face_NNP 28_CD PTB_NNP MASC-Teleph_NNP ._. 5_CD PTB_NNP Switchboard_NNP 2,100_CD PTB_NNP social_JJ Gimpel_NNP 27_CD Gimpel_NNP MASC-Blog_NNP 33_CD PTB_NNP MASC-Email_NN 63_CD PTB_NN MASC-Twitter_NNP 29_CD PTB_NNP de_FW written_VBN Tüba-DZ_NN 1,500_CD STTSsocial_NNP Twitter-Reh_NNP 20_CD STTS_NNP Table_NN 2_CD :_: Corpora_NNP used_VBD in_IN our_PRP$ experiments_NNS ._. is_VBZ misspelled_VBN ._. Other_JJ tagsets_NNS used_VBN in_IN the_DT evaluation_NN corpora_NN are_VBP Brown_JJ (_-LRB- Nelson_NNP Francis_NNP and_CC Kuçera_NNP ,_, 1964_CD )_-RRB- and_CC C5_DT (_-LRB- BNC_NNP )_-RRB- as_RB well_RB as_IN the_DT coarse-grained_JJ Gimpel_NNP tagset_NN with_IN 25_CD tags_NNS specialized_VBN on_IN social_JJ media_NNS ._. In_IN Ger-_DT man_NN ,_, the_DT Stuttgart-Tübingen-TagSet_JJ (STTS_NNS )_-RRB- with_IN 54_CD tags_NNS is_VBZ exclusively_RB used_VBN ._. If_IN a_DT model_NN trained_VBN on_IN a_DT corpus_FW with_IN a_DT certain_JJ tagset_NN is_VBZ evaluated_VBN on_IN a_DT corpus_JJ using_VBG a_DT second_JJ tagset_NN ,_, this_DT mismatch_NN will_MD result_VB in_IN artificially_RB low_JJ accuracy_NN ._. Thus_RB ,_, we_PRP map_VBP the_DT fine-grained_JJ tags_NNS to_TO the_DT coarse_JJ grained_JJ universal_JJ tagset_NN (_-LRB- Petrov_NNP et_NNP al_NN ._. ,_, 2012_CD )_-RRB- as_IN implemented_VBN by_IN DKPro_NNP Core_NNP ._. Obviously_RB ,_, sub_NN -_: tle_JJ distinctions_NNS between_IN similar_JJ tags_NNS will_MD be_VB lost_VBN in_IN the_DT process_NN ,_, but_CC for_IN many_JJ downstream_NN applications_NNS fine-grained_JJ distinctions_NNS between_IN sub-tags_NNS of_IN the_DT same_JJ word_NN class_NN are_VBP not_RB important_JJ anyway_RB ._. Thus_RB ,_, the_DT coarse-grained_JJ accuracy_NN gives_VBZ a_DT good_JJ approxi-_NNS mation_NN of_IN the_DT expected_VBN tagging_NN quality_NN ._. 2.4_CD Corpora_NNP Table_NN 2_CD gives_VBZ an_DT overview_NN of_IN the_DT corpora_JJ used_VBN in_IN our_PRP$ evaluation_NN ._. We_PRP partition_VBP the_DT English_NNP corpora_NN into_IN three_CD broad_JJ domains_NNS :_: (_-LRB- i_FW )_-RRB- formal_JJ writing_NN ,_, (_-LRB- ii_NNS )_-RRB- speech_NN transcripts_NNS ,_, and_CC (_-LRB- iii_NN )_-RRB- social_JJ media_NNS ._. We_PRP choose_VBP this_DT partitioning_NN to_TO challenge_VB the_DT taggers_NNS with_IN inherent_JJ different_JJ contents_NNS ._. For_IN German_JJ ,_, we_PRP could_MD only_RB find_VB corpora_NN for_IN the_DT written_VBN and_CC social_JJ media_NNS domains_NNS ._. English_NNP The_DT first_JJ set_NN of_IN corpora_NN contains_VBZ formal_JJ writing_NN ,_, e.g_NN ._. news_NN articles_NNS ,_, fiction_NN ,_, or_CC technical_JJ doc_NN -_: umentation_NN ._. We_PRP use_VBP subset_NN of_IN the_DT newswire_NN text_NN from_IN the_DT British_NNP National_NNP Corpus4_NNP ,_, the_DT Brown_NNP cor-_, pus_FW (_-LRB- Nelson_NNP Francis_NNP and_CC Kuçera_NNP ,_, 1964_CD )_-RRB- which_WDT con-_WP tains_VBZ American_NNP English_NNP of_IN the_DT 1960’s_NNS ,_, and_CC eight_CD subsections_NNS of_IN the_DT MASC_NNP (_-LRB- Ide_NNP et_NNP al_NN ._. ,_, 2010_CD )_-RRB- corpus_FW with_IN text_NN from_IN several_JJ written_VBN subdomains_NNS ._. The_DT sec-_NNS ond_JJ set_NN contains_VBZ transcripts_NNS of_IN spoken_VBN language_NN ._. We_PRP use_VBP the_DT Switchboard_NNP (_-LRB- Marcus_NNP et_NNP al_NN ._. ,_, 1993_CD )_-RRB- corpus_FW (telephone_NN conversations_NNS )_-RRB- and_CC five_CD speech-related_JJ subsections_NNS of_IN MASC._NNP The_DT third_JJ set_NN contains_VBZ so_IN -_: cial_JJ media_NNS messages_NNS that_IN combine_NN properties_NNS of_IN written_VBN and_CC spoken_VBN language_NN ._. Social_NNP media_NNS is_VBZ char-_DT acterized_VBN by_IN its_PRP$ high_JJ vocabulary_NN heterogeneity_NN and_CC many_JJ domain-specific_JJ tokens_NNS as_IN emoticons_NNS ,_, URLs_NNP ,_, or_CC email_NN addresses_NNS which_WDT are_VBP likely_JJ to_TO be_VB out-of_JJ -_: vocabulary_NN for_IN most_JJS tagger_NN models_NNS ._. We_PRP use_VBP four_CD subsections_NNS of_IN MASC_NNP as_RB well_RB as_IN annotated_VBN Twitter_RB messages_NNS by_IN Gimpel_NNP et_NNP al_NN ._. (_-LRB- 2011_CD )_-RRB- ._. In_IN order_NN to_TO avoid_VB testing_NN on_IN the_DT training_NN data_NNS ,_, we_PRP exclude_VBP other_JJ available_JJ PoS-annotated_JJ corpora_NN like_IN the_DT WSJ_NNP corpus_FW (_-LRB- Marcus_NNP et_NNP al_NN ._. ,_, 1993_CD )_-RRB- ,_, the_DT Twitter_NNP corpus_NN by_IN Ritter_NNP et_NNP al_NN ._. (_-LRB- 2011_CD )_-RRB- ,_, or_CC the_DT IRC_NNP chat_NN cor-_, pus_FW (_-LRB- Forsyth_NNP and_CC Martell_NNP ,_, 2007_CD )_-RRB- ,_, as_IN many_JJ of_IN the_DT models_NNS have_VBP been_VBN trained_VBN using_VBG those_DT corpora_JJ ._. As_IN the_DT provenance_NN of_IN some_DT models_NNS is_VBZ unknown_JJ ,_, their_PRP$ results_NNS should_MD be_VB treated_VBN with_IN caution_NN as_IN we_PRP might_MD still_RB be_VB testing_VBG on_IN the_DT training_NN data_NNS here_RB ._. German_JJ We_PRP use_VBP the_DT STTS-annotated_JJ Tüba-DZ_NN corpus_FW (_-LRB- Telljohann_NNP et_NNP al_NN ._. ,_, 2004_CD )_-RRB- based_VBN on_IN the_DT Ger-_NNP man_NN newspaper_NN die_VBP tageszeitung_VBN and_CC the_DT Twitter-_NNP Reh_NNP corpus_FW (_-LRB- Rehbein_NNP ,_, 2013_CD )_-RRB- of_IN German_NNP Tweets_NNP an-_CC notated_VBD with_IN an_DT Twitter-specific_JJ extension_NN of_IN STTS_NNS following_VBG Ritter_NNP et_NNP al_NN ._. (_-LRB- 2011_CD )_-RRB- ._. We_PRP exclude_VBP the_DT Tiger_NNP corpus_FW (_-LRB- Brants_NNPS et_FW al_JJ ._. ,_, 2004_CD )_-RRB- and_CC the_DT Negra_NNP corpus_FW (Skut_NNP et_FW al_NN ._. ,_, 1998_CD )_-RRB- as_IN all_DT German_JJ models_NNS are_VBP trained_VBN on_IN one_CD of_IN the_DT two_CD ._. 3_CD Results_NNS and_CC Analysis_NNP After_IN evaluating_VBG all_DT tagger_NN models_NNS on_IN all_DT corpora_NN we_PRP obtain_VBP the_DT results_NNS shown_VBN for_IN English_NNP in_IN Figure_NNP 1a_CD and_CC for_IN German_JJ in_IN Figure_NN 1b_VBD ._. The_DT x-axis_NNP shows_VBZ the_DT macro-averaged_JJ tagging_NN accuracy_NN based_VBN on_IN the_DT coarse-grained_JJ universal_JJ tagset_NN ._. As_IN discussed_VBN above_RB ,_, we_PRP cannot_MD use_VB fine-grained_JJ tags_NNS for_IN evalua_NN -_: tion_NN ,_, because_IN of_IN frequent_JJ mismatches_NNS between_IN the_DT tagset_NN used_VBN by_IN the_DT tagger_NN and_CC the_DT tagset_NN used_VBN in_IN the_DT evaluation_NN corpus_NN ._. The_DT y-axis_NNP shows_VBZ the_DT normal_JJ -_: ized_JJ processing_NN time_NN in_IN seconds_NNS per_IN million_CD tokens_NNS ._. 4http_CD ://www.natcorp.ox_NNP .ac.uk/_NNP 0.84_CD 0.86_CD 0.88_CD 0.9_CD 0.92_CD 0.94_CD 101_CD 102_CD 103_CD Ark-1_NNP Ark-2_NNP Ark-3_NNP C-1_NN C-2_NN Hepple_NNP Hun_NNP Lbj_NNP Mate_NNP O-1_NNP O-2_NNP St-1_NNP St-2_NNP St-3_NNP St-4_NNP St-5_NNP St-6Tree_NNP Accuracy_NNP tim_NN e_NN [_IN se_NN co_NN nd_NN s_VBZ 10_CD 6_CD to_TO ke_VB n_NN ]_SYM (_-LRB- a_DT )_-RRB- English_NNP 0.84_CD 0.86_CD 0.88_CD 0.9_CD 0.92_CD 0.94_CD 101_CD 102_CD 103_CD Hun_NNP Mate_NNP O-3_. O-4_. St-7_. St-8St-9_. St-10_NNP Tree_NNP Accuracy_NNP tim_NN e_NN [_IN se_NN co_NN nd_CC s_VBZ 10_CD 6_CD to_TO ke_VB n_NN ]_SYM (_-LRB- b_NN )_-RRB- German_NNP Figure_NN 1_CD :_: Macro-averaged_JJ results_NNS over_IN all_DT corpora_JJ ._. Of_IN course_NN the_DT hardware5_JJR will_MD influence_VB the_DT absolute_JJ time_NN spent_VBN on_IN the_DT task_NN ,_, but_CC the_DT relative_JJ differences_NNS between_IN the_DT models_NNS are_VBP of_IN greater_JJR importance_NN here_RB ._. In_IN general_JJ ,_, we_PRP observe_VBP the_DT expected_VBN trade-off_NN between_IN (_-LRB- i_NN )_-RRB- high-accuracy_NN taggers_NNS that_WDT invest_VBP a_DT lot_NN of_IN processing_NN into_IN feature_NN extraction_NN or_CC more_RBR so_RB -_: phisticated_VBN classifiers_NNS and_CC are_VBP thus_RB slower_JJR ,_, and_CC (_-LRB- ii_NNS )_-RRB- high-speed_JJ taggers_NNS that_WDT can_MD process_VB much_RB more_JJR to_TO -_: kens_NNS in_IN the_DT same_JJ time_NN at_IN the_DT cost_NN of_IN accuracy_NN ._. For_IN example_NN ,_, on_IN the_DT English_NNP corpora_NN Lbj_NNP is_VBZ extremely_RB fast_JJ ,_, but_CC reaches_VBZ only_RB a_DT low_JJ accuracy_NN while_IN St-6_NNP or_CC O-1_JJ yield_NN a_DT much_JJ better_JJR accuracy_NN (_-LRB- about_IN 6_CD points_NNS better_JJR )_-RRB- ,_, but_CC are_VBP an_DT order_NN of_IN magnitude_NN slower_JJR ._. A_DT surprising_JJ result_NN is_VBZ the_DT excellent_JJ performance_NN of_IN the_DT rule-based_JJ Hepple_NNP tagger_NN that_WDT is_VBZ much_RB faster_JJR and_CC more_RBR accurate_JJ than_IN any_DT other_JJ model_NN ._. This_DT outstand_NNPS -_: ing_NN performance_NN can_MD be_VB partly_RB explained_VBN by_IN our_PRP$ evaluation_NN setting_NN where_WRB we_PRP test_NN on_IN a_DT wide_JJ range_NN of_IN corpora_NN from_IN different_JJ domains_NNS ._. Rule-based_'' tag-_DT gers_NNS are_VBP supposed_VBN to_TO generalize_VB very_RB well_RB and_CC do_VB not_RB overfit_VB on_IN the_DT training_NN domain_NN ._. It_PRP would_MD be_VB interesting_JJ to_TO validate_VB this_DT finding_NN on_IN the_DT German_JJ data_NNS ,_, unfortunately_RB there_EX is_VBZ no_DT rule-based_JJ German_JJ tagger_NN in_IN our_PRP$ experiment_NN ._. On_IN the_DT models_NNS that_WDT are_VBP available_JJ for_IN German_JJ ,_, we_PRP see_VBP the_DT same_JJ trade-off_NN like_IN for_IN English_NNP ,_, with_IN the_DT HunPos_NNP and_CC the_DT OpenNLP_NNP models_NNS being_VBG quite_RB fast_RB ,_, but_CC not_RB as_RB accurate_JJ as_IN TreeTagger_NNP or_CC Mate_NNP ._. Interest-_NNP ingly_RB ,_, none_NN of_IN the_DT Stanford_NNP models_NNS is_VBZ competitive_JJ for_IN German_NNP ._. Summarizing_VBG the_DT overall_JJ results_NNS :_: Hepple_NNP is_VBZ an_DT excellent_JJ choice_NN for_IN English_NNP ,_, while_IN all_DT other_JJ models_NNS for_IN both_DT languages_NNS suffer_VBP from_IN a_DT trade-off_NN between_IN 5In_IN our_PRP$ case_NN :_: Intel_NNP Core_NNP i5_JJS 2.9_CD GHz_NNP CPU_NNP ,_, 16GB_NNP RAM_NNP ,_, single_JJ core_NN execution_NN ._. accuracy_NN and_CC speed_NN ._. As_IN a_DT consequence_NN ,_, researchers_NNS need_VBP to_TO choose_VB according_VBG to_TO their_PRP$ needs_NNS ._. A_DT digital_JJ humanities_NNS scholar_NN with_IN a_DT couple_NN of_IN hundred_CD docu-_NNS ments_VBZ to_TO tag_NN ,_, may_MD safely_RB select_VB the_DT most_RBS accurate_JJ tagger_NN ,_, while_IN a_DT social_JJ media_NNS analyst_NN looking_VBG for_IN trends_NNS in_IN the_DT full_JJ Twitter_NNP stream_NN might_MD be_VB better_JJR off_RP with_IN one_CD of_IN the_DT faster_RBR alternatives_NNS ._. So_RB far_RB ,_, we_PRP have_VBP only_RB considered_VBN the_DT macro-_NNS averaged_VBD performance_NN over_IN all_DT corpora_JJ ._. This_DT sim_FW -_: ulates_VBZ the_DT usage_NN scenario_NN in_IN which_WDT the_DT tagger_NN is_VBZ treated_VBN as_IN a_DT black-box_NN and_CC applied_VBD to_TO all_DT sorts_NNS of_IN data_NNS without_IN caring_VBG much_RB about_IN the_DT domain_NN ._. In_IN the_DT next_JJ section_NN ,_, we_PRP investigate_VB how_WRB well_RB the_DT models_NNS perform_VBP in_IN different_JJ domains_NNS ._. 3.1_CD Domain-specific_NNP results_NNS Figure_NN 2_CD gives_VBZ a_DT graphical_JJ overview_NN of_IN the_DT evalua_NN -_: tion_NN results_NNS per_IN domain_NN for_IN English_NNP ,_, while_IN Table_NN 3_CD shows_VBZ the_DT exact_JJ values_NNS ._. As_IN expected_VBN ,_, some_DT mod_JJ -_: els_NNS that_WDT are_VBP especially_RB trained_VBN for_IN a_DT certain_JJ domain_NN perform_VBP well_RB in_IN that_DT domain_NN ,_, but_CC not_RB in_IN another_DT ._. One_CD such_JJ example_NN is_VBZ the_DT Ark-3_JJ model_NN ,_, a_DT model_NN specialized_JJ for_IN social_JJ media_NNS that_WDT is_VBZ among_IN the_DT best_JJS and_CC fastest_JJS models_NNS on_IN that_DT domain_NN ,_, while_IN it_PRP does_VBZ not_RB perform_VB well_RB on_IN the_DT other_JJ domains_NNS ._. However_RB ,_, there_EX are_VBP also_RB counter-examples_NNS like_IN the_DT St-6_NN model_NN (_-LRB- trained_VBN on_IN the_DT WSJ)_NNP that_IN not_RB only_RB performs_VBZ well_RB on_IN formal_JJ writing_NN ,_, but_CC also_RB on_IN the_DT speech_NN transcripts_NNS and_CC social_JJ media_NNS ._. And_CC of_IN course_NN there_RB is_VBZ the_DT Hepple_NNP tagger_NN that_WDT performs_VBZ extremely_RB well_RB in_IN every_DT En-_NNP glish_VB domain_NN ._. In_IN general_JJ ,_, the_DT differences_NNS between_IN the_DT domains_NNS are_VBP smaller_JJR than_IN expected_VBN ._. The_DT abso_NNPS -_: lute_JJ accuracy_NN values_NNS are_VBP best_RB for_IN written_VBN ,_, followed_VBN by_IN spoken_VBN ,_, and_CC worst_JJS for_IN social_JJ media_NNS which_WDT fits_VBZ the_DT expectations_NNS ._. (_-LRB- a_DT )_-RRB- Formal_JJ /_NNS written_VBN 0.85_CD 0.87_CD 0.89_CD 0.91_CD 0.93_CD 0.95_CD 101_CD 102_CD 103_CD Ark-1_NN Ark-2_. Ark-3_. C-1_NN C-2_NN Hepple_NNP Hun_NNP Lbj_NNP Mate_NNP O-1O-2_NNP St-1_NNP St-2_NNP St-3_NNP St-4_NNP St-5_. St-6_. Tree_NNP Accuracy_NNP tim_NN e_NN [_IN se_NN co_NN nd_CC s_VBZ 10_CD 6_CD to_TO ke_VB n_NN ]_SYM (_-LRB- b_NN )_-RRB- Spoken_VBN 0.85_CD 0.87_CD 0.89_CD 0.91_CD 0.93_CD 0.95_CD 101_CD 102_CD 103_CD Ark-1_NN Ark-2_. Ark-3_. C-1_NN C-2_NN Hepple_NNP Hun_NNP Lbj_NNP Mate_NNP O-1_NNP O-2_NNP St-1_NNP St-2_NNP St-3_NNP St-4_NNP St-5_. St-6_. Tree_NNP Accuracy_NNP tim_NN e_NN [_IN se_NN co_NN nd_CC s_VBZ 10_CD 6_CD to_TO ke_VB n_NN ]_SYM (_-LRB- c_NN )_-RRB- Social_NNP 0.85_CD 0.87_CD 0.89_CD 0.91_CD 0.93_CD 0.95_CD 101_CD 102_CD 103_CD Ark-2_NNP Ark-3_NNP C-1_NN C-2_NN Hepple_NNP Hun_NNP Mate_NNP O-1O-2_NNP St-1_NNP St-2_NNP St-3_NNP St-4_NNP St-5_NNP St-6_NNP Tree_NNP Accuracy_NNP tim_NN e_NN [_IN se_NN co_NN nd_NN s_VBZ 10_CD 6_CD to_TO ke_VB n_RB ]_SYM Figure_NN 2_CD :_: English_JJ results_NNS per_IN domain_NN ._. In_IN plot_NN (_-LRB- c_NN )_-RRB- ,_, Lbj_NNP not_RB shown_VBN to_TO improve_VB readability_NN and_CC Ark-1_NNP omitted_VBD to_TO avoid_VB testing_VBG on_IN training_NN data_NNS ._. Written_NNP Speech_NNP transcripts_NNS Social_NNP media_NNS Macro-Average_JJ accuracy_NN time_NN accuracy_NN time_NN accuracy_NN time_NN accuracy_NN time_NN ∅_, %_NN ∅_NN (_-LRB- seconds106_JJ token_NN )_-RRB- ∅_, %_NN ∅_NN (_-LRB- seconds_NNS 106_CD token_JJ )_-RRB- ∅_NNS %_NN ∅_NN (_-LRB- seconds_NNS 106_CD token_JJ )_-RRB- ∅_NN ∅_NNS (_-LRB- seconds_NNS 106_CD token_JJ )_-RRB- Ark-1_NNP 87.2_CD 45_CD 85.0_CD 53_CD 86.1_CD 49_CD Ark-2_NNP 90.0_CD 54_CD 89.1_CD 63_CD 88.4_CD 46_CD 89.2_CD 54_CD Ark-3_DT 90.5_CD 48_CD 90.3_CD 325_CD 88.9_CD 42_CD 89.9_CD 138_CD C-1_NN 91.4_CD 53_CD 90.4_CD 85_CD 88.2_CD 45_CD 90.0_CD 61_CD C-2_NN 91.4_CD 52_CD 90.4_CD 84_CD 88.2_CD 43_CD 90.0_CD 60_CD Hepple_NNP 95.4_CD 2_CD 94.0_CD 3_CD 91.8_CD 3_CD 93.7_CD 3_CD Hun_NNP 90.8_CD 18_CD 90.8_CD 24_CD 87.4_CD 18_CD 89.7_CD 20_CD Lbj_NNP 85.6_CD 3_CD 87.4_CD 3_CD 79.7_CD 4_CD 84.3_CD 3_CD Mate_NNP 90.8_CD 163_CD 90.4_CD 239_CD 86.9_CD 137_CD 89.4_CD 180_CD O-1_JJ 92.1_CD 37_CD 91.2_CD 48_CD 88.7_CD 35_CD 90.6_CD 40_CD O-2_JJ 89.8_CD 25_CD 91.0_CD 33_CD 85.6_CD 23_CD 88.8_CD 27_CD St-1_NN 91.8_CD 655_CD 91.1_CD 272_CD 87.7_CD 2504_CD 90.2_CD 1144_CD St-2_JJ 91.8_CD 34_CD 91.0_CD 63_CD 88.6_CD 37_CD 90.5_CD 45_CD St-3_JJ 90.7_CD 94_CD 90.8_CD 43_CD 88.2_CD 132_CD 89.9_CD 90_CD St-4_NN 90.7_CD 395_CD 91.0_CD 166_CD 89.1_CD 422_CD 90.3_CD 327_CD St-5_. 90.7_CD 135_CD 91.0_CD 70_CD 88.7_CD 145_CD 90.1_CD 117_CD St-6_. 92.4_CD 36_CD 91.1_CD 34_CD 89.0_CD 40_CD 90.8_CD 37_CD Tree_NNP 91.2_CD 26_CD 90.4_CD 43_CD 87.9_CD 23_CD 89.8_CD 31_CD Table_NN 3_CD :_: English_NNP tagging_VBG accuracy_NN and_CC execution_NN time_NN ._. Highest_NNP accuracies_NNS per_IN domain_NN in_IN bold_JJ face_NN ._. 0.85_CD 0.9_CD 0.95_CD 1_CD 100_CD 101_CD 102_CD 103_CD 104_CD Hun_NNP Mate_NNP O-3_. O-4_. St-7_. St-8_. St-9_. St-10_NNP Tree_NNP Accuracy_NNP tim_NN e_NN [_IN se_NN co_NN nd_CC s_VBZ 10_CD 6_CD to_TO ke_VB n_NN ]_SYM (_-LRB- a_DT )_-RRB- Written_NNP 0.85_CD 0.9_CD 0.95_CD 1_CD 100_CD 101_CD 102_CD 103_CD 104_CD Hun_NNP Mate_NNP O-3O-4_NNP St-7_NNP St-8_. St-9_. St-10_NNP Tree_NNP Accuracy_NNP tim_NN e_NN [_IN se_NN co_NN nd_CC s_VBZ 10_CD 6_CD to_TO ke_VB n_NN ]_SYM (_-LRB- b_NN )_-RRB- Social_NNP Figure_NNP 3_CD :_: German_JJ results_NNS per_IN domain_NN Written_VBN Social_NNP media_NNS Macro_NNP Average_JJ accuracy_NN time_NN accuracy_NN time_NN accuracy_NN time_NN ∅_IN %_NN ∅_NN (_-LRB- seconds106_JJ token_NN )_-RRB- ∅_VBZ %_NN ∅_NN (_-LRB- seconds_NNS 106_CD token_JJ )_-RRB- ∅_NNS %_NN ∅_NN (_-LRB- seconds_NNS 106_CD token_JJ )_-RRB- Hun_NNP 96.2_CD 11_CD 90.1_CD 17_CD 93.2_CD 14_CD Mate_NNP 96.4_CD 101_CD 90.8_CD 146_CD 93.6_CD 124_CD O-3_JJ 95.4_CD 31_CD 89.4_CD 51_CD 92.4_CD 41_CD O-4_NN 95.5_CD 25_CD 89.1_CD 43_CD 92.3_CD 34_CD St-7_JJ 93.1_CD 445_CD 87.2_CD 1325_CD 90.1_CD 885_CD St-8_. 93.0_CD 43_CD 87.0_CD 82_CD 90.0_CD 62_CD St-9_. 92.2_CD 43_CD 87.4_CD 81_CD 89.8_CD 62_CD St-10_JJ 93.1_CD 438_CD 87.3_CD 1285_CD 90.2_CD 861_CD Tree_NNP 97.2_CD 7_CD 91.7_CD 151_CD 94.5_CD 79_CD Table_NN 4_CD :_: German_JJ tagging_NN accuracy_NN and_CC execution_NN time_NN ._. Highest_NNP accuracies_NNS per_IN domain_NN in_IN bold_JJ face_NN ._. When_WRB looking_VBG at_IN the_DT German_JJ domain-specific_JJ results_NNS (_-LRB- Figure_NN 3_CD and_CC Table_NNP 4)_CD ,_, we_PRP see_VBP a_DT similar_JJ distribution_NN as_IN for_IN English_NNP with_IN little_JJ differences_NNS between_IN domains_NNS ._. An_DT interesting_JJ exception_NN is_VBZ the_DT TreeTagger_NN that_WDT is_VBZ quite_RB fast_RB on_IN written_VBN data_NNS (_-LRB- reflect-_CC ing_VBG its_PRP$ popularity_NN for_IN tagging_JJ German_JJ )_-RRB- ,_, but_CC rather_RB slow_JJ on_IN social_JJ media_NNS ._. As_IN TreeTagger_NNP is_VBZ not_RB open-_VBN source_NN ,_, we_PRP could_MD not_RB further_RB investigate_VB the_DT reasons_NNS for_IN this_DT difference_NN ._. 4_CD Conclusions_NNS and_CC future_NN work_NN In_IN this_DT work_NN ,_, we_PRP evaluated_VBD a_DT large_JJ set_NN of_IN PoS_NNP tag-_, ging_NN models_NNS on_IN a_DT wide_JJ range_NN of_IN English_NNP and_CC Ger-_NNP man_NN data_NNS from_IN different_JJ domains_NNS ._. A_DT surprising_JJ result_NN is_VBZ the_DT outstanding_JJ performance_NN of_IN the_DT rule_NN -_: based_VBN Hepple_NNP tagger_NN on_IN English_NNP text_NN ._. For_IN German_JJ ,_, where_WRB no_DT rule-based_JJ tagger_NN is_VBZ readily_RB available_JJ ,_, we_PRP find_VBP that_DT researchers_NNS either_CC can_MD choose_VB a_DT fast_RB or_CC an_DT accurate_JJ model_NN depending_VBG on_IN their_PRP$ needs_NNS ._. The_DT com-_NNS prehensive_JJ results_NNS in_IN this_DT paper_NN offer_NN some_DT guidance_NN in_IN this_DT respect_NN ._. We_PRP make_VBP our_PRP$ full_JJ experimental_JJ framework_NN avail-_WDT able_JJ which_WDT will_MD enable_VB researchers_NNS to_TO easily_RB extend_VB our_PRP$ analysis_NN to_TO other_JJ languages_NNS and_CC taggers_NNS or_CC com-_NNS pare_VBP taggers_NNS under_IN different_JJ conditions_NNS .6_VBP 5_CD Acknowledgement_NNP We_PRP would_MD like_VB to_TO thank_VB Richard_NNP Eckart_NNP de_NNP Castilho_NNP for_IN his_PRP$ valuable_JJ input_NN and_CC for_IN his_PRP$ incredible_JJ work_NN on_IN the_DT DKPro_NNP Core_NNP framework_NN ._. References_NNS Chris_NNP Biemann_NNP ._. 2006_CD ._. Unsupervised_NNP part-of-speech_NN tagging_VBG employing_VBG efficient_JJ graph_NN clustering_VBG ._. In_IN Proceedings_NNP of_IN the_DT COLING/ACL_NNP 2006_CD Student_NN Re-_NNP search_NN Workshop_NNP ,_, pages_NNS 7–12_VBP ._. Association_NNP for_IN Com_NNP -_: putational_JJ Linguistics_NNP ._. Anders_NNP Björkelund_NNP ,_, Bernd_NNP Bohnet_NNP ,_, Love_NNP Hafdell_NNP ,_, and_CC Pierre_NNP Nugues_NNP ._. 2010_CD ._. A_DT high-performance_NN syntac_NN -_: tic_JJ and_CC semantic_JJ dependency_NN parser_NN ._. In_IN Proceedings_NNP of_IN the_DT 23rd_JJ International_NNP Conference_NNP on_IN Computa_NNP -_: tional_JJ Linguistics_NNP :_: Demonstrations_NNS ,_, COLING_VBG ’10_CD ,_, pages_NNS 33–36_CD ,_, Stroudsburg_NNP ,_, PA_NNP ,_, USA_NNP ._. Association_NNP for_IN Computational_NNP Linguistics_NNP ._. Sabine_NNP Brants_NNPS ,_, Stefanie_NNP Dipper_NNP ,_, Peter_NNP Eisenberg_NNP ,_, Sil-_NNP via_IN Hansen-Schirra_NNP ,_, Esther_NNP König_NNP ,_, Wolfgang_NNP Lezius_NNP ,_, Christian_NNP Rohrer_NNP ,_, George_NNP Smith_NNP ,_, and_CC Hans_NNP Uszkor-_NNP eit_, ._. 2004_CD ._. Tiger_NNP :_: Linguistic_NNP interpretation_NN of_IN a_DT Ger-_NNP man_NN corpus_FW ._. Research_NNP on_IN Language_NNP and_CC Computa_NNP -_: tion_NN ,_, 2(_JJ 4)_JJ :597–620_NN ._. 6https_'' ://github.com/zesch/pos-tagger-evaluation.git_JJ Thorsten_NNP Brants_NNPS ._. 2000_CD ._. Tnt_NNP :_: A_DT statistical_JJ part-of_JJ -_: speech_NN tagger_NN ._. In_IN Proceedings_NNP of_IN the_DT Sixth_NNP Con_NNP -_: ference_NN on_IN Applied_NNP Natural_NNP Language_NNP Processing_NNP ,_, ANLC_NNP ’00_CD ,_, pages_NNS 224–231_CD ,_, Stroudsburg_NNP ,_, PA_NNP ,_, USA_NNP ._. Association_NNP for_IN Computational_NNP Linguistics_NNP ._. Eric_NNP Brill_NNP ._. 1992_CD ._. A_DT simple_JJ rule-based_JJ part_NN of_IN speech_NN tagger_NN ._. In_IN Proceedings_NNP of_IN the_DT Third_NNP Conference_NNP on_IN Applied_NNP Natural_NNP Language_NNP Processing_NNP ,_, ANLC_NNP ’92_CD ,_, pages_NNS 152–155_CD ,_, Stroudsburg_NNP ,_, PA_NNP ,_, USA_NNP ._. Association_NNP for_IN Computational_NNP Linguistics_NNP ._. Jinho_NNP D._NNP Choi_NNP and_CC Martha_NNP Palmer_NNP ._. 2012_CD ._. Fast_NNP and_CC robust_JJ part-of-speech_NN tagging_VBG using_VBG dynamic_JJ model_NN selection_NN ._. In_IN Proceedings_NNP of_IN the_DT 50th_JJ Annual_NNP Meet-_NNP ing_NN of_IN the_DT Association_NNP for_IN Computational_NNP Linguis_NNP -_: tics_NNS :_: Short_JJ Papers_NNP –_NNP Volume_NN 2_CD ,_, ACL_NNP ’12_CD ,_, pages_NNS 363–_VBP 367_CD ,_, Stroudsburg_NNP ,_, PA_NNP ,_, USA_NNP ._. Association_NNP for_IN Compu-_NNP tational_JJ Linguistics_NNP ._. Dipanjan_NNP Das_NNP and_CC Slav_NNP Petrov._NNP 2011_CD ._. Unsupervised_NNP part-of-speech_NN tagging_VBG with_IN bilingual_JJ graph-based_JJ projections_NNS ._. In_IN Proceedings_NNP of_IN the_DT 49th_JJ Annual_JJ Meeting_NNP of_IN the_DT Association_NNP for_IN Computational_NNP Lin-_NNP guistics_NNS :_: Human_NNP Language_NNP Technologies_NNPS -_: Volume_NN 1_CD ,_, HLT_NNP ’11_CD ,_, pages_NNS 600–609_CD ,_, Stroudsburg_NNP ,_, PA_NNP ,_, USA_NNP ._. Association_NNP for_IN Computational_NNP Linguistics_NNP ._. Leon_NNP Derczynski_NNP ,_, Alan_NNP Ritter_NNP ,_, Sam_NNP Clark_NNP ,_, and_CC Kalina_NNP Bontcheva_NNP ._. 2013_CD ._. Twitter_NNP part-of-speech_NN tagging_NN for_IN all_DT :_: Overcoming_VBG sparse_JJ and_CC noisy_JJ data_NNS ._. In_IN Pro-_NNP ceedings_NNS of_IN the_DT International_NNP Conference_NNP on_IN Recent_JJ Advances_NNS in_IN Natural_NNP Language_NNP Processing_NNP ._. Associa_NNP -_: tion_NN for_IN Computational_NNP Linguistics_NNP ._. Richard_NNP Eckart_NNP de_NNP Castilho_NNP and_CC Iryna_NNP Gurevych_NNP ._. 2014_CD ._. A_DT broad-coverage_JJ collection_NN of_IN portable_JJ NLP_NNP com-_NNS ponents_NNS for_IN building_VBG shareable_JJ analysis_NN pipelines_NNS ._. In_IN Proceedings_NNP of_IN the_DT Workshop_NNP on_IN Open_NNP In-_NNP frastructures_NNS and_CC Analysis_NNP Frameworks_NNP for_IN HLT_NNP (_-LRB- OIAF4HLT)_NNP at_IN COLING_NNP 2014_CD ,_, pages_NNS 1–11_CD ,_, Dublin_NNP ,_, Ireland_NNP ,_, August_NNP ._. Association_NNP for_IN Computational_NNP Lin-_NNP guistics_NNS and_CC Dublin_NNP City_NNP University_NNP ._. David_NNP Ferrucci_NNP and_CC Adam_NNP Lally_NNP ._. 2004_CD ._. UIMA_NNP :_: An_DT architectural_JJ approach_NN to_TO unstructured_JJ information_NN processing_NN in_IN the_DT corporate_JJ research_NN environment_NN ._. Nat_NNP ._. Lang_NNP ._. Eng._NNP ,_, 10(3-4)_JJ :327–348_CD ,_, September_NNP ._. Eric_NNP N._NNP Forsyth_NNP and_CC Craig_NNP H._NNP Martell_NNP ._. 2007_CD ._. Lexical_NNP and_CC discourse_NN analysis_NN of_IN online_JJ chat_NN dialog_NN ._. In_IN Pro-_NNP ceedings_NNS of_IN the_DT International_NNP Conference_NNP on_IN Seman-_NNP tic_JJ Computing_NNP ,_, ICSC_NNP ’07_CD ,_, pages_NNS 19–26_CD ,_, Washington_NNP ,_, DC_NNP ,_, USA_NNP ._. IEEE_NNP Computer_NNP Society_NNP ._. Eugenie_NNP Giesbrecht_NNP and_CC Stefan_NNP Evert_NNP ._. 2009_CD ._. Is_VBZ part-of_JJ -_: speech_NN tagging_VBG a_DT solved_VBN task_NN ?_. an_DT evaluation_NN of_IN pos_NN taggers_NNS for_IN the_DT German_JJ web_NN as_IN corpus_JJ ._. Proceedings_NNS of_IN the_DT Fifth_NNP Web_NNP as_IN Corpus_NNP Workshop_NNP ,_, pages_NNS 27–35_CD ._. Kevin_NNP Gimpel_NNP ,_, Nathan_NNP Schneider_NNP ,_, Brendan_NNP O’Connor_NNP ,_, Dipanjan_NNP Das_NNP ,_, Daniel_NNP Mills_NNP ,_, Jacob_NNP Eisenstein_NNP ,_, Michael_NNP Heilman_NNP ,_, Dani_NNP Yogatama_NNP ,_, Jeffrey_NNP Flanigan_NNP ,_, and_CC Noah_NNP A_NNP Smith_NNP ._. 2011_CD ._. Part-of-speech_NNP Tagging_VBG for_IN Twitter_NNP :_: Annotation_NNP ,_, Features_NNP ,_, and_CC Experiments_NNS ._. In_IN Proceedings_NNP of_IN the_DT 49th_JJ Annual_JJ Meeting_NNP of_IN the_DT Association_NNP for_IN Computational_NNP Linguistics_NNP :_: Human_NNP Language_NNP Technologies_NNPS :_: Short_JJ Papers_NNP –_NNP Volume_NN 2_CD ,_, HLT_NNP ’11_CD ,_, pages_NNS 42–47_CD ,_, Stroudsburg_NNP ,_, PA_NNP ,_, USA_NNP ._. Sharon_NNP Goldwater_NNP and_CC Tom_NNP Griffiths_NNS ._. 2007_CD ._. A_DT fully_RB bayesian_JJ approach_NN to_TO unsupervised_JJ part-of-speech_NN tagging_NN ._. In_IN Proceedings_NNP of_IN the_DT 45th_JJ Annual_NNP Meet-_NNP ing_NN of_IN the_DT Association_NNP of_IN Computational_NNP Linguistics_NNP ,_, pages_NNS 744–751_CD ._. Jan_NNP Hajicˇ_NNP ,_, Massimiliano_NNP Ciaramita_NNP ,_, Richard_NNP Johans_NNP -_: son_NN ,_, Daisuke_NNP Kawahara_NNP ,_, Maria_NNP Antònia_NNP Martí_NNP ,_, Lluís_NNP Màrquez_NNP ,_, Adam_NNP Meyers_NNP ,_, Joakim_NNP Nivre_NNP ,_, Sebastian_NNP Padó_NNP ,_, Jan_NNP Šteˇpánek_NNP ,_, Pavel_NNP Stranˇák_NNP ,_, Mihai_NNP Surdeanu_NNP ,_, Nianwen_NNP Xue_NNP ,_, and_CC Yi_NNP Zhang_NNP ._. 2009_CD ._. The_DT CoNLL-_NNP 2009_CD shared_VBD task_NN :_: Syntactic_NNP and_CC semantic_JJ depen-_NNS dencies_NNS in_IN multiple_JJ languages_NNS ._. In_IN Proceedings_NNP of_IN the_DT Thirteenth_NNP Conference_NNP on_IN Computational_NNP Natu-_NNP ral_NN Language_NN Learning_VBG :_: Shared_NNP Task_NNP ,_, CoNLL_NNP ’09_CD ,_, pages_NNS 1–18_CD ,_, Stroudsburg_NNP ,_, PA_NNP ,_, USA_NNP ._. Péter_NNP Halácsy_NNP ,_, András_NNP Kornai_NNP ,_, and_CC Csaba_NNP Oravecz_NNP ._. 2007_CD ._. Hunpos_NNP :_: An_DT open_JJ source_NN trigram_NN tagger_NN ._. In_IN Proceedings_NNP of_IN the_DT 45th_JJ Annual_JJ Meeting_NNP of_IN the_DT ACL_NNP on_IN Interactive_NNP Poster_NNP and_CC Demonstration_NNP Sessions_NNP ,_, ACL_NNP ’07_CD ,_, pages_NNS 209–212_CD ,_, Stroudsburg_NNP ,_, PA_NNP ,_, USA_NNP ._. Mark_NNP Hepple_NNP ._. 2000_CD ._. Independence_NNP and_CC commitment_NN :_: Assumptions_NNP for_IN rapid_JJ training_NN and_CC execution_NN of_IN rule_NN -_: based_VBN POS_NNP taggers_NNS ._. In_IN Proceedings_NNP of_IN the_DT 38th_JJ An-_NNP nual_JJ Meeting_NNP of_IN the_DT Association_NNP for_IN Computational_NNP Linguistics_NNP (ACL-2000_NN )_-RRB- ,_, Hong_NNP Kong_NNP ._. Nancy_NNP Ide_NNP ,_, Christiane_NNP Fellbaum_NNP ,_, Collin_NNP Baker_NNP ,_, and_CC Re-_NNP becca_VBD Passonneau_NNP ._. 2010_CD ._. The_DT manually_NNPS annotated_VBD sub-corpus_JJ :_: A_DT community_NN resource_NN for_IN and_CC by_IN the_DT people_NNS ._. In_IN Proceedings_NNP of_IN the_DT ACL_NNP 2010_CD Conference_NNP Short_NNP Papers_NNP ,_, ACLShort_NNP ’10_CD ,_, pages_NNS 68–73_CD ,_, Strouds_NNS -_: burg_NN ,_, PA_NNP ,_, USA_NNP ._. Mitchell_NNP P._NNP Marcus_NNP ,_, Beatrice_NNP Santorini_NNP ,_, and_CC Mary_NNP Ann_NNP Marcinkiewicz_NNP ._. 1993_CD ._. Building_NNP a_DT large_JJ annotated_JJ corpus_NN of_IN english_NN :_: The_DT penn_JJ treebank_NN ._. COMPUTA_VB -_: TIONAL_NNP LINGUISTICS_NNP ,_, 19(_JJ 2_CD )_-RRB- :313–330_CD ._. Dalos_NNP D_NNP Miguel_NNP and_CC Rachel_NNP Edita_NNP O_NNP Roxas_NNP ._. 2007_CD ._. Comparative_NNP Evaluation_NNP of_IN Tagalog_NNP Part-of-Speech_NNP Taggers_NNP ._. 4th_JJ National_NNP Natural_NNP Language_NNP Processing_NNP Research_NNP Symposium_NNP Proceedings_NNP ,_, pages_NNS 74–77_VBP ._. W._NNP Nelson_NNP Francis_NNP and_CC Henry_NNP Kuçera_NNP ._. 1964_CD ._. Manual_NNP of_IN information_NN to_TO accompany_VB a_DT standard_JJ corpus_NN of_IN present-day_JJ edited_VBN american_JJ English_NNP ,_, for_IN use_NN with_IN digital_JJ computers_NNS ._. Olutobi_NNP Owoputi_NNP ,_, Chris_NNP Dyer_NNP ,_, Kevin_NNP Gimpel_NNP ,_, Nathan_NNP Schneider_NNP ,_, and_CC Noah_NNP A_NNP Smith_NNP ._. 2013_CD ._. Improved_VBN part-of-speech_NN tagging_VBG for_IN online_JJ conversational_JJ text_NN with_IN word_NN clusters_NNS ._. In_IN Proceedings_NNP of_IN the_DT 2013_CD Con_NNP -_: ference_NN of_IN the_DT North_NNP American_NNP Chapter_NN of_IN the_DT Asso-_NNP ciation_NN for_IN Computational_NNP Linguistics_NNP :_: Human_NNP Lan-_NNP guage_NN Technologies_NNP ._. Slav_NNP Petrov_NNP ,_, Dipanjan_NNP Das_NNP ,_, and_CC Ryan_NNP McDonald_NNP ._. 2012_CD ._. A_DT universal_JJ part-of-speech_NN tagset_NN ._. In_IN Proceed_NNP -_: ings_NNS of_IN the_DT Eight_CD International_NNP Conference_NNP on_IN Lan-_NNP guage_NN Resources_NNP and_CC Evaluation_NNP (_-LRB- LREC’12_NN )_-RRB- ,_, Istan-_NNP bul_NN ,_, Turkey_NNP ._. Ines_NNP Rehbein_NNP ._. 2013_CD ._. Fine-Grained_JJ POS_NNP Tagging_NN of_IN German_JJ Tweets_NNS ._. In_IN Language_JJ Processing_NNP and_CC Knowledge_NNP in_IN the_DT Web_NNP ,_, volume_NN 8105_CD of_IN Lecture_NNP Notes_NNPS in_IN Computer_NNP Science_NNP ,_, pages_NNS 162–175_CD ._. Alan_NNP Ritter_NNP ,_, Sam_NNP Clark_NNP ,_, Mausam_NNP ,_, and_CC Oren_NNP Etzioni_NNP ._. 2011_CD ._. Named_VBN Entity_NNP Recognition_NNP in_IN Tweets_NNP :_: An_DT Ex_NNP -_: perimental_JJ Study_NN ._. In_IN Proceedings_NNP of_IN the_DT Conference_NNP on_IN Empirical_NNP Methods_NNPS in_IN Natural_NNP Language_NNP Process_NNP -_: ing_NN ,_, EMNLP_NNP ’11_CD ,_, pages_NNS 1524–1534_CD ,_, Stroudsburg_NNP ,_, PA_NNP ,_, USA_NNP ._. Dan_NNP Roth_NNP and_CC Dmitry_NNP Zelenko_NNP ._. 1998_CD ._. Part_NNP of_IN speech_NN tagging_VBG using_VBG a_DT network_NN of_IN linear_NN separators_NNS ._. In_IN COLING_VBG 1998_CD Volume_NN 2_CD :_: The_DT 17th_JJ International_NNP Conference_NNP on_IN Computational_NNP Linguistics_NNP ._. Helmut_NNP Schmid_NNP ._. 1994_CD ._. Probabilistic_NNP part-of-speech_NN tagging_NN using_VBG decision_NN trees_NNS ._. In_IN International_NNP Con_NNP -_: ference_NN on_IN New_NNP Methods_NNPS in_IN Language_NNP Processing_NNP ,_, pages_NNS 44–49_CD ,_, Manchester_NNP ,_, UK._NNP Helmut_NNP Schmid_NNP ._. 1995_CD ._. Improvements_NNS in_IN part-of_JJ -_: speech_NN tagging_VBG with_IN an_DT application_NN to_TO german_NN ._. In_IN Proceedings_NNP of_IN the_DT ACL_NNP SIGDAT-Workshop_NNP ,_, pages_NNS 47–50_CD ._. Wojciech_NNP Skut_NNP ,_, Hans_NNP Uszkoreit_NNP ,_, Thorsten_NNP Brants_NNP ,_, and_CC Brigitte_NNP Krenn_NNP ._. 1998_CD ._. A_DT linguistically_RB interpreted_VBN corpus_NN of_IN german_JJ newspaper_NN text_NN ._. In_IN Proceedings_NNP of_IN the_DT 10th_JJ European_JJ Summer_NNP School_NNP in_IN Logic_NNP ,_, Lan-_NNP guage_NN and_CC Information_NN (_-LRB- ESSLLI’98_PRP )_-RRB- ._. Workshop_NNP on_IN Recent_JJ Advances_NNS in_IN Corpus_NNP Annotation_NNP ,_, August_NNP 17_CD -_: 28_CD ,_, Saarbrücken_NNP ,_, Germany_NNP ._. Heike_NNP Telljohann_NNP ,_, Erhard_NNP Hinrichs_NNP ,_, Sandra_NNP Kübler_NNP ,_, Ra_NNP Kübler_NNP ,_, and_CC Universität_NNP Tübingen_NNP ._. 2004_CD ._. The_DT tüba-d/z_NN treebank_NN :_: Annotating_NNP german_NN with_IN a_DT context-free_JJ backbone_NN ._. In_IN Proceedings_NNP of_IN the_DT Fourth_JJ International_NNP Conference_NN on_IN Language_NNP Resources_NNPS and_CC Evaluation_NNP (_-LRB- LREC_JJ 2004_CD )_-RRB- ,_, pages_NNS 2229–2235_CD ._. Kristina_NNP Toutanova_NNP ,_, Dan_NNP Klein_NNP ,_, Christopher_NNP D._NNP Man-_NNP ning_NN ,_, and_CC Yoram_NNP Singer_NNP ._. 2003_CD ._. Feature-rich_NNP part-of_, -_: speech_NN tagging_VBG with_IN a_DT cyclic_JJ dependency_NN network_NN ._. In_IN Proceedings_NNP of_IN the_DT 2003_CD Conference_NNP of_IN the_DT North_NNP American_NNP Chapter_NN of_IN the_DT Association_NNP for_IN Computa_NNP -_: tional_JJ Linguistics_NNP on_IN Human_NNP Language_NNP Technology_NNP –_NNP Volume_NN 1_CD ,_, NAACL_NNP ’03_CD ,_, pages_NNS 173–180_CD ,_, Strouds_NNS -_: burg_NN ,_, PA_NNP ,_, USA_NNP ._. Association_NNP for_IN Computational_NNP Lin-_NNP guistics_NNS ._.
