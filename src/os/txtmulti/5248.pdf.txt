22_CDEvolutionary_JJ Algorithms_NNP in_INDecision_NNP Tree_NNP Induction_NNFrancesco_NNP Mola1,_NNP Raffaele_NNP Miele2_NNP and_CC Claudio_NNP Conversano1_.1University_IN of_IN Cagliari,_NNP2University_IN of_IN Naples_NNP Federico_NNP II_NNPItaly_NNP1._. Introduction_NNOne_CD of_IN the_DT biggest_JJS problem_NN that_IN many_JJ data_NNS analysis_NN techniques_NNS have_VBP to_TO deal_VB with_IN nowadays_RBis_VBZ Combinatorial_NNP Optimization_NNP that,_, in_IN the_DT past,_NN has_VBZ led_VBN many_JJ methods_NNS to_TO be_VB taken_VBN apart._RBActually,_RB the_DT (still_NNP not_RB enough!)_RB higher_JJR computing_NN power_NN available_JJ makes_VBZ it_PRP possible_JJ to_TOapply_VB such_JJ techniques_NNS within_IN certain_JJ bounds._NN Since_IN other_JJ research_NN fields_NNS like_IN Artificial_NNIntelligence_NNP have_VBP been_VBN (and_NNP still_RB are)_VBP dealing_VBG with_IN such_JJ problems,_NNS their_PRP$ contribute_VBP to_TOstatistics_NNS has_VBZ been_VBN very_RB significant._.This_DT chapter_NN tries_VBZ to_TO cast_VB the_DT Combinatorial_NNPS Optimization_NNP methods_NNS into_IN the_DT Artificial_NNIntelligence_NNP framework,_, particularly_RB with_IN respect_NN Decision_NNP Tree_NNP Induction,_NNP which_WDT is_VBZconsidered_VBN a_DT powerful_JJ instrument_NN for_IN the_DT knowledge_NN extraction_NN and_CC the_DT decision_NN making_VBGsupport._NN When_WRB the_DT exhaustive_NN enumeration_NN and_CC evaluation_NN of_IN all_DT the_DT possible_JJ candidate_NNsolution_NN to_TO a_DT Tree-based_JJ Induction_NN problem_NN is_VBZ not_RB computationally_RB affordable,_VB the_DT use_NN of_INNature_NN Inspired_VBN Optimization_NN Algorithms,_IN which_WDT have_VBP been_VBN proven_VBN to_TO be_VB powerful_JJinstruments_NNS for_IN attacking_VBG many_JJ combinatorial_JJ optimization_NN problems,_NN can_MD be_VB of_IN great_JJ help._NNIn_IN this_DT respect,_NN the_DT attention_NN is_VBZ focused_VBN on_IN three_CD main_JJ problems_NNS involving_VBG Decision_NNP Tree_NNPInduction_NN by_IN mainly_RB focusing_VBG the_DT attention_NN on_IN the_DT Classification_NNP and_CC Regression_NNP Tree-CART_NNP(Breiman_NNP et_VBD al.,_RB 1984)_CD algorithm._NN First,_IN the_DT problem_NN of_IN splitting_NN complex_JJ predictors_NNS such_JJ a_DTmulti-attribute_JJ ones_NNS is_VBZ faced_VBN through_IN the_DT use_NN of_IN Genetic_NNP Algorithms._NNP In_IN addition,_VBG the_DTpossibility_NN of_IN growing_VBG “optimal”_JJ exploratory_NN trees_NNS is_VBZ also_RB investigated_VBN by_IN making_VBG use_NN of_IN Ant_NNPColony_NNP Optimization_NNP (ACO)_NNP algorithm._RB Finally,_RB the_DT derivation_NN of_IN a_DT subset_NN of_IN decision_NN trees_NNSfor_IN modelling_VBG multi-attribute_JJ response_NN on_IN the_DT basis_NN of_IN a_DT data-driven_JJ heuristic_NN is_VBZ also_RBdescribed._VBN The_DT proposed_JJ approaches_NNS might_MD be_VB useful_JJ for_IN knowledge_NN extraction_NN from_IN large_JJdatabases_NNS as_RB well_RB as_IN for_IN data_NNS mining_NN applications._VBZ The_DT solution_NN they_PRP offer_VBP for_IN complicated_VBNdata_NNS modelling_NN and_CC data_NNS analysis_NN problems_NNS might_MD be_VB considered_VBN for_IN a_DT possible_JJimplementation_NN in_IN a_DT Decision_NNP Support_NNP System_NNP (DSS)._.The_DT remainder_NN of_IN the_DT chapter_NN is_VBZ as_IN follows._VBG Section_NN 2_CD describes_VBZ the_DT main_JJ features_NNS and_CC the_DTrecent_JJ developments_NNS of_IN Decision_NNP Tree_NNP Induction._NNP An_DT overview_NN of_IN Combinatorial_NNPOptimization_NN with_IN a_DT particular_JJ focus_NN on_IN Genetic_JJ Algorithms_NNP and_CC Ant_NNP Colony_NNP Optimization_NNis_VBZ presented_VBN in_IN section_NN 3._VBD The_DT use_NN of_IN these_DT two_CD algorithms_NNS within_IN the_DT Decision_NNP Tree_NNP Induction_NNFramework_NNP is_VBZ described_VBN in_IN section_NN 4,_CD together_RB with_IN the_DT description_NN of_IN the_DT algorithm_NN for_INmodelling_VBG multi-attribute_JJ response._NN Section_NN 5_CD summarizes_VBZ the_DT results_NNS of_IN the_DT proposed_VBN O_UHpe_NNn_NNAc_VBGce_NNss_NND_LSat_INab_NNas_INe_NNw_WRBw_WRBw_WRB.i-_.te_NNch_NNon_INlin_NNe._FWco_NNm_NNSource:_NNP Advances_NNS in_IN Evolutionary_NNP Algorithms,_NNP Book_NNP edited_VBD by:_IN Witold_NNP Kosiński,_NNP ISBN_NNP 978-953-7619-11-4,_. pp._. 468,_VBD November_NNP 2008,_CDI-Tech_NNP Education_NNP and_CC Publishing,_NNP Vienna,_NNP Austria_NNPwww.intechopen.com_NNAdvances_NNS in_IN Evolutionary_NNP Algorithms_NNP444_CDmethod_NN on_IN real_JJ and_CC simulated_JJ datasets._NN Concluding_VBG remarks_NNS are_VBP presented_VBN in_IN section_NN 6._. The_DTchapter_NN also_RB includes_VBZ an_DT appendix_NN that_WDT presents_VBZ J-Fast,_JJ a_DT Java-based_JJ software_NN for_IN Decision_NNPTree_NNP that_WDT currently_RB implements_VBZ Genetic_JJ Algorithms_NNP and_CC Ant_NNP Colony_NNP Optimization._.2._VBZ Decision_IN tree_NN induction_NNDecision_NNP Tree_NNP Induction_NNP (DTI)_NNP is_VBZ a_DT tool_NN to_TO induce_VB a_DT classification_NN or_CC regression_NN model_NN from_IN(usually_RB large)_JJ datasets_NNS characterized_VBN by_IN N_NNP observations_NNS (records),_VBD each_DT one_CD containing_VBG a_DT set_NNx_NN of_IN numerical_JJ or_CC nominal_JJ variables,_NN and_CC a_DT variable_JJ y._NNP Statisticians_NNPS use_VBP the_DT terms_NNS “splitting_VBGpredictors”_VB to_TO identify_VB x_NN and_CC “response_NN variable”_NN for_IN y._NNP DTI_NNP builds_VBZ a_DT model_NN that_IN summarizes_NNSthe_DT underlying_VBG relationships_NNS between_IN x_NN and_CC y._NNP Actually,_NNP two_CD kinds_NNS of_IN model_NN can_MD be_VBestimated_VBN using_VBG decision_NN trees:_NN classification_NN trees_NNS if_IN y_PRP is_VBZ nominal,_JJ and_CC regression_NN trees_NNS if_IN y_PRP is_VBZnumerical._DT Hereinafter_IN we_PRP refer_VBP to_TO classification_NN trees_NNS to_TO show_VB the_DT main_JJ features_NNS of_IN DTI_NNP and_CCbriefly_NN recall_VBP the_DT main_JJ characteristics_NNS of_IN regression_NN trees_NNS at_IN the_DT end_NN of_IN the_DT section._NNDTI_NNP proceeds_NNS by_IN inducing_VBG a_DT series_NN of_IN follow-up_JJ (usually_RB binary)_JJ questions_NNS about_IN the_DTattributes_NNS of_IN an_DT unknown_JJ observation_NN until_IN a_DT conclusion_NN about_IN what_WP is_VBZ its_PRP$ most_RBS likely_JJ class_NNlabel_NN is_VBZ reached._VBN Questions_NNS and_CC their_PRP$ alternative_JJ answers_NNS can_MD be_VB represented_VBN hierarchically_RB in_INthe_DT form_NN of_IN a_DT decision_NN tree._NN It_PRP contains_VBZ a_DT root_NN node_NN and_CC some_DT internal_JJ and_CC terminal_JJ nodes._.The_DT root_NN node_NN and_CC the_DT internal_JJ ones_NNS are_VBP used_VBN to_TO partition_NN observations_NNS of_IN the_DT dataset_NN into_INsmaller_JJR subsets_NNS of_IN relatively_RB homogeneous_JJ classes._. To_TO classify_VB a_DT previously_RB unlabelled_VBNobservation,_NNS say_VBP i*_JJ (i*=1,…..,N),_IN we_PRP start_VBP from_IN the_DT test_NN condition_NN in_IN the_DT root_NN node_NN and_CC follow_VBthe_DT appropriate_JJ pattern_NN based_VBN on_IN the_DT outcome_NN of_IN the_DT test._NN When_WRB an_DT internal_JJ node_NN is_VBZ reached_VBN a_DTnew_JJ test_NN condition_NN is_VBZ applied,_VBN and_CC so_RB on_IN down_IN to_TO a_DT terminal_NN node._NN Encountering_VBG a_DT terminal_NNnode,_, the_DT modal_JJ class_NN of_IN the_DT observations_NNS in_IN that_DT node_NN is_VBZ the_DT class_NN label_NN of_IN y_NN assigned_VBN to_TO the_DT(previously)_JJ unlabeled_JJ observation._NN For_IN regression_NN trees,_, the_DT assigned_VBN class_NN is_VBZ the_DT mean_NN of_IN y_NNfor_IN the_DT observations_NNS belonging_VBG to_TO that_DT terminal_NN node._.Because_IN of_IN their_PRP$ top-down_JJ binary_JJ splitting_NN approach,_NN decision_NN trees_NNS can_MD easily_RB be_VB converted_VBNinto_IN IF-THEN_NNP rules_NNS and_CC used_VBD for_IN decision_NN making_NN purposes._.DTI_NNP is_VBZ useful_JJ for_IN knowledge_NN extraction_NN from_IN large_JJ databases_NNS and_CC data_NNS mining_NN applications_NNSbecause_IN of_IN the_DT possibility_NN to_TO represent_VB functions_NNS of_IN numerical_JJ and_CC nominal_JJ variables_NNS as_RB well_RBas_IN of_IN its_PRP$ feasibility,_NN predictive_JJ ability_NN and_CC interpretability._NN It_PRP can_MD effectively_RB handle_VB missing_VBGvalues_NNS and_CC noisy_JJ data_NNS and_CC can_MD be_VB used_VBN either_RB as_IN an_DT explanatory_JJ tool_NN for_IN distinguishing_VBGobservations_NNS of_IN different_JJ classes_NNS or_CC as_IN a_DT prediction_NN tool_NN to_TO class_NN labels_NNS of_IN previously_RB unseen_JJobservations._.Some_DT of_IN the_DT well-known_JJ DTI_JJ algorithms_NNS include_VBP ID3_DT (Quinlan,_NNP 1983),_CD CART_NNP (Breiman_NNP et_NNP al.,_.1984),_CD C4.5_IN (Quinlan,_NNP 1993),_CD SLIQ_IN (Metha_NNP et_NNP al.,_RB 1996),_CD FAST_NNP (Mola_NNP &_CC Siciliano,_NNP 1997)_CD and_CCGUIDE_NNP (Loh,_NN 2002)._. All_PDT these_DT algorithms_NNS use_VBP a_DT greedy,_JJ top-down_JJ recursive_JJ partitioning_NNapproach._NN They_PRP primarily_RB differ_VBP in_IN terms_NNS of_IN the_DT splitting_NN criteria,_VBD the_DT type_NN of_IN splits_NNS (2-way_JJ or_CCmulti-way)_JJ and_CC the_DT handling_NN of_IN the_DT overfitting_JJ problem._NNDTI_NNP uses_VBZ a_DT greedy,_JJ top-down_JJ recursive_JJ partitioning_NN approach_NN to_TO induce_VB a_DT decision_NN tree_NN from_INdata._NN In_IN general,_JJ DTI_NNP involves_VBZ the_DT following_VBG tasks:_JJ decision_NN tree_NN growing_VBG and_CC decision_NN tree_NNpruning._.2.1_CD Tree_NNP growing_VBGAs_IN for_IN the_DT growing_VBG of_IN a_DT decision_NN tree,_NN DTI_NNP use_NN a_DT greedy_JJ heuristic_JJ to_TO make_VB a_DT series_NN of_IN locally_RBoptimum_JJ decisions_NNS about_IN which_WDT value_NN of_IN a_DT splitting_JJ predictor_NN to_TO use_VB for_IN data_NNS partitioning._. A_NNwww.intechopen.com_NNarsencihuy@gmail.com_NNHighlight_.arsencihuy@gmail.com_NNHighlight_.Evolutionary_JJ Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NN445_CDtest_NN condition_NN depending_VBG on_IN a_DT splitting_JJ method_NN is_VBZ applied_VBN to_TO partition_VB the_DT data_NNS into_IN more_RBRhomogeneous_JJ subgroups_NNS at_IN each_DT step_NN of_IN the_DT greedy_JJ algorithm._NNSplitting_VBG methods_NNS differ_VBP with_IN respect_NN to_TO the_DT type_NN of_IN splitting_JJ predictor:_NN for_IN nominal_JJ splitting_NNpredictors_NNS the_DT test_NN condition_NN is_VBZ expressed_VBN as_IN a_DT question_NN about_IN one_CD or_CC more_JJR of_IN its_PRP$ attributes,_NNwhose_WP$ outcomes_NNS are_VBP “Yes”/”No”._NNP Grouping_NNP of_IN splitting_JJ predictor_NN attributes_NNS is_VBZ required_VBN for_INalgorithms_NNS using_VBG 2-way_JJ splits._NN For_IN ordinal_JJ or_CC continuous_JJ splitting_NN predictors_VBZ the_DT test_NNcondition_NN is_VBZ expressed_VBN on_IN the_DT basis_NN of_IN a_DT threshold_NN value_NN υ_, such_JJ as_IN (xi_NNP ≤_NNP υ?)_NNP or_CC (xi_NNP >_, υ?)._NNP By_INconsidering_VBG all_PDT the_DT possible_JJ split_NN points_NNS υ,_IN the_DT best_JJS one_NN υ*_NN partitioning_VBG the_DT instances_NNS into_INhomogeneous_JJ subgroups_NNS is_VBZ selected._VBNIn_IN the_DT classification_NN problem,_, the_DT sample_NN population_NN consists_VBZ of_IN N_NNP observations_NNS deriving_VBGfrom_IN C_NNP response_NN classes._NN A_DT decision_NN tree_NN (or_NN classifier)_NN will_MD break_VB these_DT observations_NNS into_IN k_NNterminal_NN groups,_NN and_CC to_TO each_DT of_IN these_DT a_DT predicted_VBD class_NN (being_VBG one_CD of_IN the_DT possible_JJ attributes_NNSof_IN the_DT response_NN variable)_NN is_VBZ assigned._VBN In_IN actual_JJ application,_JJ most_JJS parameters_NNS are_VBP estimated_VBNfrom_IN the_DT data._NN In_IN fact,_NN denoting_NN with_IN t_NN some_DT node_NN of_IN the_DT tree_NN (t_NN represents_VBZ both_DT a_DT set_NN of_INindividuals_NNS in_IN the_DT sample_NN data_NN and,_NNS via_IN the_DT tree_NN that_WDT produced_VBD it,_IN a_DT classification_NN rule_NN for_INfuture_JJ data)_NNS from_IN the_DT binary_JJ tree_NN it_PRP is_VBZ possible_JJ to_TO estimate_VB P(t)_NNP and_CC P(i|t)_NNP for_IN future_NNobservations_NNS as_RB follows:_.(_-LRB- )_-RRB- (_-LRB- ){_NN }_JJ (_-LRB- )_-RRB-1_CD 1_CDC_NNP C_NNPi_FW i_FW iA_FW ii_FW i_FWP_NNP t_NN P_NNP x_NN t_NN x_NN i_VBD n_RB nπ_VB τ_DT π=_JJ ==_NN ∈_NN =_SYM ≈∑_FW ∑_FW (1)_FW(_-LRB- )_-RRB- (_-LRB- ){_NN }_FW (_-LRB- ){_NN }_NN {_NN }_NN (_-LRB- )_-RRB- (_-LRB- )_-RRB-1_CDC_LSi_NN i_IN it_PRP i_VBZ i_IN it_PRP ii_.P_NNP i_FW t_NN P_NNP x_NN i_IN x_NN t_NN P_NNP x_NN t_NN x_NN i_IN P_NNP x_NN t_VBD n_RB n_RB n_RB nτ_VB π_DT τ_JJ π_NN π==_IN =_SYM ∈_NN =_SYM ∈_FW =_SYM ∈_JJ ≈_NN ∑_NN (2)_.where_WRB πi_NNP is_VBZ the_DT prior_JJ probability_NN of_IN each_DT class_NN i_IN (i_NNP ∈_NNP 1,2,….,C),_CD τ(x)_NN is_VBZ the_DT true_JJ class_NN of_IN an_DTobservation_NN xi_NN (x_NN is_VBZ the_DT vector_NN of_IN predictor_NN variables),_NN ni_NNS and_CC nt_NN are_VBP the_DT number_NN of_INobservations_NNS in_IN the_DT sample_NN that_IN respectively_RB are_VBP class_NN i_NN and_CC node_NN t,_NN and_CC nit_NN is_VBZ the_DT number_NN of_INobservations_NNS in_IN the_DT sample_NN that_WDT are_VBP class_NN i_NN and_CC node_NN t._NNIn_IN addition,_NN by_IN denoting_VBG with_IN R_NN the_DT risk_NN of_IN misclassification,_VBG the_DT risk_NN of_IN t_NN (denoted_VBN with_IN R(t))_NNSand_CC the_DT risk_NN of_IN a_DT model_NN (or_IN tree)_NNS T_NNP (denoted_VBD with_IN R(T))_NNP are_VBP measured_VBN as_IN follows:_VBN(_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )(_NN )_-RRB-1_CD,_,C_LSi_FWR_NN t_NN P_NNP i_IN t_NN L_NNP i_IN tτ==∑_NN (3)_.(_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB-1_CDk_NNj_NN jj_NNR_NN T_NNP P_NNP t_NN R_NN t==∑_NN (4)_CCwhere_WRB L(i,j)_NNP is_VBZ the_DT loss_NN matrix_NN for_IN incorrectly_RB classifying_VBG an_DT i_NN as_IN a_DT j_NN (with_IN L(i,i)=0),_NNP and_CC τ(t)_NNP is_VBZthe_DT class_NN assigned_VBN to_TO t_VB once_RB that_IN t_NN is_VBZ a_DT terminal_NN node_NN and_CC τ(t)_NN is_VBZ chosen_VBN to_TO minimize_VB R(t)_NN and_CC tj_NNare_VBP terminal_JJ nodes_NNS of_IN the_DT tree_NN T._NNP If_IN L(i,i)=1_NNP for_IN all_DT i≠j,_NN and_CC the_DT prior_JJ probabilities_NNS τ_, are_VBP set_VBN to_TObe_VB equal_JJ to_TO the_DT observed_JJ class_NN frequencies_NNS in_IN the_DT sample,_NN then_RB P(i|t)=nit/nt_NNP and_CC R(T)_NNP is_VBZ the_DTproportion_NN of_IN misclassified_JJ observations._NNWhen_WRB splitting_NN a_DT node_NN t_NN into_IN tr_NN and_CC tl_NN (left_NN and_CC right_NN sons),_NN the_DT following_VBG relationship_NN holds:_NNSP(tl)_NNP R(tl)_NNP +_NNP P(tr)_NNP R(tr)_NNP ≤_NNP P(t)_NNP R(t)._NNP An_DT obvious_JJ way_NN to_TO build_VB a_DT tree_NN is_VBZ to_TO chose_VBD that_IN split_NNmaximizing_VBG ΔR,_NNP i.e.,_IN the_DT decrease_NN in_IN risk._NNP To_TO this_DT aim,_NN several_JJ measures_NNS of_IN impurity_NN (or_CCdiversity)_NN of_IN a_DT node_NN are_VBP used._VBN Denoting_VBG with_IN f_NN some_DT impurity_NN function,_IN the_DT local_JJ impurity_NN of_INa_DT node_NN t_NN is_VBZ defined_VBN as:_INwww.intechopen.com_NNAdvances_NNS in_IN Evolutionary_NNP Algorithms_NNP446_CD(_-LRB- )_-RRB- (_-LRB- )_-RRB-1_CDC_LSiti_.t_NN f_NN pε_NN ==∑_NN (5)_.where_WRB pit_NN is_VBZ the_DT proportion_NN of_IN those_DT in_IN t_NN that_WDT belong_VBP to_TO class_NN i_NN for_IN future_JJ samples._NN Since_IN ε(t)=0_VBGwhen_WRB t_NN is_VBZ pure,_JJ f_NN must_MD be_VB concave_JJ with_IN f(0)=f(1)=0._DT Two_CD candidates_NNS for_IN f_NN are_VBP the_DT information_NNindex_NN f(p)_VBD =_SYM -p_JJ log(p)_NN and_CC the_DT Gini_NNP index_NN f(p)=_VBD -p(1-p),_JJ that_IN slightly_RB differ_VB for_IN the_DT two_CD class_NNproblem_NN where_WRB nearly_RB always_RB choose_VBP the_DT same_JJ split_NN point._NN Once_RB that_IN f_NN has_VBZ been_VBN chosen,_VBN the_DTsplit_NN maximizing_VBG the_DT impurity_NN reduction_NN is:_.(_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )l_NN l_JJ r_NN rp_JJ t_NN t_NN p_NN t_NN t_NN p_NN t_NN tε_IN ε_JJ ε_NN εΔ_NN =_SYM −_FW −_FW (6)_FWData_NNP partitioning_NN proceeds_NNS recursively_RB until_IN a_DT stopping_NN rule_NN is_VBZ satisfied:_VBN this_DT usually_RB happens_VBZwhen_WRB the_DT number_NN of_IN observations_NNS in_IN a_DT node_NN is_VBZ lower_JJR than_IN a_DT previously-specified_JJ minimum_NNnumber_NN necessary_JJ for_IN splitting,_NN as_RB well_RB as_IN when_WRB the_DT same_JJ observations_NNS belong_VBP to_TO the_DT same_JJclass_NN or_CC have_VBP the_DT same_JJ response_NN class._.2.2_CD FAST_NNP splitting_NN algorithm_NNThe_DT goodness_NN of_IN split_NN criterion_NN based_VBN on_IN (6)_JJ expresses_NNS in_IN different_JJ way_NN some_DT equivalent_NNcriteria_NNS which_WDT are_VBP present_JJ in_IN most_JJS of_IN the_DT tree-growing_NN procedures_NNS implemented_VBN in_INspecialized_JJ software;_NN such_JJ as,_NN for_IN instance,_NN CART_NNP (Breiman_NNP et_NNP al.,_RB 1984),_CD ID3_. and_CC C4.5_VB(Quinlan,_NN 1993)._MDIn_IN many_JJ situations_NNS the_DT computational_JJ time_NN required_VBN by_IN a_DT recursive_JJ partitioning_NN algorithm_NN is_VBZan_DT important_JJ issue_NN that_WDT can_MD not_RB be_VB neglected._VBN In_IN this_DT respect,_NN a_DT fast_JJ algorithm_NN is_VBZ required_VBN to_TOspeed_NN up_IN the_DT procedure._NN In_IN view_NN of_IN that,_IN it_PRP is_VBZ worth_JJ considering_VBG a_DT two-stage_NN splitting_NNcriterion_NN which_WDT takes_VBZ into_IN account_NN of_IN the_DT global_JJ role_NN played_VBD by_IN a_DT splitting_JJ predictor_NN in_IN the_DTpartitioning_NN step._VBD A_DT global_JJ impurity_NN reduction_NN factor_NN of_IN any_DT predictor_NN xi_NN is_VBZ defined_VBN as:_IN(_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )|_NN |_NN |_.s_PRPs_PRPy_NN x_NN y_RB g_VBGg_VBG G_NNPt_NN t_NN p_NN g_VBG tε∈Ε_NN =_SYM ∑_FW (7)_FWwhere_WRB εy|g(t)_NN is_VBZ the_DT impurity_NN of_IN the_DT conditional_JJ distribution_NN of_IN y_NN given_VBN the_DT s-th_JJ attribute_NN of_IN xs_NNSand_CC G_NNP is_VBZ the_DT number_NN of_IN attributes_NNS of_IN xs_NNP (g_NNP ε_NNP G)._NNP The_DT two-stage_JJ criterion_NN finds_VBZ the_DT best_JJS splitting_NNpredictor(s)_NN as_IN the_DT one_CD (or_NN those)_IN minimizing_VBG (7)_JJ and,_NNS consequently,_VBP the_DT best_JJS split_NN point_NNamong_IN the_DT candidate_NN splits_VBZ induced_VBN by_IN the_DT best_JJS predictor(s)_NN minimizing_VBG the_DT (6)_NN by_IN taking_VBGaccount_NN only_RB the_DT partitions_NNS or_CC splits_NNS generated_VBN by_IN the_DT best_JJS predictor._NN This_DT criterion_NN can_MD be_VBapplied_VBN either_CC sic_JJ et_FW simpliciter_FW or_CC by_IN considering_VBG alternative_JJ modelling_JJ strategies_NNS in_IN the_DTpredictor_NN selection_NN (an_IN overview_NN of_IN the_DT two-stage_JJ methodology_NN can_MD be_VB found_VBN in_IN Siciliano_NNP &_CCMola,_NNP 2000)._CDThe_DT FAST_NNP splitting_NN algorithm_IN (Mola_NNP &_CC Siciliano,_NNP 1997)_VBD can_MD be_VB applied_VBN when_WRB the_DT following_VBGproperty_NN holds_VBZ for_IN the_DT impurity_NN measure:_NN(_-LRB- )_-RRB- (_-LRB- )|_NN |_NN ;_:s_PRPy_NN x_NN y_RB ht_VBD t_NN h_NN g_VBG h_NN GΕ_NNP ≤_NNP Ε_NNP ∀_NNP ≠_NNP ∈_NNP (8)_.and_CC it_PRP consists_VBZ of_IN two_CD basic_JJ rules:_NN •_NNS iterate_VBP the_DT two-stage_JJ partitioning_NN criterion_NN by_IN using_VBG (7)_JJ and_CC (6):_JJ select_JJ one_NN splitting_NNpredictor_NN at_IN a_DT time_NN and_CC consider,_NN at_IN each_DT time,_NN the_DT previously_RB unselected_JJ splitting_NNpredictors;_NNwww.intechopen.com_NNEvolutionary_JJ Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NN447_CD•_RB stop_VB the_DT iterations_NNS when_WRB the_DT current_JJ best_JJS predictor_NN in_IN the_DT order_NN x(k)_NN at_IN iteration_NN k_NN does_VBZnot_RB satisfy_VB the_DT condition_NN (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )*_NN 1|_JJ |k_NN ky_JJ x_NN y_RB ht_VBD t−Ε_DT ≤_JJ Ε_NN ,_, where_WRB s*(k−1)_NN is_VBZ the_DT best_JJS partition_NN at_IN the_DTiteration_NN (k_NN −_NN 1)._.The_DT algorithm_NN finds_VBZ the_DT optimal_JJ split_NN with_IN substantial_JJ time_NN savings_NNS in_IN terms_NNS of_IN the_DT reduced_VBNnumber_NN of_IN partitions_NNS or_CC splits_VBZ to_TO be_VB tried_VBN out_RP at_IN each_DT node_NN of_IN the_DT tree._NN Simulation_NN studies_NNSshow_NN that_IN the_DT relative_JJ reduction_NN in_IN the_DT average_JJ number_NN of_IN splits_NNS analyzed_VBN by_IN the_DT FAST_NNalgorithm_NN with_IN respect_NN to_TO the_DT standard_JJ approaches_NNS in_IN binary_JJ trees_NNS increases_NNS as_IN a_DT function_NN of_INboth_PDT the_DT number_NN of_IN attributes_NNS of_IN the_DT splitting_JJ predictor_NN and_CC of_IN the_DT number_NN of_IN observations_NNS at_INa_DT given_VBN node._NN Further_JJ theoretical_JJ results_NNS about_IN the_DT computational_JJ efficiency_NN of_IN FAST-like_JJalgorithms_NNS can_MD be_VB found_VBN in_IN Klaschka_NNP et_NNP al._. (1998)._.2.3_CD Tree_NNP pruning_NNAs_IN for_IN the_DT pruning_NN step,_NN it_PRP is_VBZ usually_RB required_VBN in_IN DTI_NNP in_IN order_NN to_TO control_VB for_IN the_DT size_NN of_IN the_DTinduced_JJ model_NN and_CC to_TO avoid_VB in_IN this_DT way_NN data_NNS overfitting._, Typically,_JJ data_NNS is_VBZ partitioned_VBN into_IN a_DTtraining_NN set_VBD (containing_VBG two-third_JJ of_IN the_DT data)_NN and_CC a_DT test_NN set_VBN (with_IN the_DT remaining_VBG one-third)._.Training_NN set_NN contains_VBZ labelled_JJ observations_NNS and_CC it_PRP is_VBZ used_VBN for_IN the_DT tree_NN growing._NN It_PRP is_VBZ assumed_VBNthat_IN the_DT test_NN set_NN contains_VBZ unlabelled_JJ observations_NNS and_CC it_PRP is_VBZ used_VBN for_IN selecting_VBG the_DT final_JJdecision_NN tree:_NN to_TO check_VB whether_IN a_DT decision_NN tree,_NN say_VBP T,_NNP is_VBZ generalizable,_JJ it_PRP is_VBZ necessary_JJ to_TOevaluate_VB its_PRP$ performance_NN on_IN the_DT test_NN set_NN in_IN terms_NNS of_IN misclassification_NN error_NN by_IN comparing_VBG the_DTtrue_JJ class_NN labels_NNS of_IN the_DT test_NN data_NNS against_IN those_DT predicted_VBN by_IN T._NNP Reduced-size_NNP trees_NNS perform_VBPpoorly_RB on_IN both_DT training_NN and_CC test_NN sets_NNS causing_VBG underfitting._NNP Instead,_NNP increasing_VBG the_DT size_NN of_IN T_NNPimproves_VBZ both_DT the_DT training_NN and_CC test_NN errors_NNS up_IN to_TO a_DT “critical_JJ size”_NN from_IN which_WDT the_DT test_NN errors_NNSincrease_NN even_RB though_IN the_DT corresponding_JJ training_NN errors_NNS decrease._'' This_DT means_VBZ that_IN T_NNP overfits_NNSthe_DT data_NNS and_CC cannot_MD be_VB generalized_VBN to_TO class_NN prediction_NN of_IN unseen_JJ observations._NNP In_IN the_DTmachine_NN learning_VBG framework,_IN the_DT training_NN error_NN is_VBZ named_VBN resubstitution_NN error_NN and_CC the_DT test_NNerror_NN is_VBZ known_VBN as_IN the_DT generalization_NN error._.It_PRP is_VBZ possible_JJ to_TO prevent_VB overfitting_JJ by_IN haltering_VBG the_DT tree_NN growing_VBG before_IN it_PRP becomes_VBZ too_RBcomplex_NN (pre-pruning)._, In_IN this_DT framework,_NN one_NN can_MD assume_VB the_DT training_NN data_NNS is_VBZ a_DT good_JJrepresentation_NN of_IN the_DT overall_JJ data_NNS and_CC use_VB the_DT resubstitution_NN error_NN as_IN an_DT optimistic_JJ estimate_NNof_IN the_DT error_NN of_IN the_DT final_JJ DTI_NNP model_NN (optimistic_JJ approach)._NN Alternatively,_NNP Quinlan_NNP (1987)_.proposed_VBN a_DT pessimistic_JJ approach_NN that_WDT penalizes_VBZ complicated_VBN models_NNS by_IN assigning_VBG a_DT cost_NNpenalty_NN to_TO each_DT terminal_NN node_NN of_IN the_DT decision_NN tree:_NN for_IN C4.5,_VBG the_DT generalization_NN error_NN is_VBZR(t)/nt+ε,_NNP where,_, for_IN a_DT node_NN t,_NN nt_NN is_VBZ the_DT number_NN of_IN observations_NNS and_CC R(t)_NNP is_VBZ the_DTmisclassification_NN error._NN It_PRP is_VBZ assumed_VBN that_IN R(t)_NNP follows_VBZ a_DT Binomial_JJ distribution_NN and_CC that_DT ε_NN is_VBZthe_DT upper_JJ bound_JJ for_IN R(t)_JJ computed_VBN from_IN such_JJ a_DT distribution_NN (Quinlan,_NN 1993)._.An_DT alternative_NN pruning_NN strategy_NN is_VBZ based_VBN on_IN the_DT growing_VBG of_IN the_DT entire_JJ tree_NN and_CC the_DTsubsequent_JJ retrospective_NN trimming_VBG of_IN some_DT of_IN its_PRP$ internal_JJ nodes_NNS (post-pruning):_, the_DT subtree_NNdeparting_VBG from_IN each_DT internal_JJ node_NN is_VBZ replaced_VBN with_IN a_DT new_JJ terminal_NN node_NN whose_WP$ class_NN label_NNderives_NNS from_IN the_DT majority_NN class_NN of_IN observations_NNS belonging_VBG to_TO that_DT subtree._JJR The_DT latter_NN is_VBZdefinitively_RB replaced_VBN by_IN the_DT terminal_NN node_NN if_IN such_JJ a_DT replacement_NN induces_VBZ an_DT improvement_NN of_INthe_DT generalization_NN error._NN Pruning_NN stops_VBZ when_WRB no_DT further_JJ improvements_NNS can_MD be_VB achieved._VBN The_DTgeneralization_NN error_NN can_MD be_VB estimated_VBN through_IN either_CC the_DT optimistic_JJ or_CC pessimistic_JJapproaches._.Other_JJ post-pruning_JJ algorithms,_NNS such_JJ as_IN CART,_NNP use_VBP a_DT complexity_NN measure_NN that_WDT accounts_VBZ for_INboth_CC the_DT tree_NN size_NN and_CC the_DT generalization_NN error._NN Once_RB the_DT entire_JJ tree_NN is_VBZ grown_VBN using_VBG training_NNwww.intechopen.com_NNAdvances_NNS in_IN Evolutionary_NNP Algorithms_NNP448_CDobservations,_NNS a_DT penalty_NN parameter_NN expressing_VBG the_DT gain/cost_NN trade_NN off_IN for_IN trimming_VBG each_DTsubtree_NN is_VBZ used_VBN to_TO generate_VB a_DT sequence_NN of_IN pruned_JJ trees,_NN and_CC the_DT tree_NN in_IN the_DT sequence_NNpresenting_VBG the_DT lowest_JJS generalization_NN error_NN (0-SE_JJ rule)_NN or_CC the_DT one_CD with_IN a_DT generalization_NN error_NNwithin_IN one_CD standard_JJ error_NN of_IN its_PRP$ minimum_JJ (1-SE_JJ rule)_NN is_VBZ selected._VBN Let_VB α_NNP be_VB a_DT number_NN in_IN[0,+∞],_NN called_VBD complexity_NN parameter,_NN measuring_VBG the_DT “cost”_NN of_IN adding_VBG another_DT variable_JJ to_TO the_DTmodel._. Let_VB R(T0)_CC be_VB the_DT risk_NN for_IN the_DT zero_CD split_NN tree._NN Define:_NNS(_-LRB- )_-RRB- (_-LRB- )R_NN T_NNP R_NN T_NNP Tα_NNP α=_NNP +_NNP (9)_.to_TO be_VB the_DT cost_NN for_IN the_DT tree,_NN and_CC define_VB Tα_NNS to_TO be_VB that_DT subtree_NN of_IN the_DT entire_NN tree_NN having_VBG the_DTminimal_JJ cost._NN Obviously,_NNP T0_NNP is_VBZ the_DT entire_JJ tree_NN and_CC T∞_NNP is_VBZ the_DT zero_CD splits_VBZ model._JJ The_DT idea_NN is_VBZ to_TOfind,_NN for_IN each_DT α,_NN the_DT subtree_JJ Tα_NNP ⊆_NNP T0_. minimizing_VBG Rα(T)._NNP The_DT tuning_NN parameter_NN α_IN ≥_NNP 0_CD governs_NNSthe_DT trade_NN off_RP between_IN the_DT tree_NN size_NN and_CC its_PRP$ goodness_NN of_IN fit_NN to_TO the_DT data._NN Large_JJ values_NNS of_IN α_NNP result_NNin_IN small_JJ trees,_NN and_CC conversely_RB for_IN smaller_JJR values_NNS of_IN α._NNP Of_IN course,_NN with_IN α=0_VBG the_DT solution_NN is_VBZ the_DTfull_JJ tree_NN T0._DT It_PRP is_VBZ worth_JJ noticing_VBG that,_, by_IN adaptively_RB choosing_VBG αI,_RB it_PRP exists_VBZ a_DT unique_JJ smallest_JJSsubtree_JJ Tα_NNP minimizing_NN Rα(T)._. A_DT weakest_JJS link_NN pruning_VBG approach_NN is_VBZ used_VBN to_TO find_VB Tα:_NNS it_PRP consists_VBZin_IN successively_RB collapsing_VBG the_DT internal_JJ node_NN producing_VBG the_DT smallest_JJS per-node_JJ increase_NN in_INR(T),_NN continuing_VBG this_DT way_NN until_IN the_DT single-node_JJ (root)_IN tree_NN is_VBZ produced._VBN This_DT gives_VBZ a_DT (finite)_NNsequence_NN of_IN subtrees,_NNS and_CC it_PRP is_VBZ easy_JJ to_TO show_VB that_IN this_DT sequence_NN must_MD contains_VBZ Tα_NNP (see_NNP Breiman_NNPet_FW al_JJ (1984)_NN for_IN details)._VBGUsually,_NNP pruning_NN algorithms_NNS can_MD be_VB combined_VBN with_IN V-fold_JJ cross-validation_NN when_WRB few_JJobservations_NNS are_VBP available._JJ Training_NN data_NNS is_VBZ divided_VBN into_IN V_NNP disjoint_NN blocks_NNS and_CC a_DT tree_NN is_VBZgrown_VBN V_NNP times_NNS on_IN V-1_JJ blocks_NNS estimating_VBG the_DT error_NN by_IN testing_VBG the_DT model_NN on_IN the_DT remaining_VBGblock._NN In_IN this_DT case,_NN the_DT generalization_NN error_NN is_VBZ the_DT average_JJ error_NN made_VBN for_IN the_DT V_NNP runs._NNP The_DTestimation_NN of_IN αI_NNP is_VBZ achieved_VBN by_IN V-fold_NNP cross-validation:_, the_DT final_JJ choice_NN is_VBZ the_DT αˆ_NN minimizing_VBGthe_DT cross-validated_JJ R(T)_NN and_CC the_DT final_JJ tree_NN is_VBZ ˆTα_RB ._.Cappelli_NNP et_NNP al._. (2002)_WDT improved_VBD this_DT approach_NN introducing_VBG a_DT statistical_JJ testing_NN pruning_NN to_TOachieve_VB the_DT most_RBS reliable_JJ decision_NN rule_NN from_IN a_DT sequence_NN of_IN pruned_JJ trees._NN2.4_CD Regression_IN tree_NNIn_IN the_DT case_NN the_DT response_NN variable_NN is_VBZ numeric,_JJ the_DT outcome_NN of_IN a_DT recursive_JJ partitioning_NNalgorithm_NN is_VBZ regression_NN tree._NN Here,_IN the_DT splitting_JJ criterion_NN is_VBZ SSt-_NNP (SSl_NNP -_: SSr),_NN where_WRB SSt_NNP is_VBZ the_DTresidual_JJ sum_NN of_IN squares_NNS for_IN the_DT parent_NN node,_NN and_CC SSl_NNP and_CC SSr_NNP are_VBP the_DT residual_JJ sum_NN of_IN squares_NNSfor_IN the_DT left_JJ and_CC right_JJ son,_NN respectively._'' This_DT is_VBZ equivalent_JJ to_TO choosing_VBG the_DT splits_NNS maximizing_VBGthe_DT between-groups_NNS sum-of-squares_NNS in_IN a_DT simple_JJ analysis_NN of_IN variance._NN In_IN each_DT terminal_NN node,_NNthe_DT mean_JJ value_NN of_IN the_DT response_NN variable_JJ μy_NN of_IN cases_NNS belonging_VBG to_TO that_DT node_NN is_VBZ considered_VBN as_INthe_DT fitted_VBN value_NN whereas_IN the_DT variance_NN is_VBZ considered_VBN as_IN an_DT indicator_NN of_IN the_DT error_NN of_IN a_DT node._NN For_INa_DT new_JJ observation_NN ynew_IN the_DT prediction_NN error_NN is_VBZ (ynew_JJ -_: μy)._RP In_IN the_DT regression_NN tree_NN case,_NN cost-_NNScomplexity_NN pruning_NN is_VBZ applied_VBN with_IN the_DT sum_NN of_IN squares_NNS replacing_VBG the_DT misclassification_NN error._.2.5_CD DTI_NNP enhancements_NNSA_DT consolidated_JJ literature_NN about_IN the_DT incorporation_NN of_IN parametric_JJ and_CC nonparametric_JJ models_NNSinto_IN trees_NNS appeared_VBN in_IN recent_JJ years._NNP Several_JJ algorithms_NNS have_VBP been_VBN introduced_VBN as_IN hybrid_JJ or_CCfunctional_JJ trees_NNS (Gama,_JJ 2004),_CD among_IN the_DT machine_NN learning_VBG community._NN As_IN an_DT example,_NN DTI_.is_VBZ used_VBN for_IN regression_NN smoothing_NN purposes_NNS in_IN Conversano_NNP (2002):_IN a_DT novel_JJ class_NN of_INwww.intechopen.com_NNEvolutionary_JJ Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NN449_CDsemiparametric_JJ models_NNS named_VBN Generalized_NNP Additive_NNP Multi-Mixture_NNP Models_NNP (GAM-MM)._.Other_JJ hybrid_JJ approaches_NNS are_VBP presented_VBN in_IN Chan_NNP and_CC Loh_NNP (2004),_IN Su_NNP et_CC al._DT (2004),_IN Choi_NNP et_NNP al._.(2005)_JJ and_CC Hothorn_NNP et_NNP al._. (2006)._. Nevertheless,_RB relatively_RB simple_JJ procedures_NNS combining_VBG DTI_NNPmodels_NNS in_IN different_JJ ways_NNS have_VBP been_VBN proposed_VBN in_IN the_DT last_JJ decade_NN in_IN the_DT statistics_NNS and_CC machine_NNlearning_VBG literature_NN and_CC their_PRP$ effectiveness_NN in_IN improving_VBG the_DT predictive_JJ ability_NN of_IN the_DTtraditional_JJ DTI_NNP method_NN has_VBZ been_VBN proven_VBN in_IN different_JJ fields_NNS of_IN application._NNThe_DT first,_JJ rather_RB intuitive,_JJ approach_NN is_VBZ Tree_NNP Averaging._NNP It_PRP is_VBZ based_VBN on_IN the_DT generation_NN of_IN a_DT set_NNof_IN candidate_NN trees_NNS and_CC on_IN their_PRP$ subsequent_JJ aggregation_NN in_IN order_NN to_TO improve_VB their_PRP$generalization_NN ability._NN It_PRP requires_VBZ the_DT definition_NN of_IN a_DT suitable_JJ set_NN of_IN trees_NNS and_CC their_PRP$ associated_VBNweights_NNS and_CC classifies_VBZ a_DT new_JJ observation_NN by_IN averaging_VBG over_IN the_DT set_NN of_IN weighted_JJ trees_NNS (Oliver_.and_CC Hand,_NNP 1995)._VBD Either_NNP a_DT compromise_NN rule_NN or_CC a_DT consensus_NN rule_NN can_MD be_VB used_VBN for_IN averaging._VBGAn_DT alternative_JJ method_NN consists_VBZ in_IN summarizing_VBG the_DT information_NN of_IN each_DT tree_NN in_IN a_DT table_NN cross-_.classifying_VBG terminal_NN nodes_NNS outcomes_NNS with_IN the_DT response_NN classes_NNS in_IN order_NN to_TO assess_VB the_DTgeneralization_NN ability_NN through_IN a_DT statistical_JJ index_NN and_CC select_VB the_DT tree_NN providing_VBG the_DT maximum_NNvalue_NN of_IN such_JJ index_NN (Siciliano,_NN 1998)._.Tree_NNP Averaging_NNP is_VBZ very_RB similar_JJ to_TO Ensemble_NNP methods._, These_DT are_VBP based_VBN on_IN a_DT weighted_JJ or_CC non_JJweighted_JJ aggregation_NN of_IN single_JJ trees_NNS (the_VBD so_RB called_VBN weak_JJ learners)_NN in_IN order_NN to_TO improve_VB the_DToverall_JJ generalization_NN error_NN induced_VBN by_IN each_DT single_JJ tree._NN They_PRP are_VBP more_RBR accurate_JJ than_IN a_DTsingle_JJ tree_NN if_IN they_PRP have_VBP a_DT generalization_NN error_NN that_WDT is_VBZ lower_JJR than_IN random_JJ guessing_NN and_CC if_IN the_DTgeneralization_JJR errors_NNS of_IN the_DT different_JJ trees_NNS are_VBP uncorrelated_JJ (Dietterich,_NNS 2000)._.A_DT first_JJ example_NN of_IN Ensemble_NNP method_NN is_VBZ Bootstrap_NNP Aggregating,_NNP which_WDT is_VBZ also_RB called_VBN Bagging_.(Breiman,_IN 1996)._DT It_PRP works_VBZ by_IN randomly_RB replicating_VBG the_DT training_NN observations_NNS in_IN order_NN to_TOinduce_VB single_JJ trees_NNS whose_WP$ aggregation_NN by_IN majority_NN voting_NN provides_VBZ the_DT final_JJ classification._NNBagging_NN is_VBZ able_JJ to_TO improve_VB the_DT performance_NN of_IN unstable_JJ classifiers_NNS (i.e._. trees_NNS with_IN high_JJvariance)._DT Thus,_NNP bagging_NN is_VBZ said_VBN to_TO be_VB a_DT reduction_NN variance_NN method._VBNAdaptive_NNP Boosting,_NNP also_RB called_VBD AdaBoost_NNP (Freud_NNP &_CC Schapire,_NNP 1996)_CD is_VBZ an_DT Ensemble_NNP method_NNthat_WDT uses_VBZ iteratively_RB bootstrap_JJ replication_NN of_IN the_DT training_NN instances._NN At_IN each_DT iteration,_NNpreviously-misclassified_JJ observations_NNS receive_VBP higher_JJR probability_NN of_IN being_VBG sampled._VBN The_DT final_JJclassification_NN is_VBZ obtained_VBN by_IN majority_NN voting._NN Boosting_VBG forces_NNS the_DT decision_NN tree_NN to_TO learn_VB by_IN its_PRP$error,_NN and_CC is_VBZ able_JJ to_TO improve_VB the_DT performance_NN of_IN trees_NNS with_IN both_DT high_JJ bias_NN (such_RB as_IN single-_PRP$split_NN trees)_NN and_CC variance._NNFinally,_NNP Random_NNP Forest_NNP (Breiman,_NNP 2001)_CD is_VBZ an_DT ensemble_NN of_IN unpruned_JJ trees_NNS obtained_VBN by_INrandomly_RB resampling_VBG training_NN observations_NNS and_CC variables._VBZ The_DT overall_JJ performance_NN of_IN the_DTmethod_NN derives_NNS from_IN averaging_VBG the_DT generalization_NN errors_NNS obtained_VBN in_IN each_DT run._NNSimultaneously,_NNP suitable_JJ measures_NNS of_IN variables_NNS importance_NN are_VBP obtained_VBN to_TO enrich_VB the_DTinterpretation_NN of_IN the_DT model._NN3._DT Combinatorial_NNP optimization_NNCombinatorial_JJ Optimization_NN can_MD be_VB defined_VBN as_IN the_DT analysis_NN and_CC solution_NN of_IN problems_NNS that_WDTcan_MD be_VB mathematically_RB modelled_JJ as_IN the_DT minimization_NN (or_IN maximization)_NN of_IN an_DT objective_NNfunction_NN over_IN a_DT feasible_JJ space_NN involving_VBG mutually_RB exclusive,_JJ logical_JJ constraints._NN Such_JJ logical_JJconstraints_NNS can_MD be_VB seen_VBN as_IN the_DT arrangement_NN of_IN a_DT bunch_NN of_IN given_VBN elements_NNS into_IN sets._NN In_IN a_DTmathematical_JJ form:_NNS(_-LRB- ){_NN }min_NNT_NNP F_NNPTα∈_NN or_CC (_-LRB- ){_NN }maxT_NNP F_NNP Tα∈_NNP (10)_.www.intechopen.com_NNAdvances_NNS in_IN Evolutionary_NNP Algorithms_NNP450_CDwhere_WRB T_NNP can_MD be_VB seen_VBN as_IN an_DT arrangement,_NN F_NN is_VBZ the_DT collection_NN of_IN feasible_JJ arrangements_NNS and_CC α(T)_NNSmeasures_NNS the_DT value_NN of_IN the_DT members_NNS of_IN F._NNPCombinatorial_JJ Optimization_NN problems_NNS are_VBP of_IN great_JJ interest_NN because_IN many_JJ real_JJ life_NN decision-_.making_VBG situations_NNS force_NN people_NNS to_TO choose_VB over_IN a_DT set_NN of_IN possible_JJ alternatives_NNS with_IN the_DT aim_NN of_INmaximizing_VBG some_DT utility_NN function._NN On_IN the_DT one_CD hand,_NN the_DT discreteness_NN of_IN the_DT solutions_NNS space_NNoffers_VBZ the_DT great_JJ advantage_NN of_IN concreteness_NN and,_CC indeed,_NN elementary_JJ graphs_NNS or_CC similar_JJillustrations_NNS can_MD often_RB naturally_RB be_VB used_VBN to_TO represent_VB the_DT meaning_NN of_IN a_DT particular_JJ solution_NN to_TOa_DT problem._NN On_IN the_DT other_JJ end,_NNS those_DT problems_NNS carry_VBP a_DT heavy_JJ burden_NN in_IN terms_NNS of_INdimensionality._VBG If_IN more_JJR than_IN few_JJ choices_NNS are_VBP to_TO be_VB made,_VBN the_DT decision-making_JJ process_NN has_VBZ to_TOface_NN with_IN the_DT evaluation_NN of_IN a_DT terribly_RB big_JJ expanse_NN of_IN cases._NN This_DT dualism_NN (intuitive_JJ simplicity_NNof_IN presentation_NN of_IN a_DT solution_NN versus_IN complexity_NN of_IN solutions_NNS search)_NN has_VBZ made_VBN this_DT area_NN of_INcombinatorics_NNS attractive_JJ for_IN researchers_NNS from_IN many_JJ fields,_NNS ranging_VBG from_IN engineering_NN to_TOmanagement_NN sciences._NNElegant_JJ procedures_NNS to_TO find_VB optimal_JJ solutions_NNS have_VBP been_VBN found_VBN for_IN some_DT problems,_NN but_CC for_INmost_JJS of_IN them_PRP only_RB a_DT bunch_NN of_IN properties_NNS and_CC algorithms_NNS have_VBP been_VBN developed_VBN that_IN still_RB do_VBnot_RB allow_VB to_TO reach_VB a_DT complete_JJ resolution._NN This_DT is_VBZ the_DT case_NN of_IN Computational_NNP Statistics,_NNP in_INwhich_WDT computationally-intensive_JJ methods_NNS are_VBP used_VBN to_TO “mine“_VB large,_JJ heterogeneous,_NN multi-_.dimensional_JJ datasets_NNS in_IN order_NN to_TO discover_VB knowledge_NN in_IN the_DT data._NNTo_TO give_VB an_DT example,_NN the_DT objective_NN of_IN Cluster_NNP Analysis_NNP is_VBZ to_TO find_VB the_DT “best”_JJ partition_NN of_IN the_DTdataset_NN according_VBG to_TO some_DT criterion,_NN which_WDT is_VBZ always_RB expressed_VBN as_IN an_DT objective_JJ function._NN This_DTmeans_VBZ that_IN all_DT possible_JJ and_CC coherent_JJ partitions_NNS of_IN the_DT dataset_NN should_MD be_VB generated_VBN and_CC the_DTobjective_JJ function_NN has_VBZ to_TO be_VB calculated_VBN for_IN each_DT of_IN them._PRP$ In_IN many_JJ cases,_NNS the_DT number_NN of_INpossible_JJ partitions_NNS grows_VBZ too_RB rapidly_RB with_IN respect_NN to_TO the_DT number_NN of_IN units,_NNS making_VBG such_JJstrategy_NN practically_RB unfeasible._VBZ Another_DT example_NN is_VBZ the_DT apparently_RB simple_JJ problem_NN of_INcalculating_VBG the_DT variance_NN for_IN interval_NN data,_NNS for_IN which_WDT the_DT maximum_NN and_CC the_DT minimum_NN of_IN the_DTvariance_NN function_NN have_VBP to_TO be_VB searched_VBN over_IN the_DT multidimensional_JJ cube_NN defined_VBN by_IN all_PDT the_DTintervals_NNS in_IN which_WDT the_DT statistical_JJ units_NNS are_VBP defined._VBNThese_DT are_VBP examples_NNS of_IN statistical_JJ problems_NNS that_WDT cannot_MD be_VB faced_VBN with_IN the_DT total_JJ enumeration_NNand_CC evaluation_NN of_IN the_DT solutions._NN In_IN order_NN to_TO try_VB to_TO tackle_VB with_IN this_DT kind_NN of_IN problems,_NN a_DT lot_NN of_INtheory_NN has_VBZ been_VBN developed._VBN One_CD case_NN is_VBZ when_WRB some_DT properties_NNS about_IN the_DT objective_JJ function_NNare_VBP available._JJ These_DT allow_VBP to_TO calculate_VB some_DT kind_NN of_IN upper_JJ (or_NN lower)_JJ bound_VBN that_IN a_DT set_NN of_INpossible_JJ solutions_NNS could_MD admit._RP In_IN this_DT case,_NN the_DT search_NN could_MD be_VB performed_VBN just_RB on_IN the_DT set_NN of_INpossible_JJ solutions_NNS whose_WP$ upper_JJ bound_VBN is_VBZ higher._JJR If_IN one_CD solution_NN whose_WP$ effective_JJ value_NN is_VBZhigher_JJR than_IN the_DT bounds_NNS of_IN all_PDT the_DT other_JJ sets_NNS is_VBZ found,_VBN it_PRP would_MD not_RB be_VB necessary_JJ to_TO continue_VBthe_DT search,_NN being_VBG all_PDT the_DT other_JJ subsets_NNS not_RB able_JJ to_TO provide_VB better_JJR solutions._NN This_DT is_VBZ the_DT case_NN of_INthe_DT aforementioned_JJ problem_NN of_IN finding_VBG the_DT upper_JJ bound_JJ of_IN variance_NN for_IN interval_NN data,_NNSbecause_IN it_PRP can_MD be_VB verified_VBN that_IN the_DT maximum_NN is_VBZ necessarily_RB reached_VBN in_IN one_CD of_IN the_DT vertices_NNS of_INthe_DT multidimensional_JJ cube,_NN so_RB that_IN exploring_VBG the_DT whole_JJ cube_NN is_VBZ not_RB necessary._JJ Such_JJ a_DTsituation_NN allows_VBZ to_TO restrict_VB the_DT solutions_NNS space_NN to_TO a_DT set_NN of_IN 2n_CD possible_JJ solutions,_NN where_WRB n_NN is_VBZ the_DTnumber_NN of_IN statistical_JJ units._NN Unfortunately,_IN this_DT does_VBZ not_RB solve_VB the_DT problem_NN because_IN the_DTsolutions_NNS space_NN becomes_VBZ enormous_JJ even_RB in_IN presence_NN of_IN small_JJ datasets_NNS (with_IN just_RB 30_CD units_NNS the_DTnumber_NN of_IN solutions_NNS to_TO evaluate_VB is_VBZ greater_JJR than_IN one_CD thousand_CD millions)._.The_DT FAST_NNP algorithm_NN is_VBZ another_DT example_NN of_IN a_DT partial_JJ enumeration_NN approach,_NN in_IN which_WDT a_DTmeasure_NN of_IN the_DT upper_JJ bound_JJ of_IN the_DT predictive_JJ power_NN of_IN a_DT solutions_NNS set_NN is_VBZ defined_VBN and_CCexploited_VBN in_IN order_NN to_TO get_VB the_DT same_JJ results_NNS of_IN the_DT CART_NNP greedy_JJ approach_NN by_IN using_VBG a_DT reduced_VBNamount_NN of_IN computations._VBGwww.intechopen.com_NNEvolutionary_JJ Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NN451_CDAnother_DT way_NN to_TO proceed_VB is_VBZ to_TO make_VB use_NN of_IN non_JJ exact_JJ procedures,_NN often_RB called_VBN heuristics._.Those_DT algorithms_NNS do_VBP not_RB claim_VB to_TO find_VB the_DT global_JJ optimum,_NN but_CC are_VBP able_JJ to_TO converge_VB rapidly_RBtowards_IN a_DT local_JJ one._NNP Non_FW exact_JJ algorithms_NNS (that_WDT will_MD be_VB called_VBN heuristics_NNS in_IN the_DT rest_NN of_IN this_DTchapter)_NNS are_VBP certainly_RB not_RB recent._NNP What_WP has_VBZ changed,_VBN in_IN time,_NN is_VBZ the_DT respectability_NN associated_VBNto_TO them,_PRP due_JJ to_TO the_DT fact_NN that_IN many_JJ heuristics_NNS have_VBP been_VBN proved_VBN to_TO rival_VB their_PRP$ counterparts_NNS in_INelegance,_JJ sophistication_NN and,_CC particularly,_NN usefulness._. Many_JJ heuristics_NNS have_VBP been_VBN proposed_VBNin_IN the_DT literature,_NN but_CC only_RB two_CD kinds_NNS of_IN them_PRP will_MD be_VB briefly_RB described_VBN in_IN this_DT context_NN due_JJ to_TOtheir_PRP$ role_NN in_IN the_DT problems_NNS that_WDT will_MD be_VB faced_VBN in_IN the_DT next_JJ sections._NN These_DT are:_NNS Greedy_NNPprocedures_NNS and_CC Nature_NNP Inspired_NNP optimization_NN algorithms._. In_IN Greedy_JJ procedures_NNS the_DToptimization_NN process_NN selects,_VBN at_IN each_DT stage,_NN an_DT alternative_NN that_WDT is_VBZ the_DT best_JJS among_IN all_PDT the_DTfeasible_JJ alternatives_NNS without_IN taking_VBG into_IN account_NN the_DT impact_NN that_IN such_JJ choice_NN will_MD have_VB on_IN the_DTsubsequent_JJ decisions._, The_DT CART_NNP algorithm_NN makes_VBZ use_NN of_IN a_DT greedy_JJ procedure_NN to_TO grow_VB a_DT tree_NNin_IN which_WDT the_DT optimality_NN criterion_NN is_VBZ maximised_VBN just_RB locally,_VBN that_IN is,_NNS for_IN each_DT node_NN of_IN the_DT tree_NNbut_CC not_RB considering_VBG the_DT tree_NN as_IN a_DT whole._NN This_DT approach_NN clearly_RB results_VBZ in_IN a_DT suboptimal_NN tree_NNbut_CC allows,_RB at_IN least,_NNS to_TO obtain_VB a_DT tree_NN in_IN a_DT reasonable_JJ amount_NN of_IN time._NN Whereas,_IN the_DT so-called_JJNature_NN Inspired_NNP heuristics,_NN which_WDT are_VBP also_RB called_VBN “Heuristics_NNS from_IN Nature”_NNP (Colorni_NNP et_NNP al.,_.1993),_CD are_VBP Inspired_VBN by_IN natural_JJ phenomena_NNS or_CC behaviour_NN such_JJ as_IN Evolution,_NNP Ants,_NNP Honey-_.Bees,_NNP Immune_NNP systems,_NN Forests,_NNP etc._FW Some_DT important_JJ Nature_NN Inspired_VBN heuristics_NNS are:_.Simulated_NNP Annealing_NNP (SA),_NNP TABU_NNP Search_NNP (TS)_NNP algorithms,_IN Ant_NNP Colony_NNP Optimization_NNP (ACO)_.and_CC Evolutionary_NNP Computation_NNP (EC)._NNP ACO_NNP and_CC EC_NNP are_VBP described_VBN in_IN the_DT following_VBG since_IN they_PRPare_VBP used_VBN throughout_IN the_DT chapter._NNAnt_NNP Colony_NNP Optimization_NNP represents_VBZ a_DT class_NN of_IN algorithms_NNS that_WDT were_VBD inspired_VBN by_IN the_DTobservation_NN of_IN real_JJ ant_JJ colonies._NN Observation_NNP shows_VBZ that_IN a_DT single_JJ ant_NN only_RB applies_VBZ simple_NNrules,_NN has_VBZ no_DT knowledge_NN and_CC it_PRP is_VBZ unable_JJ to_TO succeed_VB in_IN anything_NN when_WRB it_PRP is_VBZ alone._RB However,_RBan_DT ant_JJ colony_NN benefits_NNS from_IN the_DT coordinated_JJ interaction_NN of_IN each_DT ant._NN Its_PRP$ structured_VBN behaviour,_NNdescribed_VBN as_IN a_DT “social_JJ life”,_NN leads_VBZ to_TO a_DT cooperation_NN of_IN independent_JJ searches_NNS with_IN high_JJprobability_NN of_IN success._NN ACO_NNP were_VBD initially_RB proposed_VBN by_IN Dorigo_NNP (1992)_CD to_TO attack_VB the_DT Traveling_VBGSalesman_NN Problem._NNP A_DT real_JJ ant_JJ colony_NN is_VBZ capable_JJ of_IN finding_VBG the_DT shortest_NN path_NN from_IN a_DT food_NNsource_NN to_TO its_PRP$ nest_NN by_IN using_VBG pheromone_NN information:_NN when_WRB walking,_NNS each_DT ant_NN deposits_VBZ a_DTchemical_NN substance_NN called_VBD pheromone_NN and_CC follows,_NN in_IN probability,_NNS a_DT pheromone_NN trail_NN already_RBdeposited_VBN by_IN previous_JJ ants._NN Assuming_VBG that_IN each_DT ant_NN has_VBZ the_DT same_JJ speed,_NN the_DT path_NN which_WDTends_VBZ up_RP with_IN the_DT maximum_JJ quantity_NN of_IN pheromone_NN is_VBZ the_DT shortest_NN one._.Evolutionary_JJ computation_NN (Fogel_NNP and_CC Fogel,_NNP 1993)_CD incorporates_VBZ algorithms_NNS that_WDT are_VBP inspired_VBNfrom_IN evolution_NN principles_NNS in_IN nature._NN The_DT methods_NNS of_IN evolutionary_JJ computation_NN algorithms_NNSare_VBP stochastic_JJ and_CC their_PRP$ search_NN methods_NNS imitate_VBP and_CC model_NN some_DT natural_JJ phenomena,_NNSnamely:_NN1._VBG the_DT survival_NN of_IN the_DT fittest_JJS2._DT genetic_JJ inheritance_NNEvolutionary_JJ computing_NN can_MD be_VB applied_VBN to_TO problems_NNS when_WRB it_PRP is_VBZ difficult_JJ to_TO apply_VB traditional_JJmethods_NNS (e.g.,_JJ when_WRB gradients_NNS are_VBP not_RB available)_JJ or_CC when_WRB traditional_JJ methods_NNS lead_JJ to_TOunsatisfactory_JJ solutions_NNS like_IN local_JJ optima_NNP (Fogel,_NNP 1997)._VBD Evolutionary_JJ algorithms_NNS work_VBP with_IN a_DTpopulation_NN of_IN potential_JJ solutions_NNS (i.e._. individuals)._NN Each_DT individual_NN is_VBZ a_DT potential_JJ solution_NN to_TOthe_DT problem_NN under_IN consideration_NN and_CC it_PRP is_VBZ encoded_VBN into_IN a_DT data_NNS structure_NN suitable_JJ to_TO the_DTproblem._NN Each_DT encoded_VBN solution_NN is_VBZ evaluated_VBN by_IN an_DT objective_JJ function_NN (environment)_NN in_INorder_NN to_TO measure_VB its_PRP$ fitness._NN The_DT bias_NN on_IN selecting_VBG high-fitness_NN individuals_NNS exploits_VBZ the_DTacquired_VBN fitness_NN information._NN The_DT individuals_NNS will_MD change_VB and_CC evolve_VB to_TO form_VB a_DT new_JJwww.intechopen.com_NNAdvances_NNS in_IN Evolutionary_NNP Algorithms_NNP452_CDpopulation_NN by_IN applying_VBG genetic_JJ operators._NNP Genetic_NNP operators_NNS perturb_VBP those_DT individuals_NNS in_INorder_NN to_TO explore_VB the_DT search_NN space._NN There_RB are_VBP two_CD main_JJ types_NNS of_IN genetic_JJ operators:_NN Mutation_NNand_CC Crossover._NNP Mutation_NNP type_NN operators_NNS are_VBP asexual_JJ (unary)_NN operators,_NNS which_WDT create_VBP new_JJindividuals_NNS by_IN a_DT small_JJ change_NN in_IN a_DT single_JJ individual._NN On_IN the_DT other_JJ hand,_NN Crossover_NNP type_NNoperators_NNS are_VBP multi-sexual_JJ (multary)_NN operators,_NNS which_WDT create_VBP new_JJ individuals_NNS by_IN combining_VBGparts_NNS from_IN two_CD or_CC more_JJR individuals._. As_RB soon_RB as_IN a_DT number_NN of_IN generations_NNS have_VBP evolved,_RB the_DTprocess_NN is_VBZ terminated_VBN according_VBG to_TO a_DT termination_NN criterion._NN The_DT best_JJS individual_NN in_IN the_DT final_JJstep_NN of_IN the_DT process_NN is_VBZ then_RB proposed_VBN as_IN a_DT (hopefully_RB suboptimal_JJ or_CC optimal)_JJ solution_NN for_IN the_DTproblem._NNEvolutionary_JJ computing_NN are_VBP further_RB classified_VBN into_IN four_CD groups:_NNS Genetic_JJ Algorithms_NNP (GA),_NNEvolutionary_JJ Programming,_NNP Evolution_NNP Strategies_NNP and_CC Genetic_NNP Programming._NNP Although_IN there_EXare_VBP many_JJ relevant_JJ similarities_NNS between_IN these_DT evolutionary_JJ computing_NN paradigms,_NNS profound_JJdifferences_NNS among_IN them_PRP also_RB emerge_VBP (Michalewicz,_JJ 1996)._. These_DT differences_NNS generally_RBinvolve_VB the_DT level_NN in_IN the_DT hierarchy_NN of_IN the_DT evolution_NN being_VBG modelled,_JJ that_IN is:_IN the_DT chromosome,_NNthe_DT individual_NN or_CC the_DT species._NN There_EX are_VBP also_RB many_JJ hybrid_JJ methods_NNS that_WDT combine_VBP various_JJfeatures_NNS from_IN two_CD or_CC more_JJR of_IN the_DT methods_NNS described_VBN in_IN this_DT section._NNGenetic_JJ Algorithms_NNP (GAs),_NN that_WDT will_MD be_VB used_VBN in_IN the_DT follwing,_NN are_VBP part_NN of_IN a_DT collection_NN of_INstochastic_JJ optimization_NN algorithms_NNS inspired_VBN by_IN the_DT natural_JJ genetics_NNS and_CC the_DT theory_NN of_IN the_DTbiological_JJ evolution._DT The_DT idea_NN behind_IN genetic_JJ algorithms_NNS is_VBZ to_TO simulate_VB the_DT natural_JJ evolution_NNwhen_WRB optimizing_VBG a_DT particular_JJ objective_NN function._NN GAs_NNP have_VBP emerged_VBN as_IN practical,_NN robust_JJoptimization_NN and_CC search_NN methods_NNS in_IN the_DT last_JJ three_CD decades._RP In_IN the_DT literature,_NN Hollands’_.genetic_JJ algorithm_NN is_VBZ called_VBN Simple_NNP Genetic_NNP Algorithm_NNP (Vose,_IN 1999)._DT It_PRP works_VBZ with_IN a_DTpopulation_NN of_IN individuals_NNS (chromosomes),_, which_WDT are_VBP encoded_VBN as_IN binary_JJ strings_NNS (genes)._.4._DT Genetic_JJ algorithms_NNS and_CC heuristics_NNS in_IN DTI_NNP4.1_CD Genetic_JJ algorithm_NN for_IN complex_JJ predictors_NNSThe_DT CART_NNP methodology_NN looks_VBZ for_IN the_DT best_JJS split_NN by_IN making_VBG use_NN of_IN a_DT brute-force_NN(enumerative)_NN procedure._NN All_RB the_DT possible_JJ splits_NNS from_IN all_PDT the_DT possible_JJ variables_NNS are_VBP generated_VBNand_CC evaluated._VBN Such_JJ a_DT procedure_NN must_MD be_VB performed_VBN anytime_RB a_DT node_NN has_VBZ to_TO be_VB split_VBN and_CC can_MDlead_NN to_TO computational_JJ problems_NNS when_WRB the_DT number_NN of_IN modalities_NNS grows._VBGLet_VB us_PRP first_RB consider_VBP how_WRB a_DT segmentation_NN procedure_NN generates_VBZ and_CC evaluates_VBZ all_DT possible_JJsplits._NN Nominal_NNP unordered_VBD predictors_NNS (Nup)_NNS are_VBP more_RBR complicated_JJ to_TO handle_VB than_IN ordered_VBNones_NNS because_IN the_DT number_NN of_IN possible_JJ splits_NNS that_WDT can_MD be_VB generated_VBN grows_VBZ exponentially_RB with_INthe_DT number_NN of_IN attributes_NNS m._RB The_DT number_NN of_IN possible_JJ splits_NNS is_VBZ (2m-1-1)._DT The_DT computational_JJcomplexity_NN of_IN a_DT procedure_NN that_WDT generates_VBZ and_CC evaluates_VBZ all_PDT the_DT splits_NNS from_IN a_DT nominal_JJunordered_JJ predictor_NN is_VBZ O(2n)._NNP In_IN this_DT respect,_NN it_PRP is_VBZ evident_JJ that_IN such_JJ enumerative_JJ algorithm_NNbecomes_VBZ prohibitive_JJ when_WRB the_DT number_NN of_IN attributes_NNS is_VBZ high._JJR This_DT is_VBZ one_CD of_IN the_DT reasons_NNS why_WRBsome_DT software_NN do_VBP not_RB accept_VB Nups_NNS with_IN a_DT number_NN of_IN attributes_NNS higher_JJR than_IN a_DT certain_JJthreshold_NN (usually_RB between_IN 12_CD and_CC 15)._VBGOne_CD of_IN the_DT possible_JJ way_NN to_TO proceed_VB is_VBZ to_TO make_VB use_NN of_IN a_DT heuristic_JJ procedure,_NN like_IN the_DT one_CDproposed_VBN in_IN this_DT section._NN In_IN order_NN to_TO design_VB a_DT Genetic_JJ Algorithm_NNP to_TO solve_VB such_JJ a_DTcombinatorial_JJ problem,_NN it_PRP is_VBZ necessary_JJ to_TO identify:_VB •_IN a_DT meaningful_JJ representation_NN (coding)_NN for_IN the_DT candidate_NN solutions_NNS (the_IN possible_JJ splits)_NN •_IN a_DT way_NN to_TO generate_VB the_DT initial_JJ population_NN •_VBD a_DT fitness_NN function_NN to_TO evaluate_VB any_DT candidate_NN solution_NNwww.intechopen.com_NNEvolutionary_JJ Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NN453_CD•_NNS a_DT set_NN of_IN useful_JJ genetic_JJ operators_NNS that_WDT can_MD efficiently_RB recombine_VB and_CC mutate_VB the_DT candidate_NNsolutions_NNS •_, the_DT values_NNS of_IN the_DT parameters_NNS used_VBN by_IN the_DT GA_NNP (population_NN size,_NN genetic_JJ operators_NNSparameters_NNS values,_NN selective_JJ pressure,_NN etc.);_VBD •_RP a_DT stopping_NN rule_NN for_IN the_DT algorithm._NNThe_DT aforementioned_JJ points_NNS have_VBP been_VBN tackled_VBN as_IN follows._VBG As_IN for_IN the_DT coding,_NN it_PRP has_VBZ been_VBNchosen_VBN the_DT following_VBG representation:_NN a_DT solution_NN is_VBZ coded_VBN in_IN a_DT string_NN of_IN bits_NNS (chromosomes)_.called_VBN x,_NN where_WRB each_DT bit_NN (gene)_, is_VBZ associated_VBN to_TO an_DT attribute_NN of_IN the_DT predictor_NN according_VBG to_TO the_DTfollowing_VBG rule:_NN0_CD1_CDi_FWif_IN i_PRP goes_VBZ to_TO left_NNx_NNif_IN i_PRP goes_VBZ to_TO right_RB⎧=_NN ⎨⎩_NN (11)_.The_DT choice_NN of_IN the_DT fitness_NN function_NN is_VBZ straightforward:_VBG the_DT split_NN evaluation_NN function_NN of_IN the_DTstandard_JJ recursive_JJ partitioning_NN algorithm_NN is_VBZ used_VBN (i.e._TO the_DT maximum_NN decrease_NN in_IN node_NNimpurity)._NN Since_IN the_DT canonical_JJ (binary)_NN coding_NN is_VBZ chosen,_VBN the_DT corresponding_JJ two_CD parents_NNSsingle-point_JJ crossover_NN and_CC mutation_NN operators_NNS and,_RB as_IN a_DT stopping_NN rule_NN can_MD be_VB used._VBN In_INaddition,_VBG a_DT maximum_JJ number_NN of_IN iterations_NNS is_VBZ chosen_VBN on_IN the_DT basis_NN of_IN empirical_JJ investigations._NNThe_DT rest_NN of_IN the_DT GA_NNP features_NNS are_VBP similar_JJ to_TO the_DT classic_JJ ones:_NN elitism_NN is_VBZ used_VBN (at_IN each_DT iteration_NNthe_DT best_JJS solution_NN is_VBZ kept_VBN in_IN memory)_NN and_CC the_DT initial_JJ population_NN is_VBZ chosen_VBN randomly._.4.2_CD An_DT ACO_NNP algorithm_NN for_IN exploratory_NN DTI_.When_WRB growing_VBG a_DT Classification_NN or_CC a_DT Regression_NNP Tree,_NNP CART_NNP first_RB grows_VBZ the_DT so-called_JJexploratory_NN tree._VBD Such_JJ tree_NN is_VBZ grown_VBN using_VBG data_NNS of_IN the_DT training_NN set._VBD Then,_RB it_PRP is_VBZ validated_VBN by_INusing_VBG the_DT test_NN set_NN or_CC by_IN cross-validation._NNIn_IN this_DT section,_NN the_DT attention_NN is_VBZ focused_VBN on_IN the_DT exploratory_NN tree-growing_NN procedure._NN In_IN this_DTphase,_NN in_IN theory,_VBG the_DT best_JJS possible_JJ tree_NN should_MD be_VB built,_VBN which_WDT is_VBZ the_DT tree_NN having_VBG the_DT lowest_JJSglobal_JJ impurity_NN measure_NN among_IN all_PDT the_DT generable_JJ trees._NN It_PRP has_VBZ been_VBN shown_VBN (Hyafil_JJ and_CCRivest,_NNP 1976)_CD that_IN constructing_VBG the_DT optimal_JJ tree_NN is_VBZ a_DT NP-Complete_JJ problem._NN In_IN other_JJ words,_NNin_IN order_NN to_TO use_VB a_DT polynomial_NN algorithm,_IN it_PRP is_VBZ only_RB possible_JJ to_TO get_VB suboptimal_JJ trees._NN For_IN such_PDT a_DTreason,_VB the_DT recursive_JJ partitioning_NN algorithms_NNS make_VBP use_NN of_IN greedy_JJ heuristics_NNS to_TO reach_VB a_DTcompromise_NN between_IN the_DT tree_NN quality_NN and_CC the_DT computational_JJ effort._NN In_IN particular,_DT most_JJS of_IN the_DTexisting_VBG methods_NNS for_IN DTI_NNP use_NN a_DT greedy_JJ heuristic,_NN which_WDT is_VBZ based_VBN on_IN a_DT top-down_JJ recursive_JJpartitioning_VBG approach_NN in_IN which,_CD any_DT time,_NN the_DT split_NN that_IN maximizes_VBZ the_DT one_CD step_NN impurity_NNdecrease_NN is_VBZ chosen._VBG This_DT kind_NN of_IN greedy_JJ approach,_NN that_IN splits_VBZ the_DT data_NNS locally_RB (i.e.,_, in_IN a_DT given_VBNnode)_NN and_CC only_RB once_RB for_IN each_DT node,_NN allows_VBZ to_TO grow_VB a_DT tree_NN in_IN a_DT reasonable_JJ amount_NN of_IN time._NN On_INthe_DT other_JJ hand,_NN this_DT rule_NN is_VBZ able_JJ to_TO generate_VB only_RB a_DT suboptimal_JJ tree_NN because_IN anytime_RB a_DT split_NN is_VBZchosen_VBN a_DT certain_JJ subspace_NN of_IN possible_JJ trees_NNS is_VBZ not_RB investigated_VBN anymore_RB by_IN the_DT algorithm._NN If_INthe_DT optimal_JJ tree_NN is_VBZ included_VBN in_IN one_CD of_IN those_DT subspaces_NNS there_EX is_VBZ no_DT chance_NN for_IN the_DT algorithm_NN of_INfinding_VBG it._PRP$Taking_VBG these_DT considerations_NNS into_IN account,_NN we_PRP propose_VBP an_DT Ant_NNP Colony_NNP Optimization_NNalgorithm_NN to_TO try_VB to_TO find_VB best_JJS exploratory_NN tree._NN In_IN order_NN to_TO attack_VB a_DT problem_NN with_IN ACO_NNP the_DTfollowing_VBG design_NN task_NN must_MD be_VB performed:_VBN1._PRP Represent_IN the_DT problem_NN in_IN the_DT form_NN of_IN sets_NNS of_IN components_NNS and_CC transitions_NNS or_CC by_IN means_NNS of_INa_DT weighted_JJ graph,_NN on_IN which_WDT ants_NNS build_VBP solutions_NNSwww.intechopen.com_NNAdvances_NNS in_IN Evolutionary_NNP Algorithms_NNP454_CD2._`` Appropriately_RB define_VB the_DT meaning_NN of_IN the_DT pheromone_NN trails:_NN that_WDT is,_VBZ the_DT type_NN of_IN decision_NNthey_PRP bias._MD3._`` Appropriately_RB define_VB the_DT heuristic_JJ reference_NN for_IN each_DT decision_NN an_DT ant_NN has_VBZ to_TO take_VB while_INconstructing_VBG a_DT solution._NN4._`` If_IN possible,_RB implement_VB an_DT efficient_JJ local_JJ search_NN algorithm_NN for_IN the_DT problem_NN to_TO be_VB solved._VBNThe_DT best_JJS results_NNS from_IN the_DT application_NN of_IN the_DT ACO_NNP algorithms_NNS to_TO NP-hard_NNP combinatorial_NNoptimization_NN problems_NNS are_VBP achieved_VBN by_IN coupling_VBG ACO_NNP with_IN local_JJ optimizers_NNS (Dorigo_.and_CC Stutzle,_NNP 2004)_CD5._PRP Choose_VB a_DT specific_JJ ACO_NNP algorithm_NN and_CC apply_VB it_PRP to_TO the_DT problem_NN to_TO be_VB solved,_VBN taking_VBG the_DTprevious_JJ issues_NNS into_IN account_NN6._CD Tune_NNP the_DT parameters_NNS of_IN the_DT ACO_NNP algorithm._NN A_DT good_JJ starting_NN point_NN is_VBZ to_TO use_VB parameter_NNsettings_NNS that_WDT were_VBD found_VBN to_TO be_VB good_JJ when_WRB applying_VBG the_DT same_JJ ACO_NNP algorithm_NN to_TO similar_JJproblems_NNS or_CC to_TO a_DT variety_NN of_IN other_JJ problems_NNSThe_DT most_RBS complex_JJ task_NN is_VBZ probably_RB the_DT first_JJ one,_NN in_IN which_WDT a_DT way_NN to_TO represent_VB the_DT problem_NN in_INthe_DT form_NN of_IN a_DT weighted_JJ graph_NN must_MD be_VB found._VBN We_PRP use_VBP a_DT representation_NN based_VBN on_IN the_DTfollowing_VBG idea:_NN let_VB us_PRP imagine_VB having_VBG two_CD nominal_JJ predictors_NNS P1_. =_SYM {a1,_CD b1,_CD c1}_JJ and_CC P2_JJ =_SYM {a2,_CD b2}_CDwith,_IN respectively,_JJ two_CD and_CC three_CD attributes._VBD Such_JJ simple_JJ predictors_NNS are_VBP considered_VBN only_RB to_TOexplain_VB the_DT idea,_NN because_IN of_IN the_DT combinatorial_JJ explosion_NN of_IN the_DT phenomenon._NN In_IN this_DT case,_NN the_DTset_NN of_IN all_DT possible_JJ splits,_NN at_IN a_DT root_NN node,_NN is_VBZ the_DT following:_JJ •_NN S1_IN =_SYM [a1]_CD −_CD [b1,_JJ c1]_JJ •_NN S2_. =_SYM [a1,_JJ b1]_JJ −_NN [c1]_IN •_NNP S3_NNP =_SYM [a1,_JJ c1]_JJ −_NN [b1]_IN •_NNP S4_NNP =_SYM [a2]_CD −_CD [b2]_.Any_DT time_NN a_DT split_NN is_VBZ chosen,_VBN it_PRP generates_VBZ two_CD child_NN nodes._NN For_IN such_JJ nodes,_NNS the_DT set_NN of_IN possible_JJsplits_VBZ is,_NNS in_IN the_DT worst_JJS case,_NN equal_JJ to_TO 3_CD (the_CD same_JJ as_IN the_DT parent_NN node_NN except_IN the_DT one_CD that_WDT was_VBDchosen_VBN for_IN splitting)._DT This_DT consideration_NN leads_VBZ to_TO the_DT representation_NN shown_VBN in_IN Figure_NN 1_CD in_INwhich,_NN for_IN simplicity,_RB only_RB the_DT first_JJ two_CD levels_NNS of_IN the_DT possible_JJ trees_NNS are_VBP considered._VBNIt_PRP is_VBZ easy_JJ to_TO imagine_VB how_WRB the_DT complexity_NN grows_VBZ when_WRB we_PRP deal_VBP with_IN predictors_NNS that_WDT generate_VBPhundreds_NNS or_CC even_RB thousands_NNS of_IN splits_NNS (which_WDT is_VBZ a_DT common_JJ case)._NNIn_IN Figure_NN 1,_IN the_DT space_NN of_IN all_DT possible_JJ trees_NNS is_VBZ represented_VBN by_IN a_DT connected_JJ graph._NN Moving_VBG from_INa_DT level_NN to_TO another_DT one_CD corresponds_NNS to_TO split_VB a_DT variable._JJ The_DT arcs_NNS of_IN such_JJ a_DT graph_NN have_VBP the_DT same_JJmeaning_NN of_IN the_DT arcs_NNS of_IN the_DT TSP_NNP graph_NN (transition_NN from_IN a_DT state_NN to_TO another_DT one_CD or,_NN even_RB better,_RBRaddition_NN of_IN a_DT component_NN to_TO a_DT partial_JJ solution)._NN In_IN this_DT view,_NN it_PRP would_MD be_VB correct_JJ to_TO deposit_NNpheromone_NN on_IN them._PRP The_DT pheromone_NN trails_VBZ meaning,_VBN in_IN this_DT case,_NN corresponds_NNS to_TO the_DTdesirability_NN to_TO choose_VB the_DT corresponding_JJ split_NN from_IN a_DT certain_JJ node._NNAs_IN for_IN the_DT heuristic_JJ information,_NN it_PRP is_VBZ possible_JJ to_TO refer_VB to_TO the_DT decrease_NN in_IN impurity_NN deriving_VBGfrom_IN adding_VBG the_DT corresponding_JJ node_NN to_TO the_DT tree._NN Such_JJ a_DT measure_NN has_VBZ a_DT meaning_NN which_WDT is_VBZsimilar,_NNS in_IN some_DT way,_NN to_TO the_DT one_CD that_IN visibility_NN has_VBZ in_IN the_DT TSP_NNP ._. An_DT arc_NN is_VBZ much_RB more_RBR desirable_JJas_IN higher_JJR the_DT impurity_NN decrease_NN is._VBZ As_IN a_DT result,_NN to_TO make_VB analogies_NNS with_IN the_DT TSP,_NNS such_JJimpurity_NN decrease_NN can_MD be_VB seen_VBN as_IN an_DT inverse_JJ measure_NN of_IN the_DT distance_NN between_IN two_CD nodes._NNOnce_RB the_DT construction_NN graph_NN has_VBZ been_VBN built,_VBN and_CC pheromone_NN trails_NNS meaning_NN and_CC heuristic_NNfunction_NN have_VBP been_VBN defined,_VBN it_PRP is_VBZ possible_JJ to_TO attack_VB that_DT problem_NN using_VBG an_DT ACO_NNP algorithm._. It_PRPis_VBZ important_JJ to_TO note_VB that,_IN because_IN of_IN the_DT specificity_NN of_IN the_DT problem_NN to_TO be_VB modelled_JJ (ants_NNS can_MDmove_NN into_IN a_DT connected_JJ graph_NN and_CC there_EX is_VBZ a_DT measure_NN of_IN “visibility”),_VBG the_DT search_NN of_IN the_DT best_JJStree_NN can_MD be_VB seen_VBN as_IN a_DT shortest_NN path_NN research,_NNS like_IN in_IN TSP._NNP In_IN the_DT latter,_JJ ants_NNS are_VBP forced_VBN to_TO pass_VBonly_RB one_CD time_NN for_IN each_DT city_NN while,_, in_IN our_PRP$ case,_NN ants_NNS are_VBP forced_VBN to_TO choose_VB paths_NNS that_WDTwww.intechopen.com_NNEvolutionary_JJ Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NN455_CDcorrespond_NN to_TO binary_JJ trees,_NN since_IN the_DT solutions_NNS to_TO build_VB must_MD be_VB in_IN the_DT form_NN of_IN tree_NN structures._WPAll_PDT the_DT ants_NNS will_MD start_VB from_IN the_DT root_NN node_NN and_CC will_MD be_VB forced_VBN to_TO move_VB from_IN one_CD node_NN to_TOanother_DT in_IN order_NN to_TO build_VB a_DT tour_NN that_IN corresponds_NNS to_TO a_DT tree._NNFig._NNP 1._VBD An_DT example_NN of_IN ACO_NNP algorithm_NN for_IN exploratory_NN DTI:_IN each_DT path_NN corresponds_VBZ to_TO a_DT 2-_CDlevels_NNS tree._NNIt_PRP is_VBZ important_JJ to_TO notice_VB the_DT basics_NNS of_IN the_DT ant_JJ moves_NNS in_IN the_DT graph_NN shown_VBN in_IN Figure_NN 1._. At_IN each_DTstep,_VB the_DT ant_JJ looks_NNS for_IN the_DT heuristic_JJ information_NN (impurity_NN decrease)_NN and_CC the_DT pheromone_NN trail_NNof_IN any_DT possible_JJ direction_NN and_CC decides_VBZ for_IN the_DT one_CD to_TO choose_VB (and,_NNP therefore,_, the_DT associated_VBNsplit)_NN on_IN the_DT basis_NN of_IN the_DT selected_VBN ACO_NNP algorithm._NN Once_RB the_DT ant_JJ arrives_VBZ to_TO a_DT terminal_NN node,_NN it_PRPrecursively_RB starts_VBZ to_TO move_VB back_RB to_TO the_DT other_JJ unexplored_JJ nodes._NNIn_IN different_JJ ACO_NNP algorithms,_NN pheromone_NN trails_NNS are_VBP initialized_VBN to_TO a_DT value_NN obtained_VBN by_INmanipulating_VBG the_DT quality_NN measure_NN (the_RB path’s_JJ length_NN for_IN the_DT TSP_NNP case)_NN of_IN a_DT solution_NN obtained_VBNwith_IN another_DT heuristic_JJ (Dorigo_NN suggests_VBZ the_DT nearest-neighbour_NN heuristic)._. In_IN our_PRP$ case,_NN the_DTgreedy_JJ tree_NN induction_NN rule_NN solution_NN quality_NN is_VBZ used._VBN Elitism_NNP will_MD also_RB be_VB implemented_VBN and_CC the_DTchosen_VBN parameters_NNS (due_VBP to_TO the_DT strong_JJ similarity_NN with_IN TSP)_NNP are_VBP the_DT same_JJ that_IN have_VBP been_VBN used_VBNsuccessfully_RB for_IN the_DT TSP_NNP problem._NN4.3_CD Identification_NN of_IN a_DT parsimonious_JJ set_NN of_IN decision_NN trees_NNS in_IN multi-class_JJ classification_NNIn_IN many_JJ situations,_VBP the_DT response_NN variable_JJ used_VBN in_IN classification_NN tree_NN modelling_NN rarely_RBpresents_NNS a_DT number_NN of_IN attributes_NNS that_WDT allow_VBP to_TO apply_VB the_DT recursive_JJ partitioning_NN algorithm_NN in_INthe_DT most_RBS accurate_JJ manner._NNIt_PRP is_VBZ well_RB known_VBN that:_INa)_IN a_DT multi-class_JJ response,_NN namely_RB a_DT nominal_JJ variables_NNS with_IN several_JJ classes,_NNS usually_RB causes_NNSprediction_NN inaccuracy;_NNwww.intechopen.com_NNAdvances_NNS in_IN Evolutionary_NNP Algorithms_NNP456_CDb)_NN multi-class_JJ and_CC numeric_JJ predictors_NNS play_VBP often_RB the_DT role_NN of_IN splitting_JJ variables_NNS in_IN the_DT tree_NNgrowing_VBG process_NN in_IN disadvantage_NN of_IN two-classes_NNS ones,_IN causing_VBG selection_NN bias._.To_TO account_VB for_IN the_DT problems_NNS deriving_VBG from_IN the_DT prediction_NN inaccuracy_NN of_IN tree-based_JJ classifiers_NNSgrown_VBN for_IN multi-class_JJ response,_NN as_RB well_RB as_IN to_TO reduce_VB the_DT drawback_NN of_IN the_DT loss_NN of_INinterpretability_NN induced_VBN by_IN ensemble_JJ methods_NNS in_IN these_DT situations,_NNS Mola_NNP and_CC Conversano_NNP(2008)_NN introduced_VBD an_DT algorithm_NN based_VBN on_IN a_DT Sequential_JJ Automatic_NNP Search_NNP of_IN a_DT Subset_NNP of_IN Classifiers_NNS(SASSC)._NNP It_PRP produces_VBZ a_DT partition_NN of_IN the_DT set_NN of_IN the_DT response_NN classes_NNS into_IN a_DT reduced_JJ number_NN of_INdisjoint_NN subgroups_NNS and_CC introduces_VBZ a_DT parameter_NN in_IN the_DT final_JJ classification_NN model_NN that_WDTimproves_VBZ its_PRP$ prediction_NN accuracy,_NN since_IN it_PRP allows_VBZ to_TO assign_VB each_DT new_JJ observation_NN to_TO the_DT most_RBSappropriate_JJ classifier_NN in_IN a_DT previously-identified_JJ reduced_JJ set_NN of_IN classifiers._NN It_PRP uses_VBZ a_DT data-_NNSdriven_VBN heuristic_JJ based_VBN on_IN cross-validated_JJ classification_NN trees_NNS as_IN a_DT tool_NN to_TO induce_VB the_DT set_NN of_INclassifiers_NNS in_IN the_DT final_JJ classification_NN model._.SASSC_NNP produces_VBZ a_DT partition_NN of_IN the_DT set_NN of_IN the_DT response_NN classes_NNS into_IN a_DT reduced_JJ number_NN of_INsuper-classes._NN It_PRP is_VBZ applicable_JJ to_TO a_DT dataset_NN X_NNP composed_VBD of_IN N_NNP observations_NNS characterized_VBD by_IN a_DTset_NN of_IN J_NNP (numeric_NNP or_CC nominal)_RB splitting_JJ variables_NNS xj_VBP (j=1,…..,J)_JJ and_CC a_DT response_NN variable_JJ y_NNpresenting_VBG K_NNP classes._NN Such_JJ response_NN classes_NNS identify_VBP the_DT initial_JJ set_NN of_IN classes_NNS C(0)_. =(c1,c2,….,cK)._.Partitioning_VBG X_NNP with_IN respect_NN to_TO C(0)_VB allows_VBZ to_TO identify_VB K_NNP disjoint_NN subsets_NNS X(0)k,_IN such_JJ that:_IN X(0)k_NNP =_SYM{xs_NNS :_: ys_NNS ∈_VBP ck},_VBN with_IN s=1,…..,N._PRP In_IN practice,_JJ X(0)k_NNP is_VBZ the_DT set_NN of_IN observations_NNS presenting_VBG the_DT k-th_NNclass_NN of_IN y._NNP The_DT algorithms_NNS works_VBZ by_IN aggregating_VBG the_DT K_NNP classes_NNS in_IN pairs_NNS and_CC learns_VBZ a_DT classifier_NNto_TO each_DT subset_NN of_IN corresponding_JJ observations._NNP The_DT “best”_JJ aggregation_NN (super-class)_NN is_VBZ chosen_VBNas_IN the_DT one_CD minimizing_VBG the_DT generalization_NN error_NN estimated_VBN using_VBG V-fold_JJ cross-validation._NNSuppose_VB that,_NN in_IN the_DT A-th_JJ iteration_NN of_IN the_DT algorithm_NN such_JJ a_DT best_JJS aggregation_NN is_VBZ found_VBN for_IN the_DTpair_NN of_IN classes_NNS ci*_JJ and_CC cj*_JJ (with_IN i*≠_JJ j_NN and_CC i*,_JJ j*_NN ∈_NN (1,….,K))_IN that_WDT allows_VBZ to_TO aggregate_VB the_DT subsets_NNSXi*_NNP and_CC Xj*._NNP Denoting_NNP with_IN T(i*,j*)_NNP the_DT decision_NN tree_NN minimizing_VBG the_DT cross-validated_JJgeneralization_NN error_NN δ(A)cv,_IN the_DT heuristic_JJ for_IN selecting_VBG the_DT “best”_JJ decision_NN tree_NN can_MD be_VB formalized_VBNas_IN follows:_NN(_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )(_NN ){_NN },_.(_-LRB- ,_, )_-RRB-*,_NN *_NNS arg_VBP min_NN |cv_NN i_IN ji_RB j_RBi_NN j_NNi_PRP j_RB Tδ=_NNP ∩X_NNP XA_NNP (12)_.The_DT SACCS_NNP algorithm_NN is_VBZ analytically_RB described_VBN in_IN Table_NN 1._. It_PRP proceeds_VBZ by_IN learning_VBG all_PDT the_DTpossible_JJ decision_NN trees_NNS obtainable_VBN by_IN joining_VBG in_IN pairs_NNS the_DT K_NNP subgroups,_NN and_CC by_IN retaining_VBG the_DTone_CD satisfying_VBG the_DT selection_NN criteria_NNS introduced_VBN in_IN (12)._NNP After_IN the_DT A-th_NN aggregation,_IN the_DTnumber_NN of_IN subgroups_NNS is_VBZ reduced_VBN to_TO K(A-1)_JJ -_: 1,_CD since_IN the_DT subgroups_NNS of_IN observations_NNS presenting_VBGthe_DT response_NN classes_NNS ci*_NNS and_CC cj*_NNS are_VBP discarded_VBN from_IN the_DT original_JJ partition_NN and_CC replaced_VBN by_IN the_DTsubset_NN X(A)(i*,j*)_NNP =_SYM X(i*)_NNP ∩_JJ X(j*)_NNP identified_VBN by_IN the_DT super-class_NN c(A)_NN =_SYM (c(i*)_FW ∩_NNP c(j*))._VBD The_DT initial_JJ set_NN of_INclasses_NNS C_NNP is_VBZ replaced_VBN by_IN C(A),_NNS the_DT latter_NN being_VBG composed_VBN of_IN a_DT reduced_JJ number_NN of_IN classes_NNS since_INsome_DT of_IN the_DT original_JJ classes_NNS form_VBP the_DT superclasses_NNS coming_VBG out_RB from_IN the_DT A_NNP aggregations._.Likewise,_NN also_RB X(A)k_RB is_VBZ formed_VBN by_IN a_DT lower_JJR number_NN of_IN subsets_NNS as_IN a_DT consequence_NN of_IN the_DT A_NNPaggregations._.The_DT algorithm_NN proceeds_VBZ sequentially_RB in_IN the_DT iteration_NN A+1_. by_IN searching_VBG for_IN the_DT most_JJS accurate_JJdecision_NN tree_NN over_IN all_DT the_DT possible_JJ ones_NNS obtainable_VBN by_IN joining_VBG in_IN pairs_NNS the_DT K(A)_NNP subgroups._VBD The_DTsequential_JJ search_NN is_VBZ repeated_VBN until_IN the_DT number_NN of_IN subgroups_NNS reduces_VBZ to_TO one_CD in_IN the_DT K-th_NNwww.intechopen.com_NNEvolutionary_JJ Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NN457_CDiteration._PRP The_DT decision_NN tree_NN learned_VBN on_IN the_DT last_JJ subgroup_NN corresponds_NNS to_TO the_DT one_CD obtainable_NNapplying_VBG the_DT recursive_JJ partitioning_NN algorithm_NN on_IN the_DT original_JJ dataset._NNThe_DT output_NN of_IN the_DT procedure_NN is_VBZ a_DT sequence_NN of_IN sets_NNS of_IN response_NN classes_NNS C(1),….,C(K−1)_JJ with_IN the_DTassociated_VBN sets_NNS of_IN decision_NN trees_NNS T(1)_JJ ,…..,T(K−1)._. The_DT latter_NN are_VBP derived_VBN by_IN learning_VBG K_NNP −_NNP k_NN trees_NNS(k_NN =_SYM 1,_CD …..,_, K_NNP −_NNP 1)_VBD on_IN disjoint_JJ subgroups_NNS of_IN observations_NNS whose_WP$ response_NN classes_NNS complete_JJ the_DTinitial_JJ set_NN of_IN classes_NNS C(0):_IN these_DT response_NN classes_NNS identify_VBP the_DT super-classes_NNS relating_VBG to_TO the_DT sets_NNSof_IN classifiers_NNS T(k)._. An_DT overall_JJ generalization_NN error_NN is_VBZ associated_VBN to_TO each_DT T(k):_NN such_JJ an_DT error_NN is_VBZalso_RB based_VBN on_IN V-fold_NNP cross-validation_NN and_CC it_PRP is_VBZ computed_VBN as_IN a_DT weighted_JJ average_NN of_IN the_DTgeneralization_JJR errors_NNS obtained_VBN from_IN each_DT of_IN the_DT K_NNP −_NNP k_NN decision_NN trees_NNS composing_VBG the_DT set._NN In_INaccordance_NN to_TO the_DT previously_RB introduced_VBN notation,_, the_DT overall_JJ generalization_NN errors_NNS can_MD be_VBdenoted_VBN as_IN Θ(1)cv,_JJ ……,_NN Θ(k)cv,…….,_IN Θ(K-1)cv_NNP ._. Of_IN course,_NN by_IN decreasing_VBG the_DT number_NN of_IN trees_NNScomposing_VBG a_DT sequence_NN T(k)_NN (that_IN is,_NNS when_WRB moving_VBG k_NN from_IN 1_CD to_TO K−1)_VB the_DT corresponding_JJ Θ(k)cv_NNincreases_NNS since_IN the_DT number_NN of_IN super-classes_NNS associated_VBN to_TO T(k)_NNP is_VBZ also_RB decreasing._VBG This_DT means_NNSthat_IN a_DT lower_JJR number_NN of_IN trees_NNS are_VBP learned_VBN on_IN more_JJR heterogeneous_JJ subsets_NNS of_IN observations,_NNsince_IN each_DT of_IN those_DT subsets_NNS pertain_VBP to_TO a_DT relatively_RB large_JJ number_NN of_IN response_NN classes._.{_NN }_NN (_-LRB- )(_NN )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- {_NN }_NN(_-LRB- )_-RRB- {_NN }_NN (_-LRB- )_-RRB- (_-LRB- )(_JJ )(_NN )_-RRB- (_-LRB- )(_NN )_-RRB- (_-LRB- )_-RRB- (_-LRB- ){_JJ }(_NN )_-RRB- {_NN }_JJ (_-LRB- )_-RRB-(_-LRB- )_-RRB-1_CD ;_: ;_: ,_, 1,_CD ,_,00_CD 0_CD1,_CD ,_, ;_: 1,_CD ,_,*_JJ *_NNS *_IN **,_NN *_.1_CD1_CD 2_CD 1_CD1,_CD ,_, 1_CD1_CD,_, ,_,;_: ;_: :_:1_CD:_: |_NN min_NN1_CD,_, ,_,:_:,_,i_NN j_NNK_NNP c_NN c_NN i_IN j_NNS i_IN j_NN K_NNPs_PRP s_VBZ kk_CC s_VBZ N_NNP k_NN K_NNPi_FW j_NN cv_NN i_IN ji_RB j_RBK_NNPs_PRP s_VBZ kk_NN k_NN K_NNPC_NNP c_NN c_NNSC_NNP C_NNP K_NNP K_NNP y_NNP c_NNK_NNPc_NN c_NN c_NNS T_WDTK_NNP K_NNPC_NNP c_NN c_NN c_NNSy_NN c_NNSC_LSθ_NN∩_JJ =∅_NN ≠_NN ∈_.=_SYM =_SYM−_NN−_NN +_NN=_SYM −_NN=_SYM=_SYM =_SYM =_SYM ∈_.=_SYM ∩_JJ ∩_NN =_SYM=_SYM −=_NN =_SYM=_SYM ∈_NNInput:_.Set:_NNP X_NNP x_NNFor:_NNP in_IN to_TOX_NNP X_NNPX_NNP x_NNend_NN For_INOutput:_NNSA_DTA_DT…_NN…_NN …_NNA_DT A_NNA_DT A_NNA_DT A_NNA_DT…_NN…_NNA_DT…_NN…_JJ (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )_-RRB- (_-LRB- )1_CD 1_CD 11_CD 1,_CD ;_: ,_, ,_, ;_: ,_, ,K_NNP Kcv_NNP cvKC_IN T_NNP T−_NNP −−_NNP Θ_NNP Θ_NNP …_NNP …_.Table_NN 1._VBZ The_DT SASSC_NNP algorithm_NNTaking_VBG this_DT inverse_NN relationship_NN into_IN account,_VBG the_DT analyst_NN can_MD be_VB aware_JJ of_IN the_DT overall_JJprediction_NN accuracy_NN of_IN the_DT final_JJ model_NN on_IN the_DT basis_NN of_IN the_DT relative_JJ increase_NN in_IN Θ(k)cv_NN when_WRBmoving_VBG from_IN 1_CD to_TO K−1._NNP In_IN this_DT respect,_NN he_PRP can_MD select_VB the_DT suitable_JJ number_NN of_IN decision_NN trees_NNS to_TObe_VB included_VBN in_IN the_DT final_JJ classification_NN model_NN accordingly._VBD Supposing_VBG that_IN a_DT final_JJ subset_NN of_IN g_VBGdecision_NN trees_NNS has_VBZ been_VBN selected_VBN (g<<K−1),_IN the_DT estimated_VBN classification_NN model_NN can_MD be_VBrepresented_VBN as:_NN(_-LRB- )_-RRB- (_-LRB- )(_NN )1_NN ,_, 1_CD1_CD 1_CDˆ_JJ ˆ_JJ ˆ_NN ,_, ,_,i_FWi_FWi_FWMg_.i_FW k_FW i_FW p_NN m_NNi_NN m_NNf_NN c_NN I_PRP x_SYM x_NN Rψ−=_NNP ==_NNP ∈∑∑x_NNP …_NNP (13)_.The_DT parameter_NN ψ_NN is_VBZ called_VBN “vehicle_NN parameter”._NN It_PRP allows_VBZ to_TO assign_VB a_DT new_JJ observation_NN to_TO the_DTmost_RBS suitable_JJ decision_NN tree_NN in_IN the_DT subset_NN g._NNP It_PRP is_VBZ defined_VBN by_IN a_DT set_NN of_IN g−1_DT dummy_JJ variables._NNEach_DT of_IN them_PRP equals_VBZ 1_CD if_IN the_DT object_NN belongs_VBZ to_TO the_DT i-th_JJ decision_NN tree_NN (i_WP =_SYM 1,…,_CD g−1)_CD and_CC zero_CDotherwise._DT The_DT Mi_NNP regions,_NN corresponding_JJ to_TO the_DT number_NN of_IN terminal_JJ nodes_NNS of_IN the_DT decision_NNwww.intechopen.com_NNAdvances_NNS in_IN Evolutionary_NNP Algorithms_NNP458_CDtree_NN i,_NN are_VBP created_VBN by_IN splits_NNS on_IN predictors_NNS (x1,….,xp)._. The_DT classification_NN tree_NN i_NN assigns_VBZ a_DT new_JJobservation_NN to_TO the_DT class_NN ,ˆk_NN ic_NN of_IN y_NN according_VBG to_TO the_DT region_NNi_FWmR_NN ._. I_PRP is_VBZ an_DT indicator_NN function_NN with_INvalue_NN 1_CD if_IN an_DT observation_NN belongs_VBZ to_TOi_FWmR_NN and_CC value_NN 0_IN if_IN not._NNi_FWmR_NN is_VBZ defined_VBN by_IN the_DT inputs_NNSused_VBN in_IN the_DT splits_NNS leading_VBG to_TO that_DT terminal_NN node._VBZ The_DT modal_JJ class_NN of_IN the_DT observations_NNS in_IN a_DTregion_NNi_FWmR_NN (also_RB called_VBD the_DT m-th_JJ terminal_NN node_NN of_IN the_DT i-th_JJ decision_NN tree)_NN is_VBZ usually_RB taken_VBN as_IN an_DTestimate_NN for_IN ,ˆk_NNP ic_JJ ._. This_DT notation_NN is_VBZ consistent_JJ with_IN that_DT used_VBN in_IN Hastie_NNP et_NNP al._. (2001)._.The_DT estimation_NN of_IN τi_NNP is_VBZ based_VBN on_IN the_DT prediction_NN accuracy_NN of_IN each_DT decision_NN tree_NN in_IN the_DT final_JJsubset_NN g._NNP A_DT new_JJ observation_NN is_VBZ slipped_VBN into_IN each_DT of_IN the_DT g_NN trees._, The_DT assigned_VBN class_NN ,ˆk_NN ic_NN is_VBZfound_VBN with_IN respect_NN to_TO the_DT tree_NN whose_WP$ terminal_NN node_NN better_RB classifies_VBZ the_DT new_JJ observation._NN In_INother_JJ words,_NNS a_DT new_JJ observation_NN is_VBZ assigned_VBN to_TO the_DT purest_NN terminal_NN node_NN among_IN all_PDT the_DT g_NNdecision_NN trees._NNAnother_DT option_NN of_IN the_DT algorithm_NN is_VBZ the_DT possibility_NN to_TO learn_VB decision_NN trees_NNS to_TO select_VB the_DT suitable_JJpair_NN of_IN response_NN classes_NNS satisfying_VBG (12)_IN using_VBG alternative_NN splitting_JJ criteria._NN As_IN for_IN CART,_NNP it_PRP is_VBZpossible_JJ to_TO refer_VB to_TO both_DT the_DT Gini_NNP index_NN and_CC Twoing_NNP as_IN alternative_JJ splitting_JJ rules._NN It_PRP is_VBZ known_VBNthat,_DT unlike_IN Gini_NNP rule,_NN Twoing_VBG searches_NNS for_IN the_DT two_CD classes_NNS that_WDT make_VBP up_RP together_RB more_JJR than_IN50%_CD of_IN the_DT data_NNS and_CC allows_VBZ us_PRP to_TO build_VB more_JJR balanced_VBN trees_NNS even_RB if_IN the_DT resulting_VBG recursive_JJpartitioning_VBG algorithm_NN works_NNS slower._. As_IN an_DT example,_NN if_IN the_DT total_JJ number_NN of_IN classes_NNS is_VBZ equal_JJto_TO K,_NNP Twoing_NNP uses_VBZ 2K−1_CD possible_JJ splits._NN Since_IN it_PRP has_VBZ been_VBN proved_VBN (Breiman_NNP et_NNP al.,_RB 1984,_CD pag.95)_NNthat_IN the_DT decision_NN tree_NN is_VBZ insensitive_JJ to_TO the_DT choice_NN of_IN the_DT splitting_JJ rule,_NN it_PRP can_MD be_VB interesting_JJ to_TOsee_VB how_WRB it_PRP works_VBZ in_IN a_DT framework_NN characterized_VBN by_IN the_DT search_NN of_IN the_DT most_RBS accurate_JJ decision_NNtreers_NNS like_IN the_DT one_CD introduced_VBN in_IN SASSC._NNP5._DT Application_NNP on_IN real_JJ and_CC simulated_VBN datasets_NNSGenetic_NNP Algorithm._NNP The_DT proposed_VBN GA_NNP has_VBZ been_VBN applied_VBN on_IN two_CD datasets_NNS for_IN which_WDT the_DToptimal_JJ best_JJS split_NN could_MD be_VB calculated_VBN and_CC for_IN a_DT more_RBR complex_JJ one,_NNS for_IN which_WDT it_PRP is_VBZ not_RBpossible_JJ to_TO proceed_VB with_IN such_JJ a_DT brute_NN force_NN strategy._.The_DT first_JJ test_NN has_VBZ been_VBN done_VBN on_IN the_DT “Mushroom”_JJ dataset,_NNS available_JJ from_IN the_DT UCI_NNP Machine_NNLearning_VBG Repository_NNP (source_NNP http://archive.ics.uci.edu/ml/)._'' This_DT dataset_NN has_VBZ a_DT two-class_JJresponse_NN variable_JJ (“is_IN the_DT mushroom_NN poisonous?”)_NN and_CC set_NN of_IN categorical_JJ and_CC numerical_JJpredictors._VBG One_CD of_IN them_PRP (gill_, colour)_NN has_VBZ 12_CD categories_NNS (attributes),_, which_WDT can_MD be_VB evaluated_VBNexhaustively._VBG The_DT GA_NNP algorithm_NN could_MD find_VB the_DT global_JJ best_JJS solution_NN (which_WDT was_VBD extracted_VBN by_INusing_VBG the_DT Rpart_NN package_NN of_IN the_DT R_NN software)_NN in_IN less_JJR than_IN 10_CD iterations._, The_DT algorithm_NN has_VBZ then_RBbeen_VBN tested_VBN on_IN a_DT simulated_JJ dataset_NN which_WDT was_VBD obtained_VBN by_IN uniformly_RB generating_VBG a_DT response_NNvariable_JJ with_IN 26_CD modalities_NNS and_CC a_DT nominal_JJ unordered_JJ predictor_NN with_IN 16_CD modalities_NNS for_IN 20,000_CDobservations._NNP By_IN letting_VBG be_VB 16_CD the_DT number_NN of_IN modalities_NNS of_IN the_DT splitting_NN predictor_NN it_PRP was_VBDpossible,_NN also_RB in_IN this_DT case,_NN to_TO find_VB the_DT (global)_NN best_RB split_VBN by_IN making_VBG use_NN of_IN the_DT exhaustive_NNenumeration._NN Such_JJ experimental_JJ studies_NNS showed_VBD that_IN the_DT most_RBS efficient_JJ configuration_NN of_IN the_DTGA_NNP was_VBD the_DT following:_JJ •_NN By_IN randomly_RB selecting_VBG the_DT initial_JJ population_NN (no_IN other_JJ solutions_NNS have_VBP been_VBN tried,_VBN in_IN fact)._DT •_NNP By_IN setting_VBG the_DT number_NN of_IN solutions_NNS building_VBG the_DT population_NN to_TO be_VB equal_JJ to_TO the_DT number_NN of_INnecessary_JJ genes_NNS (the_DT number_NN of_IN categories_NNS of_IN the_DT predictor)._NN •_NN By_IN setting_VBG a_DT crossover_JJ proportion_NN of_IN 0.80._DT •_NNP By_IN setting_VBG a_DT mutation_NN probability_NN equal_JJ to_TO 0.10._DT •_NN By_IN selecting_VBG the_DT rank_NN for_IN choosing_VBG the_DT solutions_NNS to_TO be_VB recombined._VBNwww.intechopen.com_NNEvolutionary_JJ Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NN459_CDFor_IN this_DT kind_NN of_IN problem_NN (20,000_CD units,_NN 16_CD categories_NNS for_IN the_DT response_NN variable_JJ and_CC 26_CDcategories_NNS for_IN the_DT splitting_NN predictor)_RB the_DT global_JJ optimum_NN was_VBD reached_VBN in_IN less_JJR than_IN 30_CDiterations._.When_WRB the_DT complexity_NN of_IN the_DT problem_NN grows_VBZ many_JJ iterations_NNS seems_VBZ to_TO be_VB required,_VBN though_INsuch_JJ number_NN never_RB appeared_VBD to_TO grow_VB exponentially._.The_DT GA_NNP has_VBZ been_VBN tested_VBN also_RB on_IN the_DT “Adult”_JJ dataset_NN available_JJ from_IN the_DT UCI_NNP Machine_NNLearning_VBG website._PRP This_DT dataset_NN has_VBZ been_VBN extracted_VBN from_IN the_DT US_NNP Census_NNP Bureau_NNP Database_NNP(source:_JJ http://www.census.gov/)_NN with_IN the_DT aim_NN of_IN predicting_VBG whether_IN a_DT person_NN earns_VBZ more_RBRthan_IN 50,000_CD dollars_NNS per_IN year._NN Such_JJ dataset_NN has_VBZ 325,614_CD observations_NNS and_CC some_DT categorical_NNunordered_JJ splitting_JJ predictors_NNS with_IN many_JJ attributes._NN In_IN particular,_NN the_DT native-country_NNpredictor_NN has_VBZ 42_CD attributes._NNState_NNP Goes_NNP to_TO State_NNP Goes_NNS to_TOUnited-States_NNP Left_VBD Cuba_NNP Left_NNPJamaica_NNP Right_NNP India_NNP Left_NNPUnknown_NNP Country_NNP Left_VBD Mexico_NNP Right_RBSouth_NNP Left_VBD Puerto-Rico_NNP Right_RBHonduras_NNS Right_RB England_NNP Left_NNPCanada_NNP Left_VBD Germany_NNP Left_VBNIran_NNP Left_VBD Philippines_NNP Left_NNPItaly_NNP Left_VBD Poland_NNP Left_NNPColumbia_NNP Right_RB Cambodia_NNP Left_NNPThailand_NNP Left_VBD Ecuador_NNP Right_RBLaos_NNP Right_RB Taiwan_NNP Left_NNPHaiti_NNP Right_RB Portugal_NNP Right_RBDominican-Republic_NNP Right_RB El-Salvador_NNP Right_RBFrance_NNP Left_VBD Guatemala_NNP Right_RBChina_NNP Left_VBD Japan_NNP Left_NNPYugoslavia_NNP Left_VBD Peru_NNP Right_RBOutlying-US_NNP Right_RB Scotland_NNP Left_NNPTrinadad-Tobago_NNP Right_NNP Greece_NNP Left_NNPNicaragua_NNP Right_NNP Vietnam_NNP Right_RBHong_NNP Left_VBD Ireland_NNP Left_NNPHungary_NNP Left_VBD Holland-Netherlands_NNP Right_RBTable_NN 2._VBZ The_DT split_NN provided_VBN by_IN the_DT GA_NNP for_IN the_DT native-country_NN in_IN the_DT Adult_NN dataset_NNThe_DT GA_NNP has_VBZ been_VBN run_VBN with_IN the_DT aim_NN of_IN trying_VBG to_TO find_VB a_DT good_JJ split_NN by_IN making_VBG use_NN of_IN the_DT native-_NNScountry_NN splitting_NN predictor_NN that_IN both_DT R_NN and_CC SPSS,_JJ for_IN instance,_NN refused_VBD to_TO process._VB As_INpreviously_RB mentioned,_JJ 30_CD iterations_NNS seemed_VBD to_TO be_VB not_RB enough_RB because,_IN in_IN many_JJ runs_NNS of_IN the_DTalgorithm,_IN the_DT “probably_RB best”_IN solution_NN appeared_VBD after_IN iteration_NN 80._VBZ The_DT solution_NN provided_VBNby_IN the_DT algorithm_NN is_VBZ shown_VBN in_IN Table_NN 2._. It_PRP gives_VBZ an_DT idea_NN of_IN the_DT complexity_NN of_IN the_DT problem._NNThe_DT corresponding_JJ decrease_NN in_IN the_DT node_NN impurity_NN is_VBZ 0.3628465._DT The_DT algorithm_NN has_VBZ been_VBNtested_VBN over_IN many_JJ simulated_JJ dataset_NN and_CC the_DT number_NN of_IN required_VBN iterations_NNS for_IN the_DT algorithm_NNto_TO reach_VB convergence_NN has_VBZ been_VBN shown_VBN to_TO linearly_RB grow_VB as_IN a_DT function_NN of_IN the_DT number_NN of_INattributes_NNS of_IN the_DT splitting_JJ predictor_NN (the_DT number_NN of_IN observations_NNS in_IN the_DT dataset_NN appeared_VBD to_TObe_VB uninfluential)._VBGwww.intechopen.com_NNAdvances_NNS in_IN Evolutionary_NNP Algorithms_NNP460_CDAnt_NNP System._NNP The_DT strong_JJ complexity_NN of_IN the_DT decision_NN tree_NN growing_VBG procedure_NN (Hyafil_NNP &_CC Rivest,_NNP1976)_CD does_VBZ not_RB allow_VB to_TO exhaustively_RB enumerate_VB and_CC evaluate_VB all_DT the_DT possible_JJ generable_NNtrees,_NN even_RB from_IN very_RB small_JJ datasets._NN In_IN this_DT respect,_NN it_PRP is_VBZ not_RB possible_JJ to_TO check_VB whether_IN the_DTchosen_VBN heuristic_NN is_VBZ able_JJ to_TO find_VB the_DT global_JJ optimum_NN (in_IN the_DT same_JJ manner_NN as_IN it_PRP has_VBZ been_VBNpreviously_RB done_VBN for_IN the_DT genetic_JJ algorithm)._NNIn_IN the_DT first_JJ experiment_NN the_DT algorithm_NN has_VBZ been_VBN tested_VBN on_IN a_DT simulated_VBN dataset_NN of_IN 500_CDobservations_NNS with_IN 11_CD nominal_JJ unordered_JJ predictors_NNS (with_IN a_DT number_NN of_IN attributes_NNS that_DT ranges_NNSbetween_IN 2_CD and_CC 9)_CD and_CC 2_CD numeric_JJ (continuous)_NN predictors._. It_PRP could_MD be_VB seen_VBN that,_IN when_WRB the_DTrequired_VBN tree_NN depth_NN increases,_VBZ the_DT differences_NNS between_IN the_DT global_JJ impurity_NN of_IN the_DT tree_NNobtained_VBN by_IN the_DT CART_NNP greedy_JJ heuristic_JJ and_CC the_DT one_CD obtained_VBN by_IN the_DT Ant_NNP System_NNP tend_VB to_TOincrease._NN Table_NN 3_CD reports_NNS such_JJ results._NNTree_NNP Depth_NNP CART_NNP Ant_NNP System_NNP4_CD 0.158119_CD 0.153846_CD5_CD 0.147435_CD 0.121794_CD6_CD 0.100427_CD 0.085477_CD7_CD 0.079059_CD 0.059829_CD8_CD 0.044871_CD 0.029911_CDTable_NN 3.Global_JJ impurity_NN of_IN the_DT decision_NN trees_NNS extracted_VBN by_IN the_DT proposed_VBN algorithm_NN on_IN a_DTsimulated_VBN dataset_NNFigure_NN 2_CD shows_VBZ the_DT result_NN obtained_VBN on_IN the_DT “Credit”_NNP dataset_NN that_WDT can_MD be_VB found_VBN in_IN the_DT SPAD_NNsoftware_NN (source:_, www.spadsoft.com)._'' This_DT dataset_NN has_VBZ 468_CD observations_NNS on_IN which_WDT 11_CDnominal_JJ variables_NNS have_VBP been_VBN observed_VBN together_RB with_IN a_DT two-class_JJ response_NN variable._VBZ The_DT aim_NNwould_MD be_VB to_TO predict_VB such_JJ response_NN variable_JJ (“is_IN a_DT customer_NN good_JJ or_CC bad?)._RBRThe_DT first_JJ decision_NN tree_NN is_VBZ the_DT one_NN found_VBN by_IN the_DT CART_NNP heuristic_NN and_CC the_DT second_JJ one_NN has_VBZ been_VBNextracted_VBN after_IN 200_CD iterations_NNS of_IN the_DT Ant_NNP System_NNP algorithm._.Table_NN 4_CD shows_NNS the_DT global_JJ impurity_NN of_IN the_DT trees_NNS extracted_VBN by_IN the_DT CART_NNP and_CC Ant_NNP heuristics._.Fig._NNP 2._VBD Decision_NNP Trees_NNP for_IN the_DT Credit_NNP dataset_NN obtained_VBD using_VBG the_DT CART_NNP heuristic_JJ (left_NN panel)_NNand_CC after_IN 200_CD iterations_NNS of_IN the_DT Ant_NNP System_NNP algorithm_NN (right_NN panel)._.www.intechopen.com_NNThe_DT algorithms_NNS presented_VBN here_RB are_VBP in_IN an_DT early_JJ stage_NN of_IN development._NN In_IN these_DT examples,_NN an_CCAnt_NNP System_NNP has_VBZ been_VBN proposed_VBN to_TO attack_VB the_DT problem_NN of_IN finding_VBG the_DT best_JJS exploratory_NNdecision_NN tree_NN and_CC it_PRP came_VBD out_RP that_IN the_DT Ant_NNP System-based_JJ decision_NN trees_NNS performed_VBN better_RB than_INthe_DT ones_NNS found_VBN by_IN the_DT CART_NNP greedy_JJ heuristic._NN Even_RB if_IN the_DT improvements_NNS weren’t_VBD too_RB large_JJEvolutionary_JJ Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NN461_CDTree_NNP Depth_NNP CART_NNP Ant_NNP System_NNP2_CD 0.2948_CD 0.2734_CD3_CD 0.2435_CD 0.2301_CD4_CD 0.2029_CD 0.1816_CD5_CD 0.1773_CD 0.1517_CD6_CD 0.1645_CD 0.1539_CDTable_NN 4._VBD Global_JJ impurity_NN of_IN the_DT decision_NN trees_NNS extracted_VBN by_IN the_DT proposed_VBN algorithm_NN on_IN the_DTCredit_NNP dataset_NNSASSC_NNP algorithm._NN In_IN the_DT following,_NN the_DT SASSC_NNP algorithm_NN is_VBZ applied_VBN on_IN the_DT “Letter_NNRecognition”_NNP dataset_NN from_IN the_DT UCI_NNP Machine_NNP Learning_NNP Repository_NNP (source_NNhttp://archive.ics.uci.edu/ml/)._PRP This_DT dataset_NN is_VBZ originally_RB analyzed_VBN in_IN Frey_NNP &_CC Slate_NNP (1991),_.who_WP did_VBD not_RB achieve_VB a_DT good_JJ performance_NN since_IN the_DT correct_JJ classified_JJ observations_NNS did_VBD never_RBexceed_VBP 85%._VBZ Later_RB on,_RB the_DT same_JJ dataset_NN is_VBZ analyzed_VBN in_IN Fogarty(1992)_JJ using_VBG nearest_JJSneighbours_NNS classification._NN Obtained_VBD results_NNS give_VB over_RP 95.4%_DT accuracy_NN compared_VBN to_TO the_DT best_JJSresult_NN of_IN 82.7%_CD reached_VBD in_IN Frey_NNP &_CC Slate(1991)._NNP Nevertheless,_NNP no_DT information_NN about_IN the_DTinterpretability_NN of_IN the_DT nearest_JJS neighbour_NN classification_NN model_NN is_VBZ provided_VBN and_CC the_DTcomputational_JJ inefficiency_NN of_IN such_JJ a_DT procedure_NN is_VBZ deliberately_RB admitted_VBN by_IN the_DT authors._NNIn_IN the_DT Letter_NNP Recognition_NNP analysis,_IN the_DT task_NN is_VBZ to_TO classify_VB 20,_CD 000_CD black-and-white_JJ rectangular_JJpixel_NN displays_NNS into_IN one_CD of_IN the_DT 26_CD letters_NNS in_IN the_DT English_NNP alphabet._NN The_DT character_NN images_NNS are_VBPbased_VBN on_IN 20_CD different_JJ fonts_NNS and_CC each_DT letter_NN within_IN these_DT 20_CD fonts_NNS was_VBD randomly_RB distorted_VBN to_TOproduce_VB a_DT file_NN of_IN 20,000_CD unique_JJ stimuli._NN Each_DT stimulus_NN was_VBD converted_VBN into_IN 16_CD numerical_JJattributes_NNS that_DT have_VBP to_TO be_VB submitted_VBN to_TO a_DT decision_NN tree._NN Dealing_VBG with_IN K_NNP =_SYM 26_CD response_NN classes,_NNSASSC_NNP provides_VBZ 25_CD sequential_JJ aggregations._NN Classification_NN trees_NNS aggregated_VBN at_IN each_DT single_JJstep_NN were_VBD chosen_VBN according_VBG to_TO 10-fold_JJ cross_NN validation._VBZ A_DT tree_NN was_VBD aggregated_VBN to_TO the_DTsequence_NN if_IN it_PRP provided_VBD the_DT lowest_JJS cross_NN validated_JJ generalization_NN error_NN with_IN respect_NN to_TO the_DTother_JJ trees_NNS obtainable_JJ from_IN different_JJ aggregations_NNS of_IN (subgroups_NNS of)_IN response_NN classes._.The_DT results_NNS of_IN the_DT SASSC_NNP algorithm_NN are_VBP summarized_VBN in_IN Figure_NN 3._. It_PRP compares_VBZ the_DTperformance_NN of_IN the_DT SASSC_NNP model_NN formed_VBD by_IN g=2_VBG up_RP to_TO g=6_VB superclasses_NNS with_IN that_DT of_IN CART_NNPusing,_NN in_IN all_DT cases,_NN either_CC Gini_NNP or_CC Twoing_NNP as_IN splitting_JJ rules._NN Bagging_CC (Brieman,_JJ 1996)_CD and_CCRandom_NNP Forest_NNP (Breiman,_NNP 2001)_CD are_VBP used_VBN as_IN benchmarking_VBG methods_NNS as_IN well._PRP Computations_.have_VBP been_VBN carried_VBN out_RP using_VBG the_DT R_NN software_NN for_IN statistical_JJ computing._NNThe_DT SASSC_NNP model_NN using_VBG 2_CD superclasses_NNS consistently_RB improves_VBZ the_DT results_NNS of_IN CART_NNP using_VBG the_DTGini_NNP (Twoing)_NNP splitting_NN rule_NN since_IN the_DT generalization_NN error_NN reduces_VBZ to_TO 0.49_CD (0.34)_CD from_IN 0.52_CD(0.49)._. As_IN expected,_VBN the_DT choice_NN of_IN the_DT splitting_JJ rule_NN (Gini_NNS or_CC Twoing)_NNP is_VBZ relevant_JJ when_WRB the_DTnumber_NN of_IN superclasses_NNS g_VBG is_VBZ relatively_RB small_JJ (2_NN ≤_IN g_VBG ≤_NNS 4),_CC whereas_IN it_PRP becomes_VBZ negligible_JJ for_INhigher_JJR values_NNS of_IN g_VBG (results_NNS for_IN g_VBG ≥_JJ 5_CD are_VBP almost_RB identical)._VBG Focusing_NNP on_IN the_DT Gini_NNP splitting_NNcriterion,_NN the_DT SASSC’s_NNP generalization_NN error_NN further_RB reduces_VBZ to_TO 0.11_CD when_WRB the_DT number_NN of_INsubsets_NNS increases_NNS to_TO 6._CD For_IN comparative_JJ purposes,_NN Bagging_NN and_CC Random_NNP Forest_NNP have_VBP been_VBNwww.intechopen.com_NN(from_IN 2%_JJ to_TO 5%_VB in_IN all_DT of_IN the_DT simulation_NN studies)_NN such_JJ algorithm_NN could_MD be_VB still_RB useful_JJ for_IN the_DTsituations_NNS in_IN which_WDT high_JJ accuracy_NN is_VBZ required_VBN from_IN the_DT decision_NN tree_NN would._WP Ant_NNP System,_NNP on_INthe_DT other_JJ hand,_NN is_VBZ the_DT simplest_JJS (yet_NN less_RBR efficient)_JJ ACO_NNP technique,_NN so_RB that_IN the_DT use_NN of_IN more_RBRpowerful_JJ ACO_NNP algorithms_NNS (which_WDT is_VBZ currently_RB under_IN development)_NN would_MD reasonably_RB bring_VBbetter_JJR results._NN It_PRP is_VBZ well_RB known_VBN that_IN ACO_NNP algorithms_NNS reach_VBP their_PRP$ maximum_JJ efficiency_NN when_WRBcoupled_VBN with_IN local_JJ search_NN techniques_NNS or_CC can_MD improve_VB their_PRP$ efficiency_NN by_IN making_VBG use_NN of_INcandidate_NN lists._NNAdvances_NNS in_IN Evolutionary_NNP Algorithms_NNP462_CDtrained_VBN using_VBG 6_CD and_CC 10_CD classifiers_NNS respectively_RB and,_RB in_IN these_DT cases,_NNS obtained_VBD generalization_NNerrors_NNS are_VBP worse_JJR than_IN those_DT deriving_VBG from_IN SASSC_NNP with_IN g_VBG =_SYM 6._CD As_IN for_IN Bagging_NNP and_CC Random_NNPForest,_NNS increasing_VBG the_DT number_NN of_IN trees_NNS used_VBN to_TO classify_VB each_DT subset_NN of_IN randomly_RB drawn_VBNobjects_NNS improves_VBZ the_DT performance_NN of_IN these_DT two_CD methods_NNS in_IN terms_NNS of_IN prediction_NN accuracy._VBZ The_DTreason_NN is_VBZ that_IN their_PRP$ predictions_NNS derive_VBP form_NN (“in-sample”)_JJ independent_JJ bootstrap_NNreplications._NNP Instead,_NNP cross-validation_NN predictions_NNS in_IN SASSC_NNP derives_NNS from_IN aggregations_NNS of_INclassifications_NNS made_VBD on_IN “out-of-sample”_JJ observations_NNS that_WDT are_VBP excluded_VBN from_IN the_DT tree_NNgrowing_VBG procedure._NN Thus,_RB it_PRP is_VBZ natural_JJ to_TO expect_VB that_DT cross-validation_NN predictions_NNS are_VBP more_RBRinaccurate_JJ than_IN bagged_JJ ones._NNP Of_IN course,_NN increasing_VBG the_DT number_NN of_IN subsets_NNS of_IN the_DT response_NNclasses_NNS in_IN SASSC_NNP reduces_VBZ the_DT cross-validated_JJ generalization_NN error_NN but,_NN at_IN the_DT same_JJ time,_NNincreases_NNS the_DT complexity_NN of_IN the_DT final_JJ classification_NN model._'' In_IN spite_NN of_IN a_DT relatively_RB lower_RBRaccuracy,_JJ interpretability_NN of_IN the_DT results_NNS in_IN SASSC_NNP with_IN g_VBG =_SYM 6_CD is_VBZ strictly_RB preserved._VBNFigure_NN 3._VBD The_DT generalization_NN errors_NNS for_IN the_DT Letter_NNP Recognition_NNP dataset_NN provided_VBN by_INalternative_JJ approaches:_JJ as_IN for_IN SASSC,_NNP subscript_NN G(T)_NNP indicates_VBZ the_DT Gini_NNP (Twoing)_NNP splitting_NNrule,_NN whereas_IN apex_NN g_NN indicates_VBZ the_DT number_NN of_IN superclasses_NNS (i.e.,_, decision_NN trees)_NN identified_VBN by_INthe_DT algorithm._NN The_DT subscript_NN for_IN Bagging_NNP and_CC Random_NNP Forest_NNP indicates_VBZ the_DT number_NN of_IN trees_NNSused_VBN to_TO obtain_VB the_DT classification_NN by_IN majority_NN voting._NN6._DT Discussion_NNP and_CC conclusions_NNSIn_IN the_DT last_JJ two_CD decades,_NNS computational_JJ enhancements_NNS highly_RB contributed_VBD to_TO the_DT increase_NN in_INpopularity_NN of_IN DTI_NNP algorithms._'' This_DT cause_NN the_DT successful_JJ use_NN of_IN Decision_NNP Tree_NNP Induction_NNP (DTI)_.using_VBG recursive_JJ partitioning_NN algorithms_NNS in_IN many_JJ diverse_JJ areas_NNS such_JJ as_IN radar_NN signal_NNclassification,_JJ character_NN recognition,_NN remote_JJ sensing,_NN medical_JJ diagnosis,_NN expert_NN systems,_NN and_CCspeech_NN recognition,_VBD to_TO name_VB only_RB a_DT few._JJ But_CC recursive_JJ partitioning_NN and_CC DTI_NNP are_VBP two_CD faces_NNS of_INwww.intechopen.com_NNEvolutionary_JJ Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NN463_CDthe_DT same_JJ medal._NN While_IN the_DT computational_JJ time_NN has_VBZ been_VBN rapidly_RB reducing,_VBG the_DT statistician_NN is_VBZmaking_VBG more_JJR use_NN of_IN computationally_RB intensive_JJ methods_NNS to_TO find_VB out_RP unbiased_JJ and_CC accurate_JJclassification_NN rules_NNS for_IN unlabelled_JJ objects._NNP Nevertheless,_NNP DTI_NNP cannot_MD result_VB in_IN finding_VBG out_INsimply_RB a_DT number_NN (the_IN misclassification_NN error),_NN but_CC also_RB an_DT accurate_JJ and_CC interpretable_JJ model._.Software_NNP enhancements_NNS based_VBN on_IN interactive_JJ user_NN interface_NN and_CC customized_VBD routines_NNS should_MDempower_NN the_DT effectiveness_NN of_IN trees_NNS with_IN respect_NN to_TO interpretability,_JJ identification_NN and_CCrobustness._NNP The_DT latter_JJ considerations_NNS have_VBP been_VBN the_DT inspiration_NN for_IN the_DT algorithms_NNS presented_VBNin_IN this_DT chapter_NN aimed_VBD at_IN the_DT improvement_NN of_IN DTI_NNP effectiveness._. They_PRP lead_VBP to_TO easily_RBinterpretable_JJ solutions_NNS for_IN rather_RB complicated_JJ data_NNS analysis_NN problems_NNS and_CC can_MD be_VB fruitfully_RBused_VBN in_IN different_JJ fields_NNS of_IN Knowledge_NNP Discovery_NNP from_IN Databases_NNP (KDD)_NNP and_CC data_NNS mining_NNsuch_JJ as,_NN for_IN example,_JJ web_NN mining_NN and_CC Customer_NNP Relationship_NNP Management_NNP (CRM)._.A_DT Genetic_JJ Algorithm_NNP for_IN multi-attribute_JJ predictor_NN splitting_NN is_VBZ proposed_VBN in_IN this_DT chapter._NN It_PRP can_MDbe_VB said_VBD that_IN the_DT proposed_VBN GA_NNP works_VBZ very_RB well_RB in_IN presence_NN of_IN treatable_JJ splitting_NN predictors,_RBfor_IN which_WDT the_DT exhaustive_JJ enumeration_NN is_VBZ affordable._VBG The_DT algorithm_NN always_RB reaches_VBZ the_DT global_JJoptimum_NN very_RB quickly._'' This_DT makes_VBZ possible_JJ to_TO think_VB positively,_NN even_RB if_IN nothing_NN can_MD be_VB said,_VBNof_IN course,_NN about_IN the_DT case_NN in_IN which_WDT the_DT number_NN of_IN attributes_NNS gets_VBZ too_RB large_JJ for_IN the_DT exhaustive_NNenumeration_NN and_CC evaluation._NN Obtained_VBN results_NNS can_MD be_VB considered_VBN definitely_RB useful_JJ in_IN those_DTcases_NNS where_WRB there_EX are_VBP no_DT other_JJ ways_NNS to_TO attack_VB the_DT problem._NN Future_JJ research_NN directions_NNS will_MDinclude_VBP exhaustive_JJ enumerations_NNS on_IN bigger_JJR datasets_NNS on_IN a_DT grid_NN computing_NN infrastructure._.In_IN addition_NN an_DT Ant_NNP Colony_NNP Optimization_NNP algorithm_NN is_VBZ also_RB proposed_VBN for_IN exploratory_NN tree_NNgrowing._VBG Such_JJ algorithm_NN could_MD be_VB useful_JJ for_IN the_DT situations_NNS in_IN which_WDT high_JJ accuracy_NN is_VBZrequired_VBN from_IN the_DT decision_NN tree_NN would._WP Ant_NNP System,_NNP on_IN the_DT other_JJ hand,_NN is_VBZ the_DT simplest_JJS (yet_NNless_RBR efficient)_JJ ACO_NNP technique,_NN so_RB that_IN the_DT use_NN of_IN more_JJR powerful_JJ ACO_NNP algorithms_NNS (which_. is_NNScurrently_RB under_IN development)_NN would_MD reasonably_RB bring_VB better_JJR results._NN It_PRP is_VBZ well_RB known_VBN that_INACO_NNP algorithms_NNS reach_VBP their_PRP$ maximum_JJ efficiency_NN when_WRB coupled_VBN with_IN local_JJ search_NN techniques_NNSor_CC can_MD improve_VB their_PRP$ efficiency_NN by_IN making_VBG use_NN of_IN candidate_NN lists._.Finally,_RB a_DT sequential_JJ search_NN algorithm_NN for_IN modelling_VBG multi-attribute_JJ response_NN through_IN DTI_NNPhas_VBZ also_RB been_VBN introduced._VBN The_DT motivation_NN underlying_VBG the_DT formalization_NN of_IN the_DT SASSC_NNPalgorithm_NN derives_NNS from_IN the_DT following_VBG intuition:_NN basically,_NN since_IN standard_JJ classification_NN trees_NNSunavoidably_RB lead_VB to_TO prediction_NN inaccuracy_NN in_IN the_DT presence_NN of_IN multi-class_JJ response,_NN it_PRP would_MDbe_VB favourable_JJ to_TO look_VB for_IN a_DT relatively_RB reduced_JJ number_NN of_IN decision_NN trees_NNS each_DT one_CD relating_VBG to_TO a_DTsubset_NN of_IN classes_NNS of_IN the_DT response_NN variable,_VBZ the_DT so_RB called_VBN super-classes._NN Reducing_VBG the_DT number_NNof_IN response_NN classes_NNS for_IN each_DT of_IN those_DT trees_NNS naturally_RB leads_VBZ to_TO improve_VB the_DT overall_NN prediction_NNaccuracy._VBG To_TO further_RBR enforce_VB this_DT guess,_NN an_DT appropriate_JJ criterion_NN to_TO derive_VB the_DT correct_JJ number_NNof_IN super-classes_NNS and_CC the_DT most_RBS parsimonious_JJ tree_NN structure_NN for_IN each_DT of_IN them_PRP has_VBZ to_TO be_VB found._VBNIn_IN this_DT respect,_NN a_DT sequential_JJ approach_NN that_WDT automatically_RB proceeds_VBZ through_IN subsequent_JJaggregations_NNS of_IN the_DT response_NN classes_NNS might_MD be_VB a_DT natural_JJ starting_NN point._NNThe_DT analysis_NN of_IN the_DT Letter_NNP Recognition_NNP dataset_NN demonstrated_VBD that_IN the_DT SASSC_NNP algorithm_NN can_MDbe_VB applied_VBN pursuing_VBG two_CD complementary_JJ goals:_NN 1)_IN a_DT content-related_JJ goal,_NN resulting_VBG in_IN the_DTspecification_NN of_IN a_DT classification_NN model_NN that_WDT provides_VBZ a_DT good_JJ interpretation_NN of_IN the_DT results_NNSwithout_IN disregarding_VBG accuracy;_NN 2)_IN a_DT performance-related_JJ goal,_NN dealing_VBG with_IN the_DT development_NNof_IN a_DT model_NN resulting_VBG effective_JJ in_IN terms_NNS of_IN predictive_JJ accuracy_NN without_IN neglecting_VBGinterpretability._NN Taking_VBG these_DT considerations_NNS into_IN account,_NN SASSC_NNP appears_VBZ as_IN a_DT valuable_JJalternative_NN to_TO evaluate_VB whether_IN a_DT restricted_JJ number_NN of_IN independent_JJ classifiers_NNS improves_VBZ the_DTgeneralization_NN error_NN of_IN a_DT classification_NN model._.www.intechopen.com_NNarsencihuy@gmail.com_NNHighlight_.arsencihuy@gmail.com_NNHighlight_.arsencihuy@gmail.com_NNHighlight_.arsencihuy@gmail.com_NNHighlight_.arsencihuy@gmail.com_NNHighlight_.arsencihuy@gmail.com_NNHighlight_.Advances_NNS in_IN Evolutionary_NNP Algorithms_NNP464_CD7._CD References_NNSBreiman,_NNP L.,_NNP Friedman,_NNP J.H.,_NNP Olshen,_NNP R.A.,_NNP &_CC Stone_NNP C.J._NNP (1984)_IN Classification_NNP and_CC Regression_NNPTrees,_NNP Wadsworth,_NNP Belmont_NNP CA._.Breiman,_NNP L._NNP (1996)_NNP Bagging_NNP Predictors,_NNP Machine_NNP Learning,_NNP 24,_CD 123-140._.Breiman,,_NNP L._NNP (2001)._NNP Random_NNP Forests,_NNP Machine_NNP Learning,_NNP 45,_CD 5-32._.Cappelli,_NNP C.,_NNP Mola,_NNP F.,_NNP &_CC Siciliano,_NNP R._NNP (2002),_IN A_DT Statistical_NNP Approach_NNP to_TO Growing_VBG a_DT Reliable_JJHonest_UH Tree,_NNP Computational_NNP Statistics_NNPS and_CC Data_NNP Analysis,_NNP 38,_VBD 285-299._.Chan,_NNP K._NNP Y._NNP &_CC Loh,_NNP W._NNP Y._NNP (2004)._NNP LOTUS:_NNP An_DT algorithm_NN for_IN building_VBG accurate_JJ and_CCcomprehensible_JJ logistic_JJ regression_NN trees._NN Journal_NNP of_IN Computational_NNP and_CC Graphical_NNPStatistics,_NNP 13,_CD 826–852._.Choi,_NNP Y.,_NNP Ahn,_NNP H._NNP &_CC Chen,_NNP J.J._NNP (2005)._. Regression_NNP trees_NNS for_IN analysis_NN of_IN count_NN data_NNS with_IN extra_JJPoisson_NNP variation._NN Computational_NNP Statistics_NNPS and_CC Data_NNP Analysis,_NNP 49,_CD 893–915._.Colorni,_NNP A.,_NNP Dorigo,_NNP M.,_NNP Maffioli,_NNP F.,_NNP Maniezzo,_NNP V.,_NNP Righini,_NNP G.,_NNP &_CC Trubian,_NNP M._NNP (1996)._.Heuristics_NNS from_IN nature_NN for_IN hard_JJ combinatorial_NN problems._, International_NNP Transactions_NNPSin_IN Operational_NNP Research,_NNP March,_NNP 1-21._.Conversano,_NNP C._NNP (2002)_NN Bagged_CC mixture_NN of_IN classifiers_NNS using_VBG Model_NNP Scoring_NNP Criteria._NNP Patterns_NNPSAnalysis_NNP &_CC Applications,_NNP 5,_CD 4,_CD 351-362._.Dietterich,_NNP T.G._NNP (2000)_VBD Ensemble_NNP methods_NNS in_IN machine_NN learning._. In_IN J.Kittler_NNP and_CC F.Roli,_NNP (Eds.),_.Multiple_NNP Classifier_NNP System._NNP First_NNP International_NNP Workshop,_NNP MCS_NNP 2000,_CD Cagliari,_NNP vol._.1857_CD of_IN Lecture_NNP notes_NNS in_IN computer_NN science._NN Springer-Verlag._.Dorigo,_NNP M._NNP &_CC Stutzle,_NNP T._NNP (2004)._NNP Ant_NNP Colony_NNP Optimization._NNP The_DT MIT_NNP Press,_NNP London._NNP 1-15_.Dorigo,_NNP M._NNP (1992)._NNP Optimization,_NNP Learning_NNP and_CC Natural_NNP Algorithms._NNP PhD_NNP thesis,_, Politecnico_NNP di_FWMilano,_NNP Italy._NNPFogarty,_NNP T._NNP (1992)_NNP First_NNP Nearest_NNP Neighbor_NNP Classification_NNP on_IN Frey_NNP and_CC Slate’s_NNP Letter_NNPRecognition_NNP Problem_NNP (Technical_NNP Note)._NNP Machine_NNP Learning,_NNP 9,_CD 387-388_CD ._.Fogel,_NNP L._NNP J._NNP (1997)._VBZ A_DT retrospective_JJ view_NN and_CC outlook_NN on_IN evolutionary_JJ algorithms._NN In_IN Fuzzy_JJDays,_NNP 337–342._MDFogel,_NNP D._NNP B._NNP &_CC Fogel,_NNP L._NNP (1993)._NNP Evolutionary_NNP computation._NN IEEE_NN Transactions_NNS on_IN Neural_JJNetworks,_JJ 5(1):1–2._.Freund,_NNP Y.,_NNP &_CC Schapire,_NNP R._NNP (1996),_VBD Experiments_NNS with_IN a_DT new_JJ boosting_VBG algorithm,_NN Machine_NNLearning:_NNP Proceedings_NNS of_IN the_DT Thirteenth_NNP International_NNP Conference,_NNP 148-156._.Frey,_NNP P.W._NNP &_CC Slate,_NNP D.J._NNP Letter_NNP Recognition_NNP Using_VBG Holland-style_NNP Adaptive_NNP Classifiers._NNP Machine_NNLearning,_NNP 6,_CD 161-182._.Gama,_NNP J._NNP (2004),_NNP Functional_NNP trees,_NN Machine_NN Learning,_NNP 55,_CD 219–250._.Hastie,_NNP T.,_NNP Friedman,_NNP J._NNP H.,_NNP &_CC Tibshirani,_NNP R.,_NNP (2001)._VBD The_DT Elements_NNS of_IN Statistical_NNP Learning:_NNP Data_NNPMining,_NNP Inference_NNP and_CC Prediction,_NNP Springer._NNPHothorn,_NNP T.,_NNP Hornik,_NNP K._NNP &_CC Zeileis,_NNP A._NN (2006)._VBD Unbiased_JJ recursive_JJ partitioning:_NN A_DT conditional_JJinference_NN framework,_NN Journal_NNP of_IN Computational_NNP and_CC Graphical_NNP Statistics,_NNP 15,_CD 651–674._.Hyafil_NNP &_CC Rivest_NNP (1976)._VBD Constructing_VBG optimal_JJ binary_JJ decision_NN trees_NNS is_VBZ NPcomplete._NNP IPL:_.Information_NN Processing_NNP Letters,_NNP 15-17._.Klaschka,_NNP J.,_NNP Siciliano,_NNP R.,_NNP &_CC Antoch,_NNP J._NNP (1998):_NNP Computational_NNP Enhancements_NNS in_IN Tree-_NNPGrowing_VBG Methods,_NNP in:_IN Rizzi,_NNP A.,_NNP Vichi,_NNP M._NNP &_CC Bock,_NNP H.H._NNP (Eds.),_NNP Advances_NNP in_IN Data_NNPScience_NNP and_CC Classification:_NNP Proceedings_NNP of_IN the_DT 6th_JJ Conference_NNP of_IN the_DT International_NNPFederation_NNP of_IN Classification_NNP Society,_NNP Springer-Verlag,_NNP Berlin_NNP Heidelberg._NNP 295-302_.Loh,_NNP W.Y._NNP (2002)._. Regression_NNP trees_NNS with_IN unbiased_JJ variable_JJ selection_NN and_CC interaction_NNdetection._NN Statistica_NNP Sinica,_NNP 12,_CD 361-386._.www.intechopen.com_NNEvolutionary_JJ Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NN465_CDMehta,_NNP M.,_NNP Agrawal,_NNP R._NNP &_CC Rissanen_NNP J._NNP (1996)._NNP SLIQ._NNP A_DT Fast_NNP Scalable_NNP Classifier_NNP for_IN Data_NNPMining._NNP In_IN Proceedings_NNP of_IN the_DT International_NNP Conference_NNP on_IN Extending_NNP Database_NNPTechnology_NNP EDBT,_NNP 18-32._.Michalewicz,_NNP Z._NNP (1996)._NNP Genetic_NNP Algorithms_NNP +_NNP Data_NNP Structures_NNP =_SYM Evolution_NNP Programs._NNP Springer-_NNPVerlag,_NNP third_JJ edition._NNMiele,_NNP R.,_NNP Mola,_NNP F.,_NNP Siciliano,_NNP R._NNP (2005)._NNP J-Fast:_NNP An_DT Interactive_NNP Software_NNP for_IN Classification_NNP and_CCRegression_NN Trees._NNP In_IN Proceedings_NNP of_IN the_DT Classification_NN and_CC Data_NNP Analysis_NNP Group_NNP(CLADAG)_NN of_IN the_DT Italian_JJ Statistical_NNP Society._NNP Parma,_NNP Italy,_NNP 437-440_CDMiele,_NNP R._NNP (2007)._NNP Nature_NNP Inspired_NNP Optimization_NN Algorithms_NNP for_IN Classification_NNP and_CC Regression_NNPTrees._NNP Ph.D._NNP Thesis._NNP Univeristy_NNP of_IN Naples_NNP “Federico_NNP II”._.Mola,_NNP F.,_NNP &_CC Conversano,_NNP C._NNP (2008)_NNP Sequential_NNP Automatic_NNP Search_NNP of_IN a_DT Subset_NNP of_IN Classifiers_NNS in_INMulticlass_NNP Learning,_NNP in:_IN Brito_NNP P._NNP &_CC Aluja-Banet_NNP T._NNP (Eds.)_NNP COMPSTAT_NNP 2008_CDProceedings_NNS in_IN Computational_NNP Statistics,_NNP Physica-Verlag,_NNP to_TO appear._MDMola,_NNP F.,_NNP &_CC Siciliano,_NNP R._NNP (1997)._NNP A_DT fast_JJ splitting_NN algorithm_NN for_IN classification_NN trees._NN Statistics_NNS and_CCComputing,_NNP 7,_CD 209–216._.Oliver,_NNP J.J.,_NNP &_CC Hand,_NNP D._NNP J._NNP (1995)._NNP On_IN Pruning_NNP and_CC Averaging_NNP Decision_NNP Trees,_NNP in_IN Machine_NNLearning:_NNP Proceedings_NNS of_IN the_DT 12th_JJ International_NNP Workshop,430-437._.Quinlan,_NNP J.R.,_NNP (1983)._VBD Learning_VBG Efficient_NN Classification_NN Procedures_NNS and_CC Their_PRP$ Application_NNP to_TOChess_NNP and_CC Games._NNP In_IN Michalski_NNP R.S.,_NNP Carbonell_NNP J.G._NNP &_CC Mitchell_NNP T.M._NNP (ed.):_NNP Machine_NNLearning:_NNP An_DT Artificial_JJ Intelligence_NN Approach,_NNP 1,_CD Tioga_NNP Publishing,_NNP 463-482._.Quinlan,_NNP J.R.,_NNP (1987)._VBD Simplifying_VBG decision_NN tree._, International_NNP Journal_NNP of_IN Man-Machine_NNP Studies,_NNP27,_CD 221–234._CDQuinlan,_NNP J._NNP R._NNP (1993)._NNP C4.5:_NNP Programs_NNP for_IN Machine_NNP Learning,_NNP Morgan_NNP Kaufmann._NNPSiciliano,_NNS R.,_NNP (1998)._. Exploratory_NNP versus_FW decision_NN trees._NN In:_IN Payne,_NNP R.,_NNP Green,_NNP P._NNP (Eds.),_.COMPSTAT_NN 1998_CD Proceedings_NNS in_IN Computational_NNP Statistics._NNP Physica-Verlag,_NNP 113–124._.Siciliano,_FW R._NNP &_CC Mola,_NNP F._NNP (2000)._NNP Multivariate_NNP Data_NNP Analysis_NNP through_IN Classification_NNP and_CCRegression_NNP Trees,_NNP Computational_NNP Statistics_NNPS and_CC Data_NNP Analysis,_NNP 32,_VBD 285-301,_JJ Elsevier_RBScience,_NNP 2000._CDSu,_NNP X.,_NNP Wang,_NNP M._NNP &_CC Fan,_NNP J._NNP (2004)._VBD Maximum_NNP likelihood_NN regression_NN trees._VBG Journal_NNP of_INComputational_NNP and_CC Graphical_NNP Statistics,_NNP 13,_CD 586–598._.Vose,_NNP M._NNP D._NNP (1999)._VBD The_DT simple_JJ genetic_JJ algorithm:_NN foundations_NNS and_CC theory._DT MIT_NNP Press,_NNPCambridge,_NNP MA._NNPAppendix:_NNP The_DT J-FAST_NN software_NNThe_DT algorithms_NNS presented_VBD in_IN this_DT chapter_NN have_VBP been_VBN implemented_VBN in_IN the_DT Java_NNP language._NN In_INorder_NN to_TO make_VB it_PRP possible_JJ to_TO test_VB them_PRP on_IN real_JJ datasets_NNS a_DT Java_NNP segmentation_NN framework,_NN called_VBNJ-FAST,_NNP has_VBZ been_VBN developed._VBN The_DT first_JJ aim_NN of_IN this_DT software_NN is_VBZ to_TO take_VB care_NN of_IN all_DT the_DT necessary_JJoperations_NNS to_TO perform_VB before_IN and_CC after_IN running_VBG the_DT recursive_JJ partitioning_NN algorithm._. These_DTcan_MD be_VB summarized_VBN as_IN follows:_JJ reading_NN data_NNS from_IN text_NN files_NNS and_CC spreadsheets;_NN processing_NNdata_NNS before_IN carrying_VBG out_RP the_DT tree_NN growing_VBG process;_NN specifying_VBG the_DT type_NN of_IN recursive_VBGpartitioning_NN algorithm_NN to_TO be_VB applied_VBN (i.e.,_IN classification_NN or_CC regression_NN tree)_NN ;_: interpretation_NN of_INthe_DT results._NNThe_DT J-FAST_NNP program_NN is_VBZ a_DT Java-based_JJ recursive_JJ partitioning_NN software,_NN which_WDT is_VBZ particularly_RBresearch_NN oriented._VBN It_PRP mainly_RB consists_VBZ of_IN a_DT flexible,_NN efficient_JJ and_CC transparent_JJ cross-platform_NNapplication_NN for_IN building_NN classification_NN and_CC regression_NN trees_NNS using_VBG any_DT kind_NN of_IN heuristic_JJ in_IN the_DTtree_NN growing_VBG process_NN (like_IN the_DT CART_NNP greedy_JJ algorithm_NN or_CC the_DT FAST_NNP branch_NN and_CC bound_VBNwww.intechopen.com_NNAdvances_NNS in_IN Evolutionary_NNP Algorithms_NNP466_CDheuristic_JJ or_CC any_DT other_JJ one_CD written_VBN by_IN the_DT user)._NN It_PRP also_RB allows_VBZ to_TO interactively_RB visualize_VB and_CCcompare_VB the_DT results._NNP J-FAST_NNP divides_VBZ the_DT recursive_JJ partitioning_NN procedure_NN into_IN three_CD main_JJsections._NNS The_DT data-importing_NN Graphical_NNP User_NNP Interface_NNP (see_NNP Figure_NN 4)_CD allows_VBZ to_TO read_VB data_NNSfrom_IN Excel-like_NNP spreadsheets_NNS and_CC plain_JJ text_NN files_NNS and_CC automatically_RB recognises_VBZ the_DT nature_NN of_INthe_DT variables_NNS by_IN distinguishing_VBG the_DT categorical,_NN numerical_JJ or_CC alphanumerical_JJ columns_NNS of_IN a_DTdata_NNS matrix._NN J-Fast_NN also_RB allows_VBZ the_DT user_NN to_TO specify_VB the_DT Decision_NNP Tree_NNP Induction_NNP model_NN by_INchoosing_VBG the_DT response_NN variable,_NN as_RB well_RB as_IN which_WDT predictor(s)_VBP should_MD be_VB treated_VBN as_IN ordinal,_NNSnominal_JJ or_CC as_IN excluded_VBN from_IN the_DT analysis._NNFig._NNP 4._VBD J-Fast_JJ data_NNS importing_VBG Graphical_NNP User_NNP Interface_NNPA_DT second_JJ GUI_NN visualizes_VBZ some_DT information_NN about_IN the_DT chosen_VBN DTI_NNP model_NN and_CC provides_VBZ some_DTdescriptive_NN statistics_NNS about_IN the_DT analyzing_NN data._NN It_PRP also_RB allows_VBZ the_DT user_NN to_TO specify_VB which_WDT are_VBPthe_DT features_NNS of_IN the_DT DTI_NNP model_NN under_IN specification,_NNS such_JJ as_IN the_DT learning_NN sample_NN rate,_NN the_DTstopping_VBG conditions,_NN the_DT possibility_NN of_IN obtaining_VBG a_DT verbose_JJ output._NN It_PRP also_RB asks_VBZ the_DT user_NN to_TOchoose_VB between_IN all_PDT the_DT recursive_JJ partitioning_NN heuristics_NNS that_WDT are_VBP present_JJ into_IN the_DT class_NN path._NNThen,_RB the_DT software_NN starts_VBZ the_DT tree_NN growing_VBG procedure._NNThe_DT third_JJ component_NN of_IN the_DT J-FAST_NN software_NN is_VBZ the_DT results_NNS navigator._. It_PRP allows_VBZ the_DT user_NN to_TOinteractively_JJ display_NN and_CC navigate_NN into_IN the_DT results_NNS of_IN the_DT analysis._NNThe_DT results_NNS navigator_NN GUI_NNP (see_NNP Figure_NNP 5)_CD consists_VBZ of_IN two_CD windows._, The_DT first_JJ one_CD is_VBZ the_DT main_JJresults_NNS window._VBD It_PRP visualises_VBZ the_DT obtained_VBN decision_NN tree,_NN charts_NNS the_DT misclassification_NN rates_NNS and_CCthe_DT selected_VBN node’s_NNS information_NN panel_NN (there_RB is_VBZ a_DT button_NN for_IN visualizing_VBG the_DT splitting_JJ rule_NN to_TOreach_VB the_DT node,_NN the_DT misclassification_NN rate_NN for_IN the_DT node,_NN etc.)._VBD The_DT second_JJ component_NN is_VBZ the_DTTree_NNP Console_NNP Window_NNP (Figure_NN 6)._. It_PRP contains_VBZ buttons_NNS that_IN allow_VBP the_DT user_NN to_TO navigate_VB through_INthe_DT pruning_NN sequence_NN and_CC access_NN directly_RB the_DT best,_JJS the_DT trivial_JJ and_CC the_DT maximal_JJ tree._NN For_IN each_DTtree_NN in_IN the_DT pruning_NN sequence,_VBD the_DT node_NN that_WDT is_VBZ going_VBG to_TO be_VB pruned_VBN is_VBZ highlighted._JJR By_IN clicking_VBGwww.intechopen.com_NNEvolutionary_JJ Algorithms_NNP in_IN Decision_NNP Tree_NNP Induction_NN467_CDon_IN the_DT node,_NN the_DT interface_NN allows_VBZ to_TO get_VB the_DT data_NNS units_NNS which_WDT fall_VBP in_IN that_DT node_NN and_CC to_TO write_VBthem_PRP into_IN a_DT file_NN in_IN order_NN to_TO continue_VB the_DT analysis_NN of_IN such_JJ units_NNS using_VBG another_DT software._NN It_PRP is_VBZalso_RB possible,_RB from_IN the_DT second_JJ step_NN GUI,_NNP to_TO simultaneously_RB start_VB more_JJR than_IN one_CD analysis_NN in_INorder_NN to_TO obtain_VB different_JJ tree_NN navigators_NNS simultaneously_RB on_IN the_DT screen._NN This_DT feature_NN is_VBZparticularly_RB useful_JJ for_IN comparing_VBG trees_NNS grown_VBN from_IN different_JJ datasets_NNS or_CC on_IN the_DT same_JJ dataset_NNbut_CC with_IN using_VBG different_JJ DTI_NNP specifications._.Fig._NNP 5._VBD J-Fast_JJ data_NNS results_NNS navigator_NN Graphical_NNP User_NNP Interface_NNPJ-FAST_NN is_VBZ more_JJR than_IN a_DT simple_JJ recursive_JJ partitioning_NN software._NN Because_IN of_IN the_DT fact_NN that_IN it_PRP has_VBZbeen_VBN mainly_RB designed_VBN to_TO support_VB the_DT research_NN activity,_IN it_PRP offers_VBZ many_JJ useful_JJ functions_NNS like_INthe_DT possibility_NN of_IN saving_VBG created_VBN objects_NNS (trees,_, datasets,_NNS nodes,_, etc.)_NN via_IN the_DT Java_NNP serialization_NNmechanism_NN in_IN order_NN to_TO better_RB analyze_VB using_VBG other_JJ ad-hoc_NN written_VBN Java_NNP programs_NNS (some_DT of_INthem_PRP have_VBP already_RB been_VBN implemented,_VBN like_IN a_DT different_JJ tree_NN interface_NN called_VBN “TreeSurfer”)._.Interactivity_NNP with_IN the_DT R_NN statistical_JJ software_NN is_VBZ also_RB provided:_VBN by_IN right-clicking_NN on_IN a_DT node_NN it_PRP is_VBZpossible_JJ to_TO send_VB the_DT corresponding_JJ data_NN to_TO R_NN in_IN order_NN to_TO continue_VB the_DT analysis._NN This_DT is_VBZparticularly_RB useful_JJ if_IN another_DT statistical_JJ analysis_NN (i.e._VBZ a_DT logit_NN model)_NN has_VBZ to_TO be_VB made_VBN on_IN a_DTparticular_JJ segment_NN (node)_IN extracted_VBN from_IN the_DT obtained_VBN decision_NN tree._NNJ-FAST_NN has_VBZ to_TO be_VB also_RB considered_VBN as_IN a_DT Java_NNP objects_VBZ Library_JJ (or_NN API_NNP -_: Application_NNP Program_NNInterface),_NNP for_IN building_VBG Classification_NNP and_CC Regression_NNP Trees._NNP Any_DT researcher_NN which_WDT is_VBZ able_JJ to_TOprogram_NN in_IN Java_NNP could_MD use_VB the_DT classes_NNS from_IN the_DT J-FAST_NNP API_NNP in_IN order_NN to_TO get_VB trees_NNS without_INhaving_VBG to_TO write_VB all_DT the_DT necessary_JJ code._NN In_IN addition,_VBG the_DT J-FAST_NNP platform_NN offers_VBZ many_JJ useful_JJobjects._FW The_DT most_RBS important_JJ ones_NNS are:_VBP •_RB Statistics:_VB it_PRP provides_VBZ univariate_JJ and_CC bivariate_JJ descriptive_NN statistics._NN •_NN DataSet:_IN it_PRP stores_VBZ data_NNS for_IN recursive_JJ partitioning_NN purposes_NNS (response_VBP variable,_JJ predictors,_NNetc.)._FW •_, Split:_FW it_PRP specifies_VBZ the_DT type_NN of_IN split_NN (binary,_NN ternary,etc.)_NNwww.intechopen.com_NNAdvances_NNS in_IN Evolutionary_NNP Algorithms_NNP468_CD•_NN TreeGrower:_NNP it_PRP is_VBZ a_DT class_NN for_IN growing_VBG decision_NN trees_NNS •_VBP Pruner:_RB it_PRP is_VBZ class_NN that_IN for_IN decision_NN tree_NN pruning_NN •_RB TreeViewer:_IN it_PRP is_VBZ a_DT interactive_JJ interface_NN class_NN •_NN Utility:_IN it_PRP encompasses_VBZ many_JJ useful_JJ function_NN like_IN reading_VBG data_NNS from_IN plain_JJ text_NN files,_NNExcel-like_NNP spreadsheets,_NN etc._FW •_FW TreeBuild_NNP interface:_, it_PRP defines_VBZ all_PDT the_DT rules_NNS to_TO follow_VB for_IN the_DT programmer_NN to_TO write_VB his_PRP$own_JJ heuristic._NNFig._NNP 6._VBZ J-Fast_JJ tree_NN console_NN window_NN Graphical_NNP User_NNP Interface_NNPwww.intechopen.com_NNAdvances_NNS in_IN Evolutionary_NNP Algorithms_NNPEdited_NNP by_IN Xiong_NNP Zhihui_NNPISBN_NNP 978-953-7619-11-4_CDHard_NNP cover,_NN 284_CD pages_NNSPublisher_NNP InTech_NNPPublished_VBN online_NNP 01,_CD November,_NNP 2008_CDPublished_VBN in_IN print_NN edition_NN November,_NNP 2008_CDInTech_NNP Europe_NNPUniversity_NNP Campus_NNP STeP_NNP Ri_NNP Slavka_NNP Krautzeka_NNP 83/A_. 51000_CD Rijeka,_NNP Croatia_NNP Phone:_NNP +385_CD (51)_IN 770_CD 447_CD Fax:_NNP +385_CD (51)_IN 686_CD 166www.intechopen.com_.InTech_NNP China_NNPUnit_NNP 405,_CD Office_NNP Block,_NNP Hotel_NNP Equatorial_JJ Shanghai_NNP No.65,_NNP Yan_NNP An_DT Road_NNP (West),_NNP Shanghai,_NNP 200040,_CD China_NNPPhone:_NNP +86-21-62489820_CD Fax:_NNP +86-21-62489821_CDWith_IN the_DT recent_JJ trends_NNS towards_IN massive_JJ data_NNS sets_NNS and_CC significant_JJ computational_JJ power,_NN combined_VBN withevolutionary_IN algorithmic_JJ advances_NNS evolutionary_JJ computation_NN is_VBZ becoming_VBG much_RB more_RBR relevant_JJ to_TO practice._VB Aimof_IN the_DT book_NN is_VBZ to_TO present_VB recent_JJ improvements,_JJ innovative_JJ ideas_NNS and_CC concepts_NNS in_IN a_DT part_NN of_IN a_DT huge_JJ EA_NN field._.How_WRB to_TO reference_NNIn_IN order_NN to_TO correctly_VB reference_NN this_DT scholarly_NN work,_NN feel_VBP free_JJ to_TO copy_VB and_CC paste_VB the_DT following:_NNFrancesco_NNP Mola,_NNP Raffaele_NNP Miele_NNP and_CC Claudio_NNP Conversano_NNP (2008)._NNP Evolutionary_NNP Algorithms_NNP in_IN Decision_NNP TreeInduction,_NNP Advances_NNP in_IN Evolutionary_NNP Algorithms,_NNP Xiong_NNP Zhihui_NNP (Ed.),_NNP ISBN:_NNP 978-953-7619-11-4,_CC InTech,Available_NNP from:http://www.intechopen.com/books/advances_in_evolutionary_algorithms/evolutionary_algorithms_in_decision_tree_induction_IN
